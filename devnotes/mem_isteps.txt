## Power off DRAM - VDDR and vPP (13.1)

Must drop VDDR first, then VPP. Only done when powered on, i.e. warm reboot.
Done using GPIO (TODO: addresses?)

## Mem PLL reset (13.2)

> - This step is a no-op on cumulus as the centaur is already has its PLLs setup
>   in step 11
> - This step is a no-op if memory is running in synchronous mode since the MCAs
>   are using the nest PLL, HWP detect and exits
> - If in async mode then this HWP will put the PLL into bypass, reset mode
> - Disable listen_to_sync for MEM chiplet, whenever MEM is not in sync to NEST

For each functional Proc:
> if ( !ATTR_MC_SYNC_MODE && !ATTR_CHIP_EC_FEATURE_DMI_MC_PLL_SCAN_BUCKETS )
  For each functional MC(BIST?):
    - Assert endpoint reset
      PERV_NET_CTRL0_WOR = 0x8..0 >> PERV_1_NET_CTRL0_PCB_EP_RESET    // 0x8..0

    - Mask PLL unlock error in PCB slave
      PERV_SLAVE_CONFIG_REG |= 0x8..0 >> 12 (no name?)                // 0x0008..0

    - Move MC PLL into reset state
      PERV_NET_CTRL0_WOR = 0x8..0 >> PERV_1_NET_CTRL0_PLL_BYPASS      // 0x04..0
      PERV_NET_CTRL0_WOR = 0x8..0 >> PERV_1_NET_CTRL0_PLL_RESET       // 0x08..0
      PERV_NET_CTRL0_WOR = 0x8..0 >> PERV_1_NET_CTRL0_PLL_TEST_EN     // 0x10..0

    - Assert MEM PLDY and DCC bypass
      PERV_NET_CTRL1_WOR =
              (0x8..0 >> PERV_1_NET_CTRL1_CLK_DCC_BYPASS_EN) |             // 0x4..0
              (0x8..0 >> PERV_1_NET_CTRL1_CLK_PDLY_BYPASS_EN               // 0x2..0

    - Drop endpoint reset
      PERV_NET_CTRL0_WAND = ~(0x8..0 >> PERV_1_NET_CTRL0_PCB_EP_RESET)     // ~0x4..0

    - Disable listen to sync pulse to MC chiplet, when MEM is not in sync to nest
      PERV_SYNC_CONFIG |= 0x8..0 >> PERV_1_SYNC_CONFIG_LISTEN_TO_PULSE_DIS // 0x08..0

    - Initialize OPCG_ALIGN register
      PERV_OPCG_ALIGN =
                (OPCG_ALIGN_INOP_ALIGN  &   0xf) << 60 |    // 0x5   << 60   (8:1)
                (OPCG_ALIGN_INOP_WAIT   &  0xff) << 44 |    // 0x00  << 44
                (OPCG_ALIGN_WAIT_CYCLES & 0xfff) <<  0 |    // 0x020 <<  0
                (OPCG_ALIGN_SCAN_RATIO  &  0x1f) << 12      // 0x00  << 12   (1:1)

    - scan0 flush PLL boundary ring
      PERV_CLK_REGION =
                (0x8..0 >> PERV_1_SCAN_REGION_TYPE_UNIT10)  |    // 0x8..0 >> 14
                (0x8..0 >> PERV_1_CLK_REGION_SEL_THOLD_SL)  |    // 0x8..0 >> 48
                (0x8..0 >> PERV_1_CLK_REGION_SEL_THOLD_NSL) |    // 0x8..0 >> 49
                (0x8..0 >> PERV_1_CLK_REGION_SEL_THOLD_ARY)      // 0x8..0 >> 50
      PERV_SCAN_REGION_TYPE = 
                (0x8..0 >> PERV_1_SCAN_REGION_TYPE_UNIT10) |     // 0x8..0 >> 14
                (0x8..0 >> PERV_1_SCAN_REGION_TYPE_BNDY)         // 0x8..0 >> 56
      PERV_OPCG_REG0 &= ~(0x8..0 >> PERV_1_OPCG_REG0_RUNN_MODE)  // 0x8..0 >> 0
      PERV_OPCG_REG0 |= 0x8..0 >> PERV_1_OPCG_REG0_RUN_SCAN0     // 0x8..0 >> 2
      timeout(200 * 16us):
        if (PERV_CPLT_STAT0 & (0x8..0 >> PERV_1_CPLT_STAT0_CC_CTRL_OPCG_DONE_DC) == 1) break   // 0x8..0 >> 8
        delay(16us)
      PERV_CLK_REGION = 0
      PERV_SCAN_REGION_TYPE = 0

## Mem PLL initf : PLL Initfile for MBAs (13.3)

> - This step is a no-op on cumulus
> - This step is a no-op if memory is running in synchronous mode since the
>   MCAs are using the nest PLL, HWP detect and exits
> - MCA PLL setup
>   - Note that Hostboot doesn't support twiddling bits, Looks up which "bucket"
>     (ring) to use from attributes set during mss_freq
>   - Then request the SBE to scan ringId with setPulse
>     - SBE needs to support 5 RS4 images
>     - Data is stored as a ring image in the SBE that is frequency specific
>     - 5 different frequencies (1866, 2133, 2400, 2667, EXP)

For each functional Proc:
> if (ATTR_MC_SYNC_MODE == 0 && ATTR_CHIP_EC_FEATURE_DMI_MC_PLL_SCAN_BUCKETS == 0)
  For each functional MCBIST
    - fapi2::putRing(mbist, ring_id(depends on RAM freq), RING_MODE_SET_PULSE_NSL)
      - /src/usr/fapi2/plat_hw_access.C:943

## mem_pll_setup: Setup PLL for MBAs (13.4)

> - This step is a no-op on cumulus
> - This step is a no-op if memory is running in synchronous mode since the MCAs
>   are using the nest PLL, HWP detect and exits
> - MCA PLL setup
>   - Moved PLL out of bypass(just DDR)
> - Performs PLL checking

For each functional Proc:
> if ( !ATTR_MC_SYNC_MODE && !ATTR_CHIP_EC_FEATURE_DMI_MC_PLL_SCAN_BUCKETS )
  For each functional MC(BIST?):
    - Drop PLDY bypass of Progdelay logic
      PERV_NET_CTRL1_WAND = ~(0x8..0 >> PERV_1_NET_CTRL1_CLK_PDLY_BYPASS_EN)   // 0x8..0 >> 2

    - Drop DCC bypass of DCC logic
      PERV_NET_CTRL1_WAND = ~(0x8..0 >> PERV_1_NET_CTRL1_CLK_DCC_BYPASS_EN)    // 0x8..0 >> 1

    > if (ATTR_NEST_MEM_X_O_PCI_BYPASS == 0)
    > {
      - Drop PLL test enable
        PERV_NET_CTRL0_WAND = ~(0x8..0 >> PERV_1_NET_CTRL0_PLL_TEST_EN)        // 0x8..0 >> 3

      - Drop PLL reset
        PERV_NET_CTRL0_WAND = ~(0x8..0 >> PERV_1_NET_CTRL0_PLL_RESET)          // 0x8..0 >> 4

      delay(5ms)

      - check PLL lock
        assert(PERV_PLL_LOCK_REG & 0x8..0 == 1)

      - Drop PLL Bypass
        PERV_NET_CTRL0_WAND = ~(0x8..0 >> PERV_1_NET_CTRL0_PLL_BYPASS)         // 0x8..0 >> 5

      - Set scan ratio to 4:1
        PERV_OPCG_ALIGN = (PERV_OPCG_ALIGN & ~(0x1f << 47)) | OPCG_ALIGN_SCAN_RATIO << 47	// | 0x3 << 47

    > }

    - Reset PCB Slave error register
      PERV_ERROR_REG = ~0

    - Unmask PLL unlock error in PCB slave
      PERV_SLAVE_CONFIG_REG &= ~(0x8..0 >> 12)        // 0x0008..0

## proc_mcs_skewadjust: Update clock mesh deskew (13.5)

> This step is a no-op

## mem_startclocks: Start clocks on MBA/MCAs (13.6)

> - This step is a no-op on cumulus
> - This step is a no-op if memory is running in synchronous mode since the MCAs
>   are using the nest PLL, HWP detect and exits
> - Drop fences and tholds on MBA/MCAs to start the functional clocks

For each functional Proc:
pg_vector = bitmap of ATTR_CHIP_UNIT_POS of functional Perv children of Proc
 - /src/import/chips/p9/procedures/hwp/perv/p9_sbe_common.C:692
> if(!ATTR_MC_SYNC_MODE)
> {
  For each functional MC(BIST?):
    - Call p9_mem_startclocks_cplt_ctrl_action_function for Mc chiplets
      p9_mem_startclocks_cplt_ctrl_action_function:
        u16 cplt_ctrl_init = ~(MC.ATTR_PG >> (16-4-11)) & 0x7ff         // >> 1
        - Drop partial good fences
          PERV_CPLT_CTRL1_CLEAR = (~MC.ATTR_PG & (0x8..0 >> 3)) | (cplt_ctrl_init << 1)
        - reset abistclk_muxsel and syncclk_muxsel
          PERV_CPLT_CTRL0_CLEAR =
              (0x8..0 >> PEC_CPLT_CTRL0_CTRL_CC_ABSTCLK_MUXSEL_DC) |                   // 0x8..0
              (0x8..0 >> PEC_CPLT_CTRL0_TC_UNIT_SYNCCLK_MUXSEL_DC)                     // 0x4..0

    - Call module align chiplets for Mc chiplets
      p9_sbe_common_align_chiplets:
        - For all chiplets: exit flush
          PERV_CPLT_CTRL0_OR = 0x8..0 >> PERV_1_CPLT_CTRL0_CTRL_CC_FLUSHMODE_INH_DC    // 0x2..0
        - For all chiplets: enable alignement
          PERV_CPLT_CTRL0_OR = 0x8..0 >> PERV_1_CPLT_CTRL0_CTRL_CC_FORCE_ALIGN_DC      // 0x1..0
        - Clear chiplet is aligned
          PERV_SYNC_CONFIG |= 0x8..0 >> PERV_1_SYNC_CONFIG_CLEAR_CHIPLET_IS_ALIGNED    // 0x01..0
        - Unset Clear chiplet is aligned
          PERV_SYNC_CONFIG &= ~(0x8..0 >> PERV_1_SYNC_CONFIG_CLEAR_CHIPLET_IS_ALIGNED) // 0x01..0
        delay(100us)
        - Poll OPCG done bit to check for run-N completeness
          timeout(10*100us):
            if (PERV_CPLT_STAT0 & (0x8..0 >> PERV_1_CPLT_STAT0_CC_CTRL_CHIPLET_IS_ALIGNED_DC) == 1) break    // 0x8..0 >> 9
            delay(100us)
        - For all chiplets: disable alignement
          PERV_CPLT_CTRL0_CLEAR = 0x8..0 >> PERV_1_CPLT_CTRL0_CTRL_CC_FORCE_ALIGN_DC   // 0x1..0

      l_clock_regions = (0x7fe & (~MD.ATTR_PG >> 1))        // uint16 to uint64 buffer conversion

    - Call module clock start stop for MC01, MC23
      p9_sbe_common_clock_start_stop(l_trgt_chplt, CLOCK_CMD = 1,
                                                      DONT_STARTSLAVE = 0, DONT_STARTMASTER = 0, l_clock_regions,
                                                      CLOCK_TYPES = 0x7):
        - Chiplet exit flush
          PERV_CPLT_CTRL0_OR = 0x8..0 >> PERV_1_CPLT_CTRL0_CTRL_CC_FLUSHMODE_INH_DC   // 0x2..0
        - Clear Scan region type register
          PERV_SCAN_REGION_TYPE = 0
        - Reading the initial status of clock controller
          l_sl_clock_status = PERV_CLOCK_STAT_SL
          l_nsl_clock_status = PERV_CLOCK_STAT_NSL
          l_ary_clock_status = PERV_CLOCK_STAT_ARY
            // Debug information only?
        - Setup all Clock Domains and Clock Types
          PERV_CLK_REGION = (PERV_CLK_REGION & ~(0xfffe00000000e000)) |
              (CLOCK_CMD << 62)                         |
              (0x8..0 >> PERV_1_CLK_REGION_SLAVE_MODE)  |         // >> 2
              (0x8..0 >> PERV_1_CLK_REGION_MASTER_MODE) |         // >> 3
              (l_clock_regions << (64-4-11))            |         // << 49
              ((CLOCK_TYPES & 0x7) << (64-48-3))                  // << 13
        - Poll OPCG done bit to check for completeness
          timeout(10*100us):
            if (PERV_CPLT_STAT0 & (0x8..0 >> PERV_1_CPLT_STAT0_CC_CTRL_OPCG_DONE_DC) == 1) break    // 0x8..0 >> 8
            delay(100us)
        > if (!DONT_STARTSLAVE && !DONT_STARTMASTER)          // true
        > {
          p9_sbe_common_check_status(i_regions, l_{sl,nsl,ary}_clock_status, l_reg_{sl,nsl,ary},
                                            i_clock_cmd, l_exp_{sl,nsl,ary}_clock_status)
          assert(PERV_CLOCK_STAT_{SL,NSL,ARY} == l_exp_{sl,nsl,ary}_clock_status)
          + debug output
        > }

    - Call p9_mem_startclocks_fence_setup_function for Mc chiplets
      p9_mem_startclocks_fence_setup_function(l_trgt_chplt, pg_vector):
        > if ((MC.ATTR_CHIP_UNIT_POS == 0x07 && pg_vector & 0x8..0 >> 5) ||
        >     (MC.ATTR_CHIP_UNIT_POS == 0x08 && pg_vector & 0x8..0 >> 3))
        > {
          - Drop chiplet fence
            PERV_NET_CTRL0_WAND = ~(0x8..0 >> PERV_1_NET_CTRL0_FENCE_EN)    // >> 18
        > }

    - Call p9_mem_startclocks_flushmode for Mc chiplets
      p9_mem_startclocks_flushmode:
        - Clear flush_inhibit to go in to flush mode
          PERV_CPLT_CTRL0_CLEAR = 0x8..0 >> PEC_CPLT_CTRL0_CTRL_CC_FLUSHMODE_INH_DC     // >> 2

    - Call p9_sbe_common_configure_chiplet_FIR for MC chiplets
      p9_sbe_common_configure_chiplet_FIR:
        - reset pervasive FIR
          PERV_LOCAL_FIR = 0
        - configure pervasive FIR action/mask
          PERV_LOCAL_FIR_ACTION0 = PERV_LFIR_ACTION0[ATTR_CHIP_UNIT_POS-1]
          PERV_LOCAL_FIR_ACTION1 = PERV_LFIR_ACTION1[ATTR_CHIP_UNIT_POS-1]
        > #ifdef __PPE__ and test for FSP-less system, no-op with SP (?)
          PERV_LOCAL_FIR_MASK = PERV_LFIR_MASK[ATTR_CHIP_UNIT_POS-1]
        - reset XFIR
          PERV_XFIR = 0
        - configure XFIR mask
          PERV_FIR_MASK = PERV_XFIR_MASK[ATTR_CHIP_UNIT_POS-1]

    - Reset FBC chiplet configuration
      PERV_CPLT_CONF0 = (PERV_CPLT_CONF0 & ~(0xfef8ULL))  |
              ATTR_PROC_FABRIC_SYSTEM_ID << (64-56-5)     |   // << 3
              ATTR_PROC_FABRIC_GROUP_ID  << (64-48-4)     |   // << 12
              ATTR_PROC_FABRIC_CHIP_ID   << (64-52-3)         // << 9

    - Add to Multicast Group
      // avoid setting if register is already set, i.e. != p9SbeChipletReset::MCGR_CNFG_SETTING_EMPTY
      PERV_MULTICAST_GROUP_1 = p9SbeChipletReset::MCGR_CNFG_SETTING_GROUP0 // Why GROUP_1 = GROUP0?
      PERV_MULTICAST_GROUP_2 = p9SbeChipletReset::MCGR_CNFG_SETTING_GROUP2
> }

End for each Proc:
- SCOM::enableMemChipletMulticast()

## host_enable_memvolt: Enable the VDDR3 Voltage Rail (13.7)

> - BMC based systems – this is a no-op

## mss_scominit: Perform scom inits to MC and PHY (13.8)

> - HW units included are MCBIST, MCA/PHY (Nimbus) or membuf, L4, MBAs (Cumulus)
> - Does not use initfiles, coded into HWP
> - Uses attributes from previous step
> - Pushes memory extent configuration into the MBA/MCAs
>   - Addresses are pulled from attributes, set previously by mss_eff_config
>   - MBA/MCAs always start at address 0, address map controlled by
>     proc_setup_bars below

for each functional MCBIST:
  assert(count_dimms(MCBIST) > 0)
  for each functional or magic MCA:
    > if (count_dimms(MCA) > 0)
    > {   // no DIMM = no SPD = no parameters to init MCA
      - mca scominit
        p9n_mca_scom(MCA, MCBIST, MCA.getParent<MCS>, FAPI_SYSTEM, MCBIST.getParent<PROC_CHIP>)     // generated from initfile
          l_chip_ec = PROC_CHIP.ATTR_EC
          l_chip_id = PROC_CHIP.ATTR_NAME
          l_TGT2_ATTR_EFF_NUM_RANKS_PER_DIMM = MCS.ATTR_EFF_NUM_RANKS_PER_DIMM
          l_def_POSITION = l_TGT0_ATTR_CHIP_UNIT_POS = MCA.ATTR_CHIP_UNIT_POS
          l_def_PORT_INDEX = l_def_POSITION%2
          l_def_NUM_RANKS = (l_TGT2_ATTR_EFF_NUM_RANKS_PER_DIMM[l_def_PORT_INDEX][0] +
                                    l_TGT2_ATTR_EFF_NUM_RANKS_PER_DIMM[l_def_PORT_INDEX][1])
          l_TGT2_ATTR_EFF_NUM_MASTER_RANKS_PER_DIMM = MCS.ATTR_EFF_NUM_MASTER_RANKS_PER_DIMM
          l_def_SLOT0_DENOMINATOR = ((l_TGT2_ATTR_EFF_NUM_MASTER_RANKS_PER_DIMM[l_def_PORT_INDEX][0] ==
                                             0x0) | l_TGT2_ATTR_EFF_NUM_MASTER_RANKS_PER_DIMM[l_def_PORT_INDEX][0])
          l_def_SLOT0_DRAM_STACK_HEIGHT = (l_TGT2_ATTR_EFF_NUM_RANKS_PER_DIMM[l_def_PORT_INDEX][0] /
                l_def_SLOT0_DENOMINATOR)
          l_def_is_dual_slot = ((l_TGT2_ATTR_EFF_NUM_RANKS_PER_DIMM[l_def_PORT_INDEX][0] > 0)
                                       && (l_TGT2_ATTR_EFF_NUM_RANKS_PER_DIMM[l_def_PORT_INDEX][1] > 0))
          l_def_refblock_off_special_case = (((l_def_is_dual_slot == 0)
                && (l_TGT2_ATTR_EFF_NUM_MASTER_RANKS_PER_DIMM[l_def_PORT_INDEX][0] == 4))
                && (l_def_SLOT0_DRAM_STACK_HEIGHT == 2))
          l_TGT3_ATTR_ENABLE_MEM_EARLY_DATA_SCOM = SYSTEM.ATTR_ENABLE_MEM_EARLY_DATA_SCOM
          l_TGT4_ATTR_CHIP_EC_FEATURE_HW401780 = !!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!
          // Regs for ID=5 below are not documented
          *0x5010823 =        // P9N2_MCS_PORT02_MCPERF0
              [22-27] = 0x20

          *0x5010824 =
              [0-2]   = 1
              [3-5]   = 3
              [6-8]   = 5
              [9-11]  = 7
              [13-15] = 0b000 : if (l_TGT2_ATTR_EFF_NUM_MASTER_RANKS_PER_DIMM[l_def_PORT_INDEX][0] == 1),
                        0b001 : if (l_TGT2_ATTR_EFF_NUM_MASTER_RANKS_PER_DIMM[l_def_PORT_INDEX][0] == 2),
                        0b100 : if (l_TGT2_ATTR_EFF_NUM_MASTER_RANKS_PER_DIMM[l_def_PORT_INDEX][0] == 4),
              [13-15] |= 0b010 : if (l_def_is_dual_slot && l_TGT2_ATTR_EFF_NUM_MASTER_RANKS_PER_DIMM[l_def_PORT_INDEX][0] != 4)
              [16] = 1 : if (1 < l_def_NUM_RANKS <= 8 && l_def_refblock_off_special_case) else 0  // MC01_PORT0_ATCL_CL_CLSCOM_MCPERF2_ENABLE_REFRESH_BLOCK_SQ
              [17] = 1 : if (1 < l_def_NUM_RANKS <= 8 && l_def_refblock_off_special_case) else 0  // MC01_PORT0_ATCL_CL_CLSCOM_MCPERF2_ENABLE_REFRESH_BLOCK_NSQ
              [18]    = 0     // MC01_PORT0_ATCL_CL_CLSCOM_MCPERF2_ENABLE_REFRESH_BLOCK_DISP
              [28-31] = 0b0100
              [50-54] = 0b11100
              [61] = 1 : if (l_TGT3_ATTR_ENABLE_MEM_EARLY_DATA_SCOM == fapi2::ENUM_..._ON) else 0 // MC01_PORT0_ATCL_CL_CLSCOM_MCPERF2_EN_ALT_ECR_ERR

          *0x5010825 =
              [1]     = 0     // MC01_PORT0_ATCL_CL_CLSCOM_MCAMOC_FORCE_PF_DROP0_OFF
              [4-28]  = 0x19fffff : if (l_TGT4_ATTR_CHIP_EC_FEATURE_HW401780 != 1) else 0
              [29-31] = 1     // MC01_PORT0_ATCL_CL_CLSCOM_MCAMOC_AMO_SIZE_SELECT_128B_RW_64B_DATA

          *0x5010826 =
              [0-7]   = 1
              [8-15]  = l_def_MC_EPSILON_CFG_T0
              [16-23] = l_def_MC_EPSILON_CFG_T1
              [24-31] = l_def_MC_EPSILON_CFG_T1
              [32-39] = l_def_MC_EPSILON_CFG_T2
              [40-47] = l_def_MC_EPSILON_CFG_T2

          *0x5010827 =
              [0]     = 1   // MC01_PORT0_ATCL_CL_CLSCOM_MCBUSYQ_ENABLE_BUSY_COUNTERS_ON
              [1-3]   = 1   // MC01_PORT0_ATCL_CL_CLSCOM_MCBUSYQ_BUSY_COUNTER_WINDOW_SELECT_1024_CYCLES
              [4-13]  = 38
              [14-23] = 51
              [24-33] = 64

          *0x501082b =
              [31] = 1      // MC01_PORT0_ATCL_CL_CLSCOM_MCPERF3_ENABLE_CL0
              [41] = 1      // MC01_PORT0_ATCL_CL_CLSCOM_MCPERF3_ENABLE_AMO_MSI_RMW_ONLY
              [43] = 1 : if (l_TGT3_ATTR_ENABLE_MEM_EARLY_DATA_SCOM == fapi2::ENUM_..._OFF) else 0 // MC01_PORT0_ATCL_CL_CLSCOM_MCPERF3_ENABLE_CP_M_MDI0_LOCAL_ONLY
              [44] = 1      // MC01_PORT0_ATCL_CL_CLSCOM_MCPERF3_DISABLE_WRTO_IG
              [45] = 1

          MC01.PORT0.SRQ.MBA_DSM0Q =       // 0x701090a
              [0-5]   MBA_DSM0Q_CFG_RODT_START_DLY = l_TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] -
                          l_TGT2_ATTR_EFF_DRAM_CWL[l_def_PORT_INDEX]
              [6-11]  MBA_DSM0Q_CFG_RODT_END_DLY = l_TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] -
                          l_TGT2_ATTR_EFF_DRAM_CWL[l_def_PORT_INDEX] + 5
              [12-17] MBA_DSM0Q_CFG_WODT_START_DLY = 0
              [18-23] MBA_DSM0Q_CFG_WODT_END_DLY = 5
              [24-29] MBA_DSM0Q_CFG_WRDONE_DLY = 24
              [30-35] MBA_DSM0Q_CFG_WRDATA_DLY = (l_TGT2_ATTR_EFF_DRAM_CWL[l_def_PORT_INDEX] +
                        l_TGT2_ATTR_MSS_EFF_DPHY_WLO[l_def_PORT_INDEX]) - 8
              [36-41] MBA_DSM0Q_CFG_RDTAG_DLY =
                if (TGT2_ATTR_EFF_DIMM_TYPE[l_def_PORT_INDEX][0] == 1):
                  MSS_FREQ_EQ_1866:               TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] + 7
                  MSS_FREQ_EQ_2133:               TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] + 7
                  MSS_FREQ_EQ_2400 && NOT_NVDIMM: TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] + 8
                  MSS_FREQ_EQ_2400 && IS_NVDIMM:  TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] + 9
                  MSS_FREQ_EQ_2666:               TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] + 9
                if (TGT2_ATTR_EFF_DIMM_TYPE[l_def_PORT_INDEX][0] == 3):
                  MSS_FREQ_EQ_1866:               TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] + 9
                  MSS_FREQ_EQ_2133:               TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] + 9
                  MSS_FREQ_EQ_2400:               TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] + 10
                  MSS_FREQ_EQ_2666:               TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] + 11

          MC01.PORT0.SRQ.MBA_TMR0Q =      // 0x701090b
              [0-3]   MBA_TMR0Q_RRDM_DLY =    l_def_RANK_SWITCH_TCK + 4
              [4-7]   MBA_TMR0Q_RRSMSR_DLY =  4
              [8-11]  MBA_TMR0Q_RRSMDR_DLY =  4
              [12-15] MBA_TMR0Q_RROP_DLY =    l_TGT2_ATTR_EFF_DRAM_TCCD_L[l_def_PORT_INDEX]
              [16-19] MBA_TMR0Q_WWDM_DLY =    l_def_RANK_SWITCH_TCK + 4
              [20-23] MBA_TMR0Q_WWSMSR_DLY =  4
              [24-27] MBA_TMR0Q_WWSMDR_DLY =  4
              [28-31] MBA_TMR0Q_WWOP_DLY =    l_TGT2_ATTR_EFF_DRAM_TCCD_L[l_def_PORT_INDEX]
              [32-36] MBA_TMR0Q_RWDM_DLY =    l_TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] + 4 +
                        l_def_BUS_TURNAROUND_TCK - l_TGT2_ATTR_EFF_DRAM_CWL[l_def_PORT_INDEX]
              [37-41] MBA_TMR0Q_RWSMSR_DLY =  l_TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] + 4 +
                        l_def_BUS_TURNAROUND_TCK - l_TGT2_ATTR_EFF_DRAM_CWL[l_def_PORT_INDEX]
              [42-46] MBA_TMR0Q_RWSMDR_DLY =  l_TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX] + 4 +
                        l_def_BUS_TURNAROUND_TCK - l_TGT2_ATTR_EFF_DRAM_CWL[l_def_PORT_INDEX]
              if (l_TGT2_ATTR_EFF_DIMM_TYPE[l_def_PORT_INDEX][0] != 1)
                [32-36] += 6
                [37-41] += 6
                [42-46] += 6
              [47-50] MBA_TMR0Q_WRDM_DLY =    l_TGT2_ATTR_EFF_DRAM_CWL[l_def_PORT_INDEX] + 4 +
                    l_def_BUS_TURNAROUND_TCK - l_TGT2_ATTR_EFF_DRAM_CL[l_def_PORT_INDEX]
              [51-56] MBA_TMR0Q_WRSMSR_DLY =  l_TGT2_ATTR_EFF_DRAM_CWL[l_def_PORT_INDEX] + 4 +
                    l_TGT2_ATTR_EFF_DRAM_TWTR_S[l_def_PORT_INDEX]
              [57-62] MBA_TMR0Q_WRSMDR_DLY =  l_TGT2_ATTR_EFF_DRAM_CWL[l_def_PORT_INDEX] + 4 +
                    l_TGT2_ATTR_EFF_DRAM_TWTR_S[l_def_PORT_INDEX]

          MC01.PORT0.SRQ.MBA_TMR1Q =      // 0x701090c
              [0-3]   MBA_TMR1Q_RRSBG_DLY =   l_TGT2_ATTR_EFF_DRAM_TCCD_L[l_def_PORT_INDEX]
              [4-9]   MBA_TMR1Q_WRSBG_DLY =   l_TGT2_ATTR_EFF_DRAM_CWL[l_def_PORT_INDEX] + 4 +
                    l_TGT2_ATTR_EFF_DRAM_TWTR_L[l_def_PORT_INDEX]
              [10-15] MBA_TMR1Q_CFG_TFAW =    l_TGT2_ATTR_EFF_DRAM_TFAW[l_def_PORT_INDEX]
              [16-20] MBA_TMR1Q_CFG_TRCD =    l_TGT2_ATTR_EFF_DRAM_TRCD[l_def_PORT_INDEX]
              [21-25] MBA_TMR1Q_CFG_TRP =     l_TGT2_ATTR_EFF_DRAM_TRP[l_def_PORT_INDEX]
              [26-31] MBA_TMR1Q_CFG_TRAS =    l_TGT2_ATTR_EFF_DRAM_TRAS[l_def_PORT_INDEX]
              [41-47] MBA_TMR1Q_CFG_WR2PRE =  l_TGT2_ATTR_EFF_DRAM_CWL[l_def_PORT_INDEX] + 4 +
                    l_TGT2_ATTR_EFF_DRAM_TWR[l_def_PORT_INDEX]
              [48-51] MBA_TMR1Q_CFG_RD2PRE =  l_TGT2_ATTR_EFF_DRAM_TRTP[l_def_PORT_INDEX]
              [52-55] MBA_TMR1Q_TRRD =        l_TGT2_ATTR_EFF_DRAM_TRRD_S[l_def_PORT_INDEX]
              [56-59] MBA_TMR1Q_TRRD_SBG =    l_TGT2_ATTR_EFF_DRAM_TRRD_L[l_def_PORT_INDEX]
              [60-63] MBA_TMR1Q_CFG_ACT_TO_DIFF_RANK_DLY =
                MSS_FREQ_EQ_1866: 8
                MSS_FREQ_EQ_2133: 9
                MSS_FREQ_EQ_2400: 10
                MSS_FREQ_EQ_2666: 11

          MC01.PORT0.SRQ.MBA_WRQ0Q =      // 0x701090d
              [5]     MBA_WRQ0Q_CFG_WRQ_FIFO_MODE =               l_TGT1_ATTR_MSS_REORDER_QUEUE_SETTING
              [6]   MBA_WRQ0Q_CFG_DISABLE_WR_PG_MODE =            1
              [55-58] MBA_WRQ0Q_CFG_WRQ_ACT_NUM_WRITES_PENDING =  8

          MC01.PORT0.SRQ.MBA_RRQ0Q =      // 0x701090e
              [6]     MBA_RRQ0Q_CFG_RRQ_FIFO_MODE =             l_TGT1_ATTR_MSS_REORDER_QUEUE_SETTING
              [57-60] MBA_RRQ0Q_CFG_RRQ_ACT_NUM_READS_PENDING = 8

          MC01.PORT0.SRQ.MBA_FARB0Q =     // 0x7010913
              if (l_TGT3_ATTR_MSS_MRW_DRAM_2N_MODE == 0x02 || (l_TGT3_ATTR_MSS_MRW_DRAM_2N_MODE == 0x00 && l_TGT2_ATTR_MSS_VPD_MR_MC_2N_MODE_AUTOSET == 0x02))
                [17] MBA_FARB0Q_CFG_2N_ADDR =         1
              [38] MBA_FARB0Q_CFG_PARITY_AFTER_CMD =  1
              [61-63] MBA_FARB0Q_CFG_OPT_RD_SIZE =    3

          MC01.PORT0.SRQ.MBA_FARB1Q =     // 0x7010914
              [0-2]   MBA_FARB1Q_CFG_SLOT0_S0_CID = 0
              [3-5]   MBA_FARB1Q_CFG_SLOT0_S1_CID = 4
              [6-8]   MBA_FARB1Q_CFG_SLOT0_S2_CID = 2
              [9-11]  MBA_FARB1Q_CFG_SLOT0_S3_CID = 6
              if (l_def_SLOT0DRAM_STACK_HEIGHT == 8)
                [12-14] MBA_FARB1Q_CFG_SLOT0_S4_CID =   1
                [15-17] MBA_FARB1Q_CFG_SLOT0_S5_CID =   5
                [18-20] MBA_FARB1Q_CFG_SLOT0_S6_CID =   3
                [21-23] MBA_FARB1Q_CFG_SLOT0_S7_CID =   7
              else
                [12-14] MBA_FARB1Q_CFG_SLOT0_S4_CID =   0
                [15-17] MBA_FARB1Q_CFG_SLOT0_S5_CID =   4
                [18-20] MBA_FARB1Q_CFG_SLOT0_S6_CID =   2
                [21-23] MBA_FARB1Q_CFG_SLOT0_S7_CID =   6
              if (l_def_MASTER_RANKS_DIMM0 == 4)
                [12-14] MBA_FARB1Q_CFG_SLOT0_S4_CID =   4     // TODO: test if all slots with 1x4R DIMMs works with that
              [24-26] MBA_FARB1Q_CFG_SLOT1_S0_CID = 0
              [27-29] MBA_FARB1Q_CFG_SLOT1_S1_CID = 4
              [30-32] MBA_FARB1Q_CFG_SLOT1_S2_CID = 2
              [33-35] MBA_FARB1Q_CFG_SLOT1_S3_CID = 6
              if (l_def_SLOT1DRAM_STACK_HEIGHT == 8)
                [36-38] MBA_FARB1Q_CFG_SLOT1_S4_CID =   1
                [39-41] MBA_FARB1Q_CFG_SLOT1_S5_CID =   5
                [42-44] MBA_FARB1Q_CFG_SLOT1_S6_CID =   3
                [45-47] MBA_FARB1Q_CFG_SLOT1_S7_CID =   7
              else
                [36-38] MBA_FARB1Q_CFG_SLOT1_S4_CID =   0
                [39-41] MBA_FARB1Q_CFG_SLOT1_S5_CID =   4
                [42-44] MBA_FARB1Q_CFG_SLOT1_S6_CID =   2
                [45-47] MBA_FARB1Q_CFG_SLOT1_S7_CID =   6
              if (l_def_MASTER_RANKS_DIMM1 == 4)
                [36-38] MBA_FARB1Q_CFG_SLOT1_S4_CID =   4     // TODO: test if all slots with 1x4R DIMMs works with that

          MC01.PORT0.SRQ.MBA_FARB2Q =       // 0x7010915
              F(X) = (((X >> 4) & 0xc) | ((X >> 2) & 0x3))    // Bits 0,1,4,5 of X
              [0-3]   MBA_FARB2Q_CFG_RANK0_RD_ODT = F(ATTR_MSS_VPD_MT_ODT_RD[l_def_PORT_INDEX][0][0])
              [4-7]   MBA_FARB2Q_CFG_RANK1_RD_ODT = F(ATTR_MSS_VPD_MT_ODT_RD[l_def_PORT_INDEX][0][1])
              [8-11]  MBA_FARB2Q_CFG_RANK2_RD_ODT = F(ATTR_MSS_VPD_MT_ODT_RD[l_def_PORT_INDEX][0][2])
              [12-15] MBA_FARB2Q_CFG_RANK3_RD_ODT = F(ATTR_MSS_VPD_MT_ODT_RD[l_def_PORT_INDEX][0][3])
              [16-19] MBA_FARB2Q_CFG_RANK4_RD_ODT = F(ATTR_MSS_VPD_MT_ODT_RD[l_def_PORT_INDEX][1][0])
              [20-23] MBA_FARB2Q_CFG_RANK5_RD_ODT = F(ATTR_MSS_VPD_MT_ODT_RD[l_def_PORT_INDEX][1][1])
              [24-27] MBA_FARB2Q_CFG_RANK6_RD_ODT = F(ATTR_MSS_VPD_MT_ODT_RD[l_def_PORT_INDEX][1][2])
              [28-31] MBA_FARB2Q_CFG_RANK7_RD_ODT = F(ATTR_MSS_VPD_MT_ODT_RD[l_def_PORT_INDEX][1][3])
              [32-35] MBA_FARB2Q_CFG_RANK0_WR_ODT = F(ATTR_MSS_VPD_MT_ODT_WR[l_def_PORT_INDEX][0][0])
              [36-39] MBA_FARB2Q_CFG_RANK1_WR_ODT = F(ATTR_MSS_VPD_MT_ODT_WR[l_def_PORT_INDEX][0][1])
              [40-43] MBA_FARB2Q_CFG_RANK2_WR_ODT = F(ATTR_MSS_VPD_MT_ODT_WR[l_def_PORT_INDEX][0][2])
              [44-47] MBA_FARB2Q_CFG_RANK3_WR_ODT = F(ATTR_MSS_VPD_MT_ODT_WR[l_def_PORT_INDEX][0][3])
              [48-51] MBA_FARB2Q_CFG_RANK4_WR_ODT = F(ATTR_MSS_VPD_MT_ODT_WR[l_def_PORT_INDEX][1][0])
              [52-55] MBA_FARB2Q_CFG_RANK5_WR_ODT = F(ATTR_MSS_VPD_MT_ODT_WR[l_def_PORT_INDEX][1][1])
              [56-59] MBA_FARB2Q_CFG_RANK6_WR_ODT = F(ATTR_MSS_VPD_MT_ODT_WR[l_def_PORT_INDEX][1][2])
              [60-63] MBA_FARB2Q_CFG_RANK7_WR_ODT = F(ATTR_MSS_VPD_MT_ODT_WR[l_def_PORT_INDEX][1][3])

          MC01.PORT0.SRQ.PC.MBAREF0Q =      // 0x7010932
              [5-7]   MBAREF0Q_CFG_REFRESH_PRIORITY_THRESHOLD = 3
              [8-18]  MBAREF0Q_CFG_REFRESH_INTERVAL =           l_def_REFRESH_INTERVAL
              [30-39] MBAREF0Q_CFG_TRFC =                       l_TGT2_ATTR_EFF_DRAM_TRFC[l_def_PORT_INDEX]
              [40-49] MBAREF0Q_CFG_REFR_TSV_STACK =             l_TGT2_ATTR_EFF_DRAM_TRFC_DLR[l_def_PORT_INDEX]
              [50-60] MBAREF0Q_CFG_REFR_CHECK_INTERVAL =        (l_def_REFRESH_INTERVAL * l_def_NUM_RANKS * 6) / 5

          MC01.PORT0.SRQ.PC.MBARPC0Q =      // 0x7010934
              [6-10]  MBARPC0Q_CFG_PUP_AVAIL =
                MSS_FREQ_EQ_1866: 6
                MSS_FREQ_EQ_2133: 7
                MSS_FREQ_EQ_2400: 8
                MSS_FREQ_EQ_2666: 9
              [11-15] MBARPC0Q_CFG_PDN_PUP =
                MSS_FREQ_EQ_1866: 5
                MSS_FREQ_EQ_2133: 6
                MSS_FREQ_EQ_2400: 6
                MSS_FREQ_EQ_2666: 7
              [16-20] MBARPC0Q_CFG_PUP_PDN =
                MSS_FREQ_EQ_1866: 5
                MSS_FREQ_EQ_2133: 6
                MSS_FREQ_EQ_2400: 6
                MSS_FREQ_EQ_2666: 7
              [21] MBARPC0Q_RESERVED_21 =         // MCP_PORT0_SRQ_PC_MBARPC0Q_CFG_QUAD_RANK_ENC
                (l_def_MASTER_RANKS_DIMM0 == 4): 1
                (l_def_MASTER_RANKS_DIMM0 != 4): 0

          MC01.PORT0.SRQ.PC.MBASTR0Q =      // 0x7010935
              [12-16] MBASTR0Q_CFG_TCKESR = 5
              [17-21] MBASTR0Q_CFG_TCKSRE =
                MSS_FREQ_EQ_1866: 10
                MSS_FREQ_EQ_2133: 11
                MSS_FREQ_EQ_2400: 12
                MSS_FREQ_EQ_2666: 14
              [22-26] MBASTR0Q_CFG_TCKSRX =
                MSS_FREQ_EQ_1866: 10
                MSS_FREQ_EQ_2133: 11
                MSS_FREQ_EQ_2400: 12
                MSS_FREQ_EQ_2666: 14
              [27-37] MBASTR0Q_CFG_TXSDLL =
                MSS_FREQ_EQ_1866: 597
                MSS_FREQ_EQ_2133: 768
                MSS_FREQ_EQ_2400: 768
                MSS_FREQ_EQ_2666: 939
              [46-56] MBASTR0Q_CFG_SAFE_REFRESH_INTERVAL = l_def_REFRESH_INTERVAL

          MC01.PORT0.ECC64.SCOM.RECR =      // 0x7010a0a
              [16-18] MBSECCQ_VAL_TO_DATA_DELAY =
                l_TGT4_ATTR_MC_SYNC_MODE == 1:  5
                l_def_mn_freq_ratio < 915:      3
                l_def_mn_freq_ratio < 1150:     4
                l_def_mn_freq_ratio < 1300:     5
                l_def_mn_freq_ratio >= 1300:    6
              [19]    MBSECCQ_DELAY_VALID_1X =  0
              [20-21] MBSECCQ_NEST_VAL_TO_DATA_DELAY =
                l_TGT4_ATTR_MC_SYNC_MODE == 1:  1
                l_def_mn_freq_ratio < 1040:     1
                l_def_mn_freq_ratio < 1150:     0
                l_def_mn_freq_ratio < 1215:     1
                l_def_mn_freq_ratio < 1300:     0
                l_def_mn_freq_ratio < 1400:     1
                l_def_mn_freq_ratio >= 1400:    0
              [22]    MBSECCQ_DELAY_NONBYPASS =
                l_TGT4_ATTR_MC_SYNC_MODE == 1:  0
                l_def_mn_freq_ratio < 1215:     0
                l_def_mn_freq_ratio >= 1215:    1
              [40]    MBSECCQ_RESERVED_36_43 =        // MCP_PORT0_ECC64_ECC_SCOM_MBSECCQ_BYPASS_TENURE_3
                l_TGT4_ATTR_MC_SYNC_MODE == 1:  0
                l_TGT4_ATTR_MC_SYNC_MODE == 0:  1

          MC01.PORT0.ECC64.SCOM.DBGR =      // 0x7010a0b
              [9]     DBGR_ECC_WAT_ACTION_SELECT =  0
              [10-11] DBGR_ECC_WAT_SOURCE =         0

          MC01.PORT0.WRITE.WRTCFG =         // 0x7010a38
              [9] = 1     // MCP_PORT0_WRITE_NEW_WRITE_64B_MODE   this is marked as RO const 0 for bits 8-63 in docs!

      - mca thermal throttle scominit
        mss::mc::thermal_throttle_scominit(MCA)
          set_pwr_cntrl_reg(MCA)
            MC01.PORT0.SRQ.PC.MBARPC0Q =      // 0x7010934
              [3-5]   MBARPC0Q_CFG_MIN_MAX_DOMAINS =                    0
              [22]    MBARPC0Q_CFG_MIN_DOMAIN_REDUCTION_ENABLE =
                ATTR_MSS_MRW_POWER_CONTROL_REQUESTED == PD_AND_STR_OFF: 0
                else:                                                   1
              [23-32] MBARPC0Q_CFG_MIN_DOMAIN_REDUCTION_TIME =          959
          set_str_reg(MCA)
            MC01.PORT0.SRQ.PC.MBASTR0Q =      // 0x7010935
              [0]     MBASTR0Q_CFG_STR_ENABLE =
                ATTR_MSS_MRW_POWER_CONTROL_REQUESTED == PD_AND_STR:           1
                ATTR_MSS_MRW_POWER_CONTROL_REQUESTED == PD_AND_STR_CLK_STOP:  1
                ATTR_MSS_MRW_POWER_CONTROL_REQUESTED == POWER_DOWN:           0
                ATTR_MSS_MRW_POWER_CONTROL_REQUESTED == PD_AND_STR_OFF:       0
              [2-11]  MBASTR0Q_CFG_ENTER_STR_TIME =                           1023
          set_nm_support(MCA)
            MC01.PORT1.SRQ.MBA_FARB3Q =       // 0x7010956
              [0-14]  MBA_FARB3Q_CFG_NM_N_PER_SLOT = ATTR_MSS_RUNTIME_MEM_THROTTLED_N_COMMANDS_PER_SLOT[mss::index(MCA)]
              [15-30] MBA_FARB3Q_CFG_NM_N_PER_PORT = ATTR_MSS_RUNTIME_MEM_THROTTLED_N_COMMANDS_PER_PORT[mss::index(MCA)]
              [31-44] MBA_FARB3Q_CFG_NM_M =          ATTR_MSS_MRW_MEM_M_DRAM_CLOCKS
              [45-47] MBA_FARB3Q_CFG_NM_RAS_WEIGHT = 0
              [48-50] MBA_FARB3Q_CFG_NM_CAS_WEIGHT = 1
              // Set to disable permanently due to hardware design bug (HW403028) that won't be changed
              [53]    MBA_FARB3Q_CFG_NM_CHANGE_AFTER_SYNC = 0
          set_safemode_throttles(MCA)
            MC01.PORT1.SRQ.MBA_FARB4Q =       // 0x7010957
              [27-41] MBA_FARB4Q_EMERGENCY_N = ATTR_MSS_RUNTIME_MEM_THROTTLED_N_COMMANDS_PER_PORT[mss::index(MCA)]  // BUG? var name says per_slot...
              [42-55] MBA_FARB4Q_EMERGENCY_M = ATTR_MSS_MRW_MEM_M_DRAM_CLOCKS
    > }
    - phy scominit // can do even when no DIMMs
      p9n_ddrphy_scom(MCA, MCBIST.getParent<PROC_CHIP>)
        --------------------------------------------------------
        IOM0.DDRPHY_DP16_DLL_VREG_CONTROL0_P0_{0,1,2,3,4} =     // 0x8000002a0701103f, +0x0400_0000_0000   // this seems strange...
            [48-50] RXREG_VREG_COMPCON_DC = 3
            [52-59] = 0x74:
                    [53-55] RXREG_VREG_DRVCON_DC =  0x7
                    [56-58] RXREG_VREG_REF_SEL_DC = 0x2
            [62-63] = 0:
                    [62] DLL_DRVREN_MODE =      POWER8 mode (thermometer style, enabling all drivers up to the one that is used)
                    [63] DLL_CAL_CKTS_ACTIVE =  After VREG calibration, some analog circuits are powered down

        IOM0.DDRPHY_DP16_DLL_VREG_CONTROL1_P0_{0,1,2,3,4} =     // 0x8000002b0701103f, +0x0400_0000_0000   // this seems strange...
            [48-50] RXREG_VREG_COMPCON_DC = 3
            [52-59] = 0x74:
                    [53-55] RXREG_VREG_DRVCON_DC =  0x7
                    [56-58] RXREG_VREG_REF_SEL_DC = 0x2
            [62-63] = 0:
                    [62] DLL_DRVREN_MODE =      POWER8 mode (thermometer style, enabling all drivers up to the one that is used)
                    [63] DLL_CAL_CKTS_ACTIVE =  After VREG calibration, some analog circuits are powered down

        IOM0.DDRPHY_DP16_WRCLK_PR_P0_{0,1,2,3,4} =              // 0x800000740701103f, +0x0400_0000_0000
            // For zero delay simulations, or simulations where the delay of the SysClk tree and the WrClk tree are equal, set this field to 60h
            [49-55] TSYS_WRCLK = 0x60

        IOM0.DDRPHY_DP16_IO_TX_CONFIG0_P0_{0,1,2,3,4} =         // 0x800000750701103f, +0x0400_0000_0000
            [48-51] STRENGTH =                    0x4 // 2400 MT/s
            [52]    DD2_RESET_READ_FIX_DISABLE =  0   // Enable the DD2 function to remove the register reset on read feature on status registers

        IOM0.DDRPHY_DP16_DLL_CONFIG1_P0_{0,1,2,3,4} =           // 0x800000770701103f, +0x0400_0000_0000
            [48-63] = 0x0006:
                    [48-51] HS_DLLMUX_SEL_0_0_3 = 0
                    [53-56] HS_DLLMUX_SEL_1_0_3 = 0
                    [61]    S0INSDLYTAP =         1 // For proper functional operation, this bit must be 0b
                    [62]    S1INSDLYTAP =         1 // For proper functional operation, this bit must be 0b

        IOM0.DDRPHY_DP16_IO_TX_FET_SLICE_P0_{0,1,2,3,4} =       // 0x800000780701103f, +0x0400_0000_0000
            [48-63] = 0x7f7f:
                    [59-55] EN_SLICE_N_WR = 0x7f
                    [57-63] EN_SLICE_P_WR = 0x7f
        ----------------------------------------------------------------

a)      IOM0.DDRPHY_ADR_BIT_ENABLE_P0_ADR0 =        // 0x800040000701103f     // can all 'a)' be reordered and merged into loop?
            [48-63] = 0xffff

a)      IOM0.DDRPHY_ADR_BIT_ENABLE_P0_ADR1 =        // 0x800044000701103f
            [48-63] = 0xffff

        IOM0.DDRPHY_ADR_DIFFPAIR_ENABLE_P0_ADR1 =   // 0x800044010701103f
            [48-63] = 0x5000:
                    [49] DI_ADR2_ADR3: 1 = Lanes 2 and 3 are a differential clock pair
                    [51] DI_ADR6_ADR7: 1 = Lanes 6 and 7 are a differential clock pair

        IOM0.DDRPHY_ADR_DELAY1_P0_ADR1 =            // 0x800044050701103f
            [48-63] = 0x4040:
                    [49-55] ADR_DELAY2 = 0x40
                    [57-63] ADR_DELAY3 = 0x40

        IOM0.DDRPHY_ADR_DELAY3_P0_ADR1 =            // 0x800044070701103f
            [48-63] = 0x4040:
                    [49-55] ADR_DELAY6 = 0x40
                    [57-63] ADR_DELAY7 = 0x40

a)      IOM0.DDRPHY_ADR_BIT_ENABLE_P0_ADR2 =        // 0x800048000701103f
            [48-63] = 0xffff

a)      IOM0.DDRPHY_ADR_BIT_ENABLE_P0_ADR3 =        // 0x80004c000701103f
            [48-63] = 0xffff

        ------------------------------------------------
        IOM0.DDRPHY_ADR_DLL_VREG_CONFIG_1_P0_ADR32S{0,1} =    // 0x800080310701103f, +0x0400_0000_0000
            [48-63] = 0x0008:
                    [48-51] HS_DLLMUX_SEL_0_3 = 0
                    [59-62] STRENGTH =          4 // 2400 MT/s

        IOM0.DDRPHY_ADR_MCCLK_WRCLK_PR_STATIC_OFFSET_P0_ADR32S{0,1} =     // 0x800080330701103f, +0x0400_0000_0000
            [48-63] = 0x6000
                      // For zero delay simulations, or simulations where the delay of the SysClk tree and the WrClk tree are equal, set this field to 60h
                      [49-55] TSYS_WRCLK = 0x60

        IOM0.DDRPHY_ADR_DLL_VREG_CONTROL_P0_ADR32S{0,1} =     // 0x8000803d0701103f, +0x0400_0000_0000
            [48-50] RXREG_VREG_COMPCON_DC =         3
            [52-59] = 0x74:
                    [53-55] RXREG_VREG_DRVCON_DC =  0x7
                    [56-58] RXREG_VREG_REF_SEL_DC = 0x2
            [63] DLL_CAL_CKTS_ACTIVE =  0   // After VREG calibration, some analog circuits are powered down
        ------------------------------------------------

        IOM0.DDRPHY_PC_CONFIG0_P0 =             // 0x8000c00c0701103f
            [48-63] = 0x0202:
                    [48-51] PDA_ENABLE_OVERRIDE =     0
                    [52]    2TCK_PREAMBLE_ENABLE =    0
                    [53]    PBA_ENABLE =              0
                    [54]    DDR4_CMD_SIG_REDUCTION =  1
                    [55]    SYSCLK_2X_MEMINTCLKO =    0
                    [56]    RANK_OVERRIDE =           0
                    [57-59] RANK_OVERRIDE_VALUE =     0
                    [60]    LOW_LATENCY =             0
                    [61]    DDR4_IPW_LOOP_DIS =       0
                    [62]    DDR4_VLEVEL_BANK_GROUP =  1
                    [63]    VPROTH_PSEL_MODE =        0

  p9n_mcbist_scom(MCBIST)
    MC01.MCBIST.MBA_SCOMFIR.WATCFG0AQ =         // 0x7012380
        [0-47]  WATCFG0AQ_CFG_WAT_EVENT_SEL =  0x400000000000

    MC01.MCBIST.MBA_SCOMFIR.WATCFG0BQ =         // 0x7012381
        [0-43]  WATCFG0BQ_CFG_WAT_MSKA =  0x3fbfff
        [44-60] WATCFG0BQ_CFG_WAT_CNTL =  0x10000

    MC01.MCBIST.MBA_SCOMFIR.WATCFG0DQ =         // 0x7012383
        [0-43]  WATCFG0DQ_CFG_WAT_PATA =  0x80200004000

    MC01.MCBIST.MBA_SCOMFIR.WATCFG3AQ =         // 0x701238f
        [0-47]  WATCFG3AQ_CFG_WAT_EVENT_SEL = 0x800000000000

    MC01.MCBIST.MBA_SCOMFIR.WATCFG3BQ =         // 0x7012390
        [0-43]  WATCFG3BQ_CFG_WAT_MSKA =  0xfffffffffff
        [44-60] WATCFG3BQ_CFG_WAT_CNTL =  0x10400

    MC01.MCBIST.MBA_SCOMFIR.MCBCFGQ =           // 0x70123e0
        [36]    MCBCFGQ_CFG_LOG_COUNTS_IN_TRACE = 0

    MC01.MCBIST.MBA_SCOMFIR.DBGCFG0Q =          // 0x70123e8
        [0]     DBGCFG0Q_CFG_DBG_ENABLE =         1
        [23-33] DBGCFG0Q_CFG_DBG_PICK_MCBIST01 =  0x780

    MC01.MCBIST.MBA_SCOMFIR.DBGCFG1Q =          // 0x70123e9
        [0]     DBGCFG1Q_CFG_WAT_ENABLE = 1

    MC01.MCBIST.MBA_SCOMFIR.DBGCFG2Q =          // 0x70123ea
        [0-19]  DBGCFG2Q_CFG_WAT_LOC_EVENT0_SEL = 0x10000
        [20-39] DBGCFG2Q_CFG_WAT_LOC_EVENT1_SEL = 0x08000

    MC01.MCBIST.MBA_SCOMFIR.DBGCFG3Q =          // 0x70123eb
        [20-22] DBGCFG3Q_CFG_WAT_GLOB_EVENT0_SEL =      0x4
        [23-25] DBGCFG3Q_CFG_WAT_GLOB_EVENT1_SEL =      0x4
        [37-40] DBGCFG3Q_CFG_WAT_ACT_SET_SPATTN_PULSE = 0x4

  - Initialize via scoms for non-static PHY items
    mss::phy_scominit(MCBIST)         // Freq is set per MCBIST, can we get better granularity?
      reset_io_tx_config0
        // These registers were already modified by p9n_ddrphy_scom. Can we set proper strength already there?
        IOM0.DDRPHY_DP16_IO_TX_CONFIG0_P0_{0,1,2,3,4} =     // 0x800000750701103f, +0x0400_0000_0000
            [48-51] STRENGTH =
                MSS_FREQ_EQ_1866: 1
                MSS_FREQ_EQ_2133: 2
                MSS_FREQ_EQ_2400: 4
                MSS_FREQ_EQ_2666: 8

      reset_dll_vreg_config1
        // These registers were already modified by p9n_ddrphy_scom. Can we set proper strength already there?
        IOM0.DDRPHY_ADR_DLL_VREG_CONFIG_1_P0_ADR32S{0,1} =  // 0x800080310701103f, +0x0400_0000_0000
            [59-62] STRENGTH =
                MSS_FREQ_EQ_1866: 1
                MSS_FREQ_EQ_2133: 2
                MSS_FREQ_EQ_2400: 4
                MSS_FREQ_EQ_2666: 8

      for each functional MCA:
        if (count_dimm(MCA) == 0) continue
        set_rank_pairs
          // TODO: assumes non-LR DIMMs (platform wiki) and no ATTR_EFF_RANK_GROUP_OVERRIDE (default in
          // hb_temp_defaults.xml), add if needed (get_rank_pair_assignments)
          IOM0.DDRPHY_PC_RANK_PAIR0_P0 =      // 0x8000C0020701103F
              // TODO: re-check whether these numbers are correct. Some assumptions and simplifications were made here
              [48-63] = 0x1537 & F[rank_count]:     // F = {0, 0xf000, 0xf0f0, 0xfff0, 0xffff}
                  [48-50] RANK_PAIR0_PRI = 0
                  [51]    RANK_PAIR0_PRI_V = 1: if (rank_count >= 1)
                  [52-54] RANK_PAIR0_SEC = 2
                  [55]    RANK_PAIR0_SEC_V = 1: if (rank_count >= 3)
                  [56-58] RANK_PAIR1_PRI = 1
                  [59]    RANK_PAIR1_PRI_V = 1: if (rank_count >= 2)
                  [60-62] RANK_PAIR1_SEC = 3
                  [63]    RANK_PAIR1_SEC_V = 1: if (rank_count == 4)
          IOM0.DDRPHY_PC_RANK_PAIR1_P0 =      // 0x8000C0030701103F
              [48-63] = 0x1537 & F[rank_count]:     // F = {0, 0xf000, 0xf0f0, 0xfff0, 0xffff}
                  [48-50] RANK_PAIR2_PRI = 0
                  [51]    RANK_PAIR2_PRI_V = 1: if (rank_count >= 1)
                  [52-54] RANK_PAIR2_SEC = 2
                  [55]    RANK_PAIR2_SEC_V = 1: if (rank_count >= 3)
                  [56-58] RANK_PAIR3_PRI = 1
                  [59]    RANK_PAIR3_PRI_V = 1: if (rank_count >= 2)
                  [60-62] RANK_PAIR3_SEC = 3
                  [63]    RANK_PAIR3_SEC_V = 1: if (rank_count == 4)
          IOM0.DDRPHY_PC_RANK_PAIR2_P0 =      // 0x8000C0300701103F
              [48-63] = 0
          IOM0.DDRPHY_PC_RANK_PAIR3_P0 =      // 0x8000C0310701103F
              [48-63] = 0
          IOM0.DDRPHY_PC_CSID_CFG_P0 =        // 0x8000C0330701103F
                  [0-63]  0xf000:
                      [48]  CS0_INIT_CAL_VALUE = 1
                      [49]  CS1_INIT_CAL_VALUE = 1
                      [50]  CS2_INIT_CAL_VALUE = 1
                      [51]  CS3_INIT_CAL_VALUE = 1
          IOM0.DDRPHY_PC_MIRROR_CONFIG_P0 =   // 0x8000C0110701103F
                  [all] = 0
                  // A rank is mirrored if all are true:
                  //  - the rank is valid (RANK_PAIRn_XXX_V ==    1)
                  //  - the rank is odd   (RANK_PAIRn_XXX[LSB] == 1)
                  //  - the mirror mode attribute is set for the rank's DIMM (set in
                  //    src/import/chips/p9/procedures/hwp/memory/lib/dimm/eff_dimm.C from SPD[136])
                  //  - We are not in quad encoded mode (so master ranks <= 2)
                  [48]    ADDR_MIRROR_RP0_PRI
                          ...
                  [55]    ADDR_MIRROR_RP3_SEC
                  [58]    ADDR_MIRROR_A3_A4 = 1
                  [59]    ADDR_MIRROR_A5_A6 = 1
                  [60]    ADDR_MIRROR_A7_A8 = 1
                  [61]    ADDR_MIRROR_A11_A13 = 1
                  [62]    ADDR_MIRROR_BA0_BA1 = 1
                  [63]    ADDR_MIRROR_BG0_BG1 = 1
          IOM0.DDRPHY_PC_RANK_GROUP_EXT_P0 =  // 0x8000C0350701103F
                  [all] = 0
                  // Same rules as above
                  [48]    ADDR_MIRROR_RP0_TER
                          ...
                  [55]    ADDR_MIRROR_RP3_QUA

        reset_data_bit_enable
          IOM0.DDRPHY_DP16_DQ_BIT_ENABLE0_P0_{0,1,2,3} =    // 0x800000000701103F, +0x0400_0000_0000
                  [all] = 0
                  [48-63] DATA_BIT_ENABLE_0_15 = 0xffff
          IOM0.DDRPHY_DP16_DQ_BIT_ENABLE0_P0_4 =            // 0x800010000701103F
                  [all] = 0
                  [48-63] DATA_BIT_ENABLE_0_15 = 0xff00
          IOM0.DDRPHY_DP16_DFT_PDA_CONTROL_P0_{0,1,2,3,4} = // 0x800000010701103F, +0x0400_0000_0000
                  // This reg is named MCA_DDRPHY_DP16_DATA_BIT_ENABLE1_P0_n in the code.
                  // BUG? Spec says bits [48-55] must remain at reset value, but code disagrees. Follow the code for now...
                  [all] = 0

        reset_bad_bits
          // TODO: this disables bad DQ (and DQS if all DQs are dead) bits, based on data saved in NVRAM during earlier
          // trainings. For now assume there are no bad DQ bits.
          // Regs touched: IOM0.DDRPHY_DP16_DQ_BIT_DISABLE_RP{0-3}_P0_{0-4}, IOM0.DDRPHY_DP16_DQS_BIT_DISABLE_RP{0-3}_P0_{0-4}
          // - Is it enough to leave reset values or do we have to set them to 0 explicitly?
          //   - Those bits are set to 1 during training for failed pins in calibration steps
          // - Can DQ(S) bits be "resurrected" later in the training or is the NVRAM data final?

        get_rank_pairs(MCA, l_pairs)
          // l_pairs holds 4 bits of useful information (rank 0,1,2,3 exists or not). It uses up to 4*sizeof(uint64) bytes
          // for this (plus vector overhead) when passed as an argument; a vector of 5 vectors of 5 such 4-element vectors
          // is used in const data section for this. There is also a function which main task is to convert 4/5 to 2/3 and
          // skip empty elements before returning final vector, so static const data cannot be reused.
          // TL;DR: this function and its data is a waste of space
          // See set_rank_pairs above, this function uses different path to get almost identical result. Why this overcomplication?
          l_pairs = vector of {0, 1, 2, 3}, skip entry(-ies) if rank count is <2, e.g.
                  {0,2}   - 1 ranks DIMM0, 1 ranks DIMM1
                  {0,2,3} - 1 ranks DIMM0, 2(3,4) ranks DIMM1
                  {0,1}   - 2(3,4) ranks DIMM0, 0 ranks DIMM1 etc.

        // The following two functions specify which clock/strobes pins (16-23) of DP16 are used to capture outgoing/incoming
        // data on which data pins (0-16). Those will eventually arrive to DIMM as DQS and DQ, respectively. The mapping must
        // be the same for write and read. It will be used after DRAM training to discover which nibbles failed.
        // TODO: are those mappings determined by hardware or can we change them to uniform mapping for all DIMMs/ranks?
        // Schematics don't show what happens inside CPU, i.e. whether these DP16 pins are multiplexed (and configurable by
        // these registers) or hardwired between DP16 and external CPU pins.
        reset_write_clock_enable(MCA, l_pairs)    // Merge with next function
          for each rp in l_pairs:
            wrckl_enable =        // src/import/chips/p9/procedures/hwp/memory/lib/phy/dp16.C
              wrclk_enable_no_spare_x4[0]: if DRAM width = x4
              wrclk_enable_no_spare_x8[MCA.pos]: if DRAM width = x8
            for each reg in wrclk_enable:
              reg.first + (rp << 40) =    // IOM0.DDRPHY_DP16_WRCLK_EN_RP<rp>_P0_{0-4}            0x80000<rp>050701103F, +0x0400_0000_0000
                    [48-63] QUADx_CLKyy = reg.second  // different for each reg/port, but the same for read and write

        reset_read_clock_enable(MCA, l_pairs)
          for each rp in l_pairs:
            rdckl_enable =        // src/import/chips/p9/procedures/hwp/memory/lib/phy/dp16.C
              rdclk_enable_no_spare_x4[0]: if DRAM width = x4
              rdclk_enable_no_spare_x8[MCA.pos]: if DRAM width = x8
            for each reg in rdclk_enable:
              reg.first + (rp << 40) =    // IOM0.DDRPHY_DP16_READ_CLOCK_RANK_PAIR<rp>_P0_{0-4}   0x80000<rp>040701103F, +0x0400_0000_0000
                    [48-63] QUADx_CLKyy = reg.second  // different for each reg/port, but the same for read and write

        reset_rd_vref
          //       RD_VREF_DVDD * (100000 - ATTR_MSS_VPD_MT_VREF_MC_RD) / RD_VREF_DAC_STEP
          vref_bf =     12      * (100000 - ATTR_MSS_VPD_MT_VREF_MC_RD) / 6500
          IOM0.DDRPHY_DP16_RD_VREF_DAC_{0-7}_P0_{0-3},            // addresses are not regular for DAC
          IOM0.DDRPHY_DP16_RD_VREF_DAC_{0-3}_P0_4 =               // only half of last DP16 is used
                [49-55] BIT0_VREF_DAC = vref_bf
                [57-63] BIT1_VREF_DAC = vref_bf
          IOM0.DDRPHY_DP16_RD_VREF_CAL_EN_P0_{0-4}                // 0x800000760701103F, +0x0400_0000_0000
                [48-63] VREF_CAL_EN = 0xffff          // enable = 0xffff, disable = 0x0000

        pc::reset
          // IOM0.DDRPHY_PC_CONFIG0_P0 (0x8000c00c0701103f) has been reset in p9n_ddrphy_scom()
          IOM0.DDRPHY_PC_CONFIG1_P0 =             // 0x8000c00d0701103f
                [48-51] WRITE_LATENCY_OFFSET =  ATTR_MSS_EFF_DPHY_WLO
                [52-55] READ_LATENCY_OFFSET =   ATTR_MSS_EFF_DPHY_RLO
                          // If the MRW states 'auto' we use what's in VPD, otherwise we use what's in the MRW
                          +1: if 2N mode (ATTR_MSS_VPD_MR_MC_2N_MODE_AUTOSET, ATTR_MSS_MRW_DRAM_2N_MODE)  // Gear-down mode in JEDEC
                // Assume no LRDIMM
                [59-61] MEMORY_TYPE =           0x5     // 0x7 for LRDIMM
                [62]    DDR4_LATENCY_SW =       1

          IOM0.DDRPHY_PC_ERROR_STATUS0_P0 =       // 0x8000C0120701103F
                [all]   0

          IOM0.DDRPHY_PC_INIT_CAL_ERROR_P0 =      // 0x8000C0180701103F
                [all]   0

        wc::reset
          IOM0.DDRPHY_WC_CONFIG0_P0 =             // 0x8000CC000701103F
                [all]   0
                // BUG? Mismatch between comment (-,-), code (+,+) and docs (-,+) for operations inside 'max'
                [48-55] TWLO_TWLOE =        12 + max((twldqsen - tmod), (twlo + twlow))
                                     + longest DQS delay in clocks (rounded up) + longest DQ delay in clocks (rounded up)
                [56]    WL_ONE_DQS_PULSE =  1
                [57-62] FW_WR_RD =          0x20      // "# dd0 = 17 clocks, now 32 from SWyatt"
                [63]    CUSTOM_INIT_WRITE = 1         // set to a 1 to get proper values for RD VREF

          IOM0.DDRPHY_WC_CONFIG1_P0 =             // 0x8000CC010701103F
                [all]   0
                [48-51] BIG_STEP =          7
                [52-54] SMALL_STEP =        0
                [55-60] WR_PRE_DLY =        0x2a (42)

          IOM0.DDRPHY_WC_CONFIG2_P0 =             // 0x8000CC020701103F
                [all]   0
                [48-51] NUM_VALID_SAMPLES = 5
                [52-57] FW_RD_WR =          max(tWTR + 11, AL + tRTP + 3)
                [58-61] IPW_WR_WR =         5     // results in 24 clock cycles

          IOM0.DDRPHY_WC_CONFIG3_P0 =             // 0x8000CC050701103F
                [all]   0
                [55-60] MRS_CMD_DQ_OFF =    0x3f

          IOM0.DDRPHY_WC_RTT_WR_SWAP_ENABLE_P0    // 0x8000CC060701103F
                [48]    WL_ENABLE_RTT_SWAP =            0
                [49]    WR_CTR_ENABLE_RTT_SWAP =        0
                [48]    WR_CTR_VREF_COUNTER_RESET_VAL = 150ns converted to clock cycles (depends on the frequency)  // JESD79-4C Table 67

        rc::reset
          IOM0.DDRPHY_RC_CONFIG0_P0               // 0x8000C8000701103F
                [all]   0
                [48-51] GLOBAL_PHY_OFFSET =
                            MSS_FREQ_EQ_1866: 12
                            MSS_FREQ_EQ_2133: 12
                            MSS_FREQ_EQ_2400: 13
                            MSS_FREQ_EQ_2666: 13
                [62]    PERFORM_RDCLK_ALIGN = 1

          IOM0.DDRPHY_RC_CONFIG1_P0               // 0x8000C8010701103F
                [all]   0

          IOM0.DDRPHY_RC_CONFIG2_P0               // 0x8000C8020701103F
                [all]   0
                [48-52] CONSEC_PASS = 8
                [57-58] 3                   // not documented, BURST_WINDOW?

          IOM0.DDRPHY_RC_CONFIG3_P0               // 0x8000C8070701103F
                [all]   0
                [51-54] COARSE_CAL_STEP_SIZE = 4  // 5/128

          IOM0.DDRPHY_RC_RDVREF_CONFIG0_P0 =      // 0x8000C8090701103F
                [all]   0
                [48-63] WAIT_TIME =
                            0xffff          // as slow as possible, or use calculation from vref_guess_time(), or:
                            MSS_FREQ_EQ_1866: 0x0804
                            MSS_FREQ_EQ_2133: 0x092a
                            MSS_FREQ_EQ_2400: 0x0a50
                            MSS_FREQ_EQ_2666: 0x0b74    // use this value for all freqs maybe?

          IOM0.DDRPHY_RC_RDVREF_CONFIG1_P0 =      // 0x8000C80A0701103F
                [all]   0
                [48-55] CMD_PRECEDE_TIME =  (AL + CL + 15)
                [56-59] MPR_LOCATION =      4     // "From R. King."

        seq::reset
          IOM0.DDRPHY_SEQ_CONFIG0_P0 =            // 0x8000C4020701103F
                [all]   0
                [49]    TWO_CYCLE_ADDR_EN =
                            2N mode:                1
                            else:                   0
                [54]    DELAYED_PAR = 1
                [62]    PAR_A17_MASK =
                            16Gb x4 configuration:  0
                            else:                   1

          // All log2 values in timing registers are rounded up (I think...)
          IOM0.DDRPHY_SEQ_MEM_TIMING_PARAM0_P0 =  // 0x8000C4120701103F
                [all]   0
                [48-51] TMOD_CYCLES = 5           // log2(max(tMRD, tMOD)) = log2(24), JEDEC tables 169 and 170 and section 13.5
                [52-55] TRCD_CYCLES = log2(tRCD)  // 12.5-15ns, depending on freq either 4 or 5, JEDEC tables 144-150 and s. 13.5
                [56-59] TRP_CYCLES =  log2(tRP)   // 12.5-15ns, depending on freq either 4 or 5, JEDEC tables 144-150 and s. 13.5
                [52-55] TRFC_CYCLES = log2(tRFC)  // different DIMMs on one port may have different tRFCs, use max?

          IOM0.DDRPHY_SEQ_MEM_TIMING_PARAM1_P0 =  // 0x8000C4130701103F
                [all]   0
                [48-51] TZQINIT_CYCLES =  10      // log2(1024), JEDEC tables 169 and 170
                [52-55] TZQCS_CYCLES =    7       // log2(128), JEDEC tables 169 and 170
                [56-59] TWLDQSEN_CYCLES = 5       // log2(25) rounded up, JEDEC tables 169 and 170
                [60-63] TWRMRD_CYCLES =   6       // log2(40) rounded up, JEDEC tables 169 and 170

          IOM0.DDRPHY_SEQ_MEM_TIMING_PARAM2_P0 =  // 0x8000C4140701103F
                [all]   0
                [48-51] TODTLON_OFF_CYCLES =  log2(CWL + AL + PL - 2)
                [52-63] =                     0x777     // "Reset value of SEQ_TIMING2 is lucky 7's"

          IOM0.DDRPHY_SEQ_RD_WR_DATA0_P0 =        // 0x8000C4000701103F
                [all]   0
                [48-63] RD_RW_DATA_REG0 = 0xaa00

          IOM0.DDRPHY_SEQ_RD_WR_DATA1_P0 =        // 0x8000C4010701103F
                [all]   0
                [48-63] RD_RW_DATA_REG1 = 0x00aa

          IOM0.DDRPHY_SEQ_ODT_RD_CONFIG0_P0 =     // 0x8000C40E0701103F
                F(X) = (((X >> 4) & 0xc) | ((X >> 2) & 0x3))    // Bits 0,1,4,5 of X, see also MC01.PORT0.SRQ.MBA_FARB2Q
                [all]   0
                [48-51] ODT_RD_VALUES0 = F(ATTR_MSS_VPD_MT_ODT_RD[index(MCA)][0][0])
                [56-59] ODT_RD_VALUES1 = F(ATTR_MSS_VPD_MT_ODT_RD[index(MCA)][0][1])

          IOM0.DDRPHY_SEQ_ODT_RD_CONFIG1_P0 =     // 0x8000C40F0701103F
                F(X) = (((X >> 4) & 0xc) | ((X >> 2) & 0x3))    // Bits 0,1,4,5 of X, see also MC01.PORT0.SRQ.MBA_FARB2Q
                [all]   0
                [48-51] ODT_RD_VALUES0 =    // TODO: where those VPD values come from? Aren't they the same by any chance?
                          count_dimm(MCA) == 2: F(ATTR_MSS_VPD_MT_ODT_RD[index(MCA)][1][0])
                          count_dimm(MCA) != 2: F(ATTR_MSS_VPD_MT_ODT_RD[index(MCA)][0][2])
                [56-59] ODT_RD_VALUES1 =
                          count_dimm(MCA) == 2: F(ATTR_MSS_VPD_MT_ODT_RD[index(MCA)][1][1])
                          count_dimm(MCA) != 2: F(ATTR_MSS_VPD_MT_ODT_RD[index(MCA)][0][3])


          IOM0.DDRPHY_SEQ_ODT_WR_CONFIG0_P0 =     // 0x8000C40A0701103F
                F(X) = (((X >> 4) & 0xc) | ((X >> 2) & 0x3))    // Bits 0,1,4,5 of X, see also MC01.PORT0.SRQ.MBA_FARB2Q
                [all]   0
                [48-51] ODT_WR_VALUES0 = F(ATTR_MSS_VPD_MT_ODT_WR[index(MCA)][0][0])
                [56-59] ODT_WR_VALUES1 = F(ATTR_MSS_VPD_MT_ODT_WR[index(MCA)][0][1])

          IOM0.DDRPHY_SEQ_ODT_WR_CONFIG1_P0 =     // 0x8000C40B0701103F
                F(X) = (((X >> 4) & 0xc) | ((X >> 2) & 0x3))    // Bits 0,1,4,5 of X, see also MC01.PORT0.SRQ.MBA_FARB2Q
                [all]   0
                [48-51] ODT_WR_VALUES2 =
                          // RDIMM can't have more than 2 master ranks, maybe don't use ranks 2/3? On the other hand,
                          // maybe ranks 2/3 are used as "DIMM1 not present". TODO: check VPD for clues
                          count_dimm(MCA) == 2: F(ATTR_MSS_VPD_MT_ODT_WR[index(MCA)][1][0])
                          count_dimm(MCA) != 2: F(ATTR_MSS_VPD_MT_ODT_WR[index(MCA)][0][2])
                [56-59] ODT_WR_VALUES3 =
                          count_dimm(MCA) == 2: F(ATTR_MSS_VPD_MT_ODT_WR[index(MCA)][1][1])
                          count_dimm(MCA) != 2: F(ATTR_MSS_VPD_MT_ODT_WR[index(MCA)][0][3])

        reset_ac_boost_cntl
          IOM0.DDRPHY_DP16_ACBOOST_CTL_BYTE{0,1}_P0_{0,1,2,3,4} =     // 0x8000002{2,3}0701103F, +0x0400_0000_0000
                // For all of the AC Boost attributes, they're laid out in the uint32_t as such:
                // Bit 0-2   = DP16 Block 0 (DQ Bits 0-7)       BYTE0_P0_0
                // Bit 3-5   = DP16 Block 0 (DQ Bits 8-15)      BYTE1_P0_0
                // Bit 6-8   = DP16 Block 1 (DQ Bits 0-7)       BYTE0_P0_1
                // Bit 9-11  = DP16 Block 1 (DQ Bits 8-15)      BYTE1_P0_1
                // Bit 12-14 = DP16 Block 2 (DQ Bits 0-7)       BYTE0_P0_2
                // Bit 15-17 = DP16 Block 2 (DQ Bits 8-15)      BYTE1_P0_2
                // Bit 18-20 = DP16 Block 3 (DQ Bits 0-7)       BYTE0_P0_3
                // Bit 21-23 = DP16 Block 3 (DQ Bits 8-15)      BYTE1_P0_3
                // Bit 24-26 = DP16 Block 4 (DQ Bits 0-7)       BYTE0_P0_4
                // Bit 27-29 = DP16 Block 4 (DQ Bits 8-15)      BYTE1_P0_4
                [all]   0?    // function does read prev values from SCOM but then overwrites all non-const-0 fields. Why bother?
                [48-50] S{0,1}ACENSLICENDRV_DC = appropriate bits from ATTR_MSS_VPD_MT_MC_DQ_ACBOOST_WR_DOWN
                [51-53] S{0,1}ACENSLICENDRV_DC = appropriate bits from ATTR_MSS_VPD_MT_MC_DQ_ACBOOST_WR_UP
                [54-56] S{0,1}ACENSLICENDRV_DC = appropriate bits from ATTR_MSS_VPD_MT_MC_DQ_ACBOOST_RD_UP

        reset_ctle_cntl
          IOM0.DDRPHY_DP16_CTLE_CTL_BYTE{0,1}_P0_{0,1,2,3,4} =        // 0x8000002{0,1}0701103F, +0x0400_0000_0000
                // For the capacitance CTLE attributes, they're laid out in the uint64_t as such. The resitance
                // attributes are the same, but 3 bits long. Notice that DP Block X Nibble 0 is DQ0:3,
                // Nibble 1 is DQ4:7, Nibble 2 is DQ8:11 and 3 is DQ12:15.
                // Bit 0-1   = DP16 Block 0 Nibble 0     Bit 16-17 = DP16 Block 2 Nibble 0     Bit 32-33 = DP16 Block 4 Nibble 0
                // Bit 2-3   = DP16 Block 0 Nibble 1     Bit 18-19 = DP16 Block 2 Nibble 1     Bit 34-35 = DP16 Block 4 Nibble 1
                // Bit 4-5   = DP16 Block 0 Nibble 2     Bit 20-21 = DP16 Block 2 Nibble 2     Bit 36-37 = DP16 Block 4 Nibble 2
                // Bit 6-7   = DP16 Block 0 Nibble 3     Bit 22-23 = DP16 Block 2 Nibble 3     Bit 38-39 = DP16 Block 4 Nibble 3
                // Bit 8-9   = DP16 Block 1 Nibble 0     Bit 24-25 = DP16 Block 3 Nibble 0
                // Bit 10-11 = DP16 Block 1 Nibble 1     Bit 26-27 = DP16 Block 3 Nibble 1
                // Bit 12-13 = DP16 Block 1 Nibble 2     Bit 28-29 = DP16 Block 3 Nibble 2
                // Bit 14-15 = DP16 Block 1 Nibble 3     Bit 30-31 = DP16 Block 3 Nibble 3
                [48-49] NIB_{0,2}_DQSEL_CAP = appropriate bits from ATTR_MSS_VPD_MT_MC_DQ_CTLE_CAP
                [53-55] NIB_{0,2}_DQSEL_RES = appropriate bits from ATTR_MSS_VPD_MT_MC_DQ_CTLE_RES
                [56-57] NIB_{1,3}_DQSEL_CAP = appropriate bits from ATTR_MSS_VPD_MT_MC_DQ_CTLE_CAP
                [61-63] NIB_{1,3}_DQSEL_RES = appropriate bits from ATTR_MSS_VPD_MT_MC_DQ_CTLE_RES

        reset_delay
          // "If the reset value is not sufficient for the given system, these registers must be set via the programming interface."
          IOM0.DDRPHY_ADR_DELAY0_P0_ADR0 =
                [all]   0
                [49-55] ADR_DELAY0 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CNTL_D0_CSN0
                [57-63] ADR_DELAY1 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CMD_ADDR_WEN_A14
          IOM0.DDRPHY_ADR_DELAY1_P0_ADR0 =
                [all]   0
                [49-55] ADR_DELAY2 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CNTL_D1_ODT1
                [57-63] ADR_DELAY3 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_C0
          IOM0.DDRPHY_ADR_DELAY2_P0_ADR0 =
                [all]   0
                [49-55] ADR_DELAY4 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_BA1
                [57-63] ADR_DELAY5 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A10
          IOM0.DDRPHY_ADR_DELAY3_P0_ADR0 =
                [all]   0
                [49-55] ADR_DELAY6 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CNTL_D0_ODT1
                [57-63] ADR_DELAY7 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_BA0
          IOM0.DDRPHY_ADR_DELAY4_P0_ADR0 =
                [all]   0
                [49-55] ADR_DELAY8 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A00
                [57-63] ADR_DELAY9 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CNTL_D1_ODT0
          IOM0.DDRPHY_ADR_DELAY5_P0_ADR0 =
                [all]   0
                [49-55] ADR_DELAY10 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CNTL_D0_ODT0
                [57-63] ADR_DELAY11 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CMD_ADDR_CASN_A15

          IOM0.DDRPHY_ADR_DELAY0_P0_ADR1 =
                [all]   0
                [49-55] ADR_DELAY0 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A13
                [57-63] ADR_DELAY1 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CNTL_D0_CSN1
          IOM0.DDRPHY_ADR_DELAY1_P0_ADR1 =
                [all]   0
                [49-55] ADR_DELAY2 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_D0_CLKN
                [57-63] ADR_DELAY3 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_D0_CLKP
          IOM0.DDRPHY_ADR_DELAY2_P0_ADR1 =
                [all]   0
                [49-55] ADR_DELAY4 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A17
                [57-63] ADR_DELAY5 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_C1
          IOM0.DDRPHY_ADR_DELAY3_P0_ADR1 =
                [all]   0
                [49-55] ADR_DELAY6 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_D1_CLKN
                [57-63] ADR_DELAY7 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_D1_CLKP
          IOM0.DDRPHY_ADR_DELAY4_P0_ADR1 =
                [all]   0
                [49-55] ADR_DELAY8 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_C2
                [57-63] ADR_DELAY9 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CNTL_D1_CSN1
          IOM0.DDRPHY_ADR_DELAY5_P0_ADR1 =
                [all]   0
                [49-55] ADR_DELAY10 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A02
                [57-63] ADR_DELAY11 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CMD_PAR

          IOM0.DDRPHY_ADR_DELAY0_P0_ADR2 =
                [all]   0
                [49-55] ADR_DELAY0 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CNTL_D1_CSN0
                [57-63] ADR_DELAY1 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CMD_ADDR_RASN_A16
          IOM0.DDRPHY_ADR_DELAY1_P0_ADR2 =
                [all]   0
                [49-55] ADR_DELAY2 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A08
                [57-63] ADR_DELAY3 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A05
          IOM0.DDRPHY_ADR_DELAY2_P0_ADR2 =
                [all]   0
                [49-55] ADR_DELAY4 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A03
                [57-63] ADR_DELAY5 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A01
          IOM0.DDRPHY_ADR_DELAY3_P0_ADR2 =
                [all]   0
                [49-55] ADR_DELAY6 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A04
                [57-63] ADR_DELAY7 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A07
          IOM0.DDRPHY_ADR_DELAY4_P0_ADR2 =
                [all]   0
                [49-55] ADR_DELAY8 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A09
                [57-63] ADR_DELAY9 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A06
          IOM0.DDRPHY_ADR_DELAY5_P0_ADR2 =
                [all]   0
                [49-55] ADR_DELAY10 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CNTL_D0_CKE1
                [57-63] ADR_DELAY11 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A12

          IOM0.DDRPHY_ADR_DELAY0_P0_ADR3 =
                [all]   0
                [49-55] ADR_DELAY0 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CMD_ACTN
                [57-63] ADR_DELAY1 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_A11
          IOM0.DDRPHY_ADR_DELAY1_P0_ADR3 =
                [all]   0
                [49-55] ADR_DELAY2 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_BG0
                [57-63] ADR_DELAY3 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CNTL_D0_CKE0
          IOM0.DDRPHY_ADR_DELAY2_P0_ADR3 =
                [all]   0
                [49-55] ADR_DELAY4 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CNTL_D1_CKE1
                [57-63] ADR_DELAY5 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_ADDR_BG1
          IOM0.DDRPHY_ADR_DELAY3_P0_ADR3 =
                [all]   0
                [49-55] ADR_DELAY6 = ATTR_MSS_VPD_MR_MC_PHASE_ROT_CNTL_D1_CKE0

        reset_tsys_adr
          IOM0.DDRPHY_ADR_MCCLK_WRCLK_PR_STATIC_OFFSET_P0_ADR32S{0,1} =   // 0x800080330701103F, +0x0400_0000_0000
                [all]   0
                [49-55] TSYS_WRCLK = ATTR_MSS_VPD_MR_TSYS_ADR
                      // From regs spec:
                      // Set to ‘19’h for 2666 MT/s.
                      // Set to ‘17’h for 2400 MT/s.
                      // Set to ‘14’h for 2133 MT/s.
                      // Set to ‘12’h for 1866 MT/s.

        reset_tsys_data
          IOM0.DDRPHY_DP16_WRCLK_PR_P0_{0,1,2,3,4} =                      // 0x800000740701103F, +0x0400_0000_0000
                [all]   0
                [49-55] TSYS_WRCLK = ATTR_MSS_VPD_MR_TSYS_DATA
                      // From regs spec:
                      // Set to ‘12’h for 2666 MT/s.
                      // Set to ‘10’h for 2400 MT/s.
                      // Set to ‘0F’h for 2133 MT/s.
                      // Set to ‘0D’h for 1866 MT/s.

        reset_io_impedances
          IOM0.DDRPHY_DP16_IO_TX_FET_SLICE_P0_{0,1,2,3,4} =               // 0x800000780701103F, +0x0400_0000_0000
                [all]   0
                // 0 - Hi-Z, otherwise impedance = 240/<num of set bits> Ohms
                [49-55] EN_SLICE_N_WR = ATTR_MSS_VPD_MT_MC_DRV_IMP_DQ_DQS[{0,1,2,3,4}]
                [57-63] EN_SLICE_P_WR = ATTR_MSS_VPD_MT_MC_DRV_IMP_DQ_DQS[{0,1,2,3,4}]

          IOM0.DDRPHY_DP16_IO_TX_PFET_TERM_P0_{0,1,2,3,4} =               // 0x8000007B0701103F, +0x0400_0000_0000
                [all]   0
                // 0 - Hi-Z, otherwise impedance = 240/<num of set bits> Ohms
                [49-55] EN_SLICE_N_WR = ATTR_MSS_VPD_MT_MC_RCV_IMP_DQ_DQS[{0,1,2,3,4}]

          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP0_P0_ADR1 =    // yes, ADR1  // 0x800044200701103F
                // These are RMW one at a time. I don't see why not all at once, or at least in pairs (P and N of the same clocks)
                if (ATTR_MSS_VPD_MT_MC_DRV_IMP_CLK == ENUM_ATTR_MSS_VPD_MT_MC_DRV_IMP_CLK_OHM30):
                  [54,52,62,60] SLICE_SELn = 1    // CLK00 P, CLK00 N, CLK01 P, CLK01 N
                else
                  [54,52,62,60] = 0

          // Following are reordered to minimalize number of register reads/writes
          ------------------------------------------------------------------------
          val = (ATTR_MSS_VPD_MT_MC_DRV_IMP_CMD_ADDR == ENUM_ATTR_MSS_VPD_MT_MC_DRV_IMP_CMD_ADDR_OHM30) ? 1 : 0
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP0_P0_ADR0 =
                [50,56,58,62] =           val       // ADDR14/WEN, BA1, ADDR10, BA0
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP1_P0_ADR0 =
                [48,54] =                 val       // ADDR0, ADDR15/CAS
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP0_P0_ADR1 =        // same as CLK, however it uses different VPD
                [48,56] =                 val       // ADDR13, ADDR17/RAS
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP1_P0_ADR1 =
                [52]    =                 val       // ADDR2
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP0_P0_ADR2 =
                [50,52,54,56,58,60,62] =  val       // ADDR16/RAS, ADDR8, ADDR5, ADDR3, ADDR1, ADDR4, ADDR7
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP1_P0_ADR2 =
                [48,50,54] =              val       // ADDR9, ADDR6, ADDR12
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP0_P0_ADR3 =
                [48,50,52,58] =           val       // ACT_N, ADDR11, BG0, BG1

          // Following are reordered to minimalize number of register reads/writes
          ------------------------------------------------------------------------
          val = (ATTR_MSS_VPD_MT_MC_DRV_IMP_CNTL == ENUM_ATTR_MSS_VPD_MT_MC_DRV_IMP_CNTL_OHM30) ? 1 : 0
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP0_P0_ADR0 =        // same as CMD/ADDR, however it uses different VPD
                [52,60] =                 val       // ODT3, ODT1
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP1_P0_ADR0 =        // same as CMD/ADDR, however it uses different VPD
                [50,52] =                 val       // ODT2, ODT0
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP1_P0_ADR1 =        // same as CMD/ADDR, however it uses different VPD
                [54] =                    val       // PARITY
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP1_P0_ADR2 =        // same as CMD/ADDR, however it uses different VPD
                [52] =                    val       // CKE1
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP0_P0_ADR3 =        // same as CMD/ADDR, however it uses different VPD
                [54,56,60,62] =           val       // CKE0, CKE3, CKE2, RESET_N

          // Following are reordered to minimalize number of register reads/writes
          ------------------------------------------------------------------------
          val = (ATTR_MSS_VPD_MT_MC_DRV_IMP_CSCID == ENUM_ATTR_MSS_VPD_MT_MC_DRV_IMP_CSCID_OHM30) ? 1 : 0
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP0_P0_ADR0 =        // same as CMD/ADDR and CNTL, however it uses different VPD
                [48,54] =                 val       // CS0, CID0
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP0_P0_ADR1 =        // same as CLK and CMD/ADDR, however it uses different VPD
                [50,58] =                 val       // CS1, CID1
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP1_P0_ADR1 =        // same as CMD/ADDR and CNTL, however it uses different VPD
                [48,50] =                 val       // CS3, CID2
          IOM0.DDRPHY_ADR_IO_FET_SLICE_EN_MAP0_P0_ADR2 =        // same as CMD/ADDR, however it uses different VPD
                [48] =                    val       // CS2

          // IO impedances regs summary:            lanes 9-15 have different possible settings (results in 15/30 vs 40/30 Ohm)
          // MAP0_ADR0: all set                       MAP1_ADR0: lanes 12-15 not set
          // MAP0_ADR1: all set                       MAP1_ADR1: lanes 12-15 not set
          // MAP0_ADR2: all set                       MAP1_ADR2: lanes 12-15 not set
          // MAP0_ADR3: all set                       MAP1_ADR3: not used
          // This mapping is consistent with ADR_DELAYx_P0_ADRy settings

        reset_wr_vref_registers
          IOM0.DDRPHY_DP16_WR_VREF_CONFIG0_P0_{0,1,2,3,4} =       // 0x8000006C0701103F, +0x0400_0000_0000
                // This may be a good place for tweaking training times, if needed
                [all]   0
                [48]    WR_CTR_1D_MODE_SWITCH =       0     // 1 for <DD2
                [49]    WR_CTR_RUN_FULL_1D =          1
                [50-52] WR_CTR_2D_SMALL_STEP_VAL =    0     // implicit +1
                [53-56] WR_CTR_2D_BIG_STEP_VAL =      1     // implicit +1
                [57-59] WR_CTR_NUM_BITS_TO_SKIP =     0     // skip nothing
                [60-62] WR_CTR_NUM_NO_INC_VREF_COMP = 7

          IOM0.DDRPHY_DP16_WR_VREF_CONFIG1_P0_{0,1,2,3,4} =       // 0x800000EC0701103F, +0x0400_0000_0000
                [all]   0
                [48]    WR_CTR_VREF_RANGE_SELECT =      0       // range 1 by default (60-92.5%)
                [49-55] WR_CTR_VREF_RANGE_CROSSOVER =   0x18    // JEDEC table 34
                [56-62] WR_CTR_VREF_SINGLE_RANGE_MAX =  0x32    // JEDEC table 34

          IOM0.DDRPHY_DP16_WR_VREF_STATUS0_P0_{0,1,2,3,4} =       // 0x8000002E0701103F, +0x0400_0000_0000
                [all]   0

          IOM0.DDRPHY_DP16_WR_VREF_STATUS1_P0_{0,1,2,3,4} =       // 0x8000002F0701103F, +0x0400_0000_0000
                [all]   0

          IOM0.DDRPHY_DP16_WR_VREF_ERROR_MASK{0,1}_P0_{0,1,2,3,4} =   // 0x800000F{B,A}0701103F, +0x0400_0000_0000
                [all]   0
                [48-63] 0xffff

          IOM0.DDRPHY_DP16_WR_VREF_ERROR{0,1}_P0_{0,1,2,3,4} =    // 0x800000A{E,F}0701103F, +0x0400_0000_0000
                [all]   0

          // Assume RDIMM
          // Assume unpopulated DIMMs/ranks are not calibrated so their settings doesn't matter (more reg accesses, much simpler code)
          IOM0.DDRPHY_DP16_WR_VREF_VALUE{0,1}_RANK_PAIR0_P0_{0,1,2,3,4} =   // 0x8000005{E,F}0701103F, +0x0400_0000_0000
          IOM0.DDRPHY_DP16_WR_VREF_VALUE{0,1}_RANK_PAIR1_P0_{0,1,2,3,4} =   // 0x8000015{E,F}0701103F, +0x0400_0000_0000
          IOM0.DDRPHY_DP16_WR_VREF_VALUE{0,1}_RANK_PAIR2_P0_{0,1,2,3,4} =   // 0x8000025{E,F}0701103F, +0x0400_0000_0000
          IOM0.DDRPHY_DP16_WR_VREF_VALUE{0,1}_RANK_PAIR3_P0_{0,1,2,3,4} =   // 0x8000035{E,F}0701103F, +0x0400_0000_0000
                [all]   0
                [49]    WR_VREF_RANGE_DRAM{0,2} = ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x40
                [50-55] WR_VREF_VALUE_DRAM{0,2} = ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x3f
                [57]    WR_VREF_RANGE_DRAM{1,3} = ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x40
                [58-63] WR_VREF_VALUE_DRAM{1,3} = ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x3f

        reset_drift_limits
          IOM0.DDRPHY_DP16_DRIFT_LIMITS_P0_{0,1,2,3,4} =          // 0x8000000A0701103F, +0x0400_0000_0000
                [48-49] DD2_BLUE_EXTEND_RANGE = 1         // always ONE_TO_FOUR due to red waterfall workaround

        // Workarounds
        dqs_polarity        // Does not apply to DD2

        rd_dia_config5
          IOM0.DDRPHY_DP16_RD_DIA_CONFIG5_P0_{0,1,2,3,4} =        // 0x800000120701103F, +0x0400_0000_0000
                // "this isn't an EC feature workaround, it's a incorrect documentation workaround"
                [all]   0
                [49]    DYN_MCTERM_CNTL_EN =      1
                [52]    PER_CAL_UPDATE_DISABLE =  1     // "This bit must be set to 0 for normal operation"
                [59]    PERCAL_PWR_DIS =          1

        dqsclk_offset
          IOM0.DDRPHY_DP16_DQSCLK_OFFSET_P0_{0,1,2,3,4} =         // 0x800000370701103F, +0x0400_0000_0000
                // "this isn't an EC feature workaround, it's a incorrect documentation workaround"
                [all]   0
                [49-55] DQS_OFFSET = 0x08       // Config provided by S. Wyatt 9/13

        odt_config        // Does not apply to DD2

  - Do FIRry things
    mss::unmask::after_scominit(MCBIST)
      for each functional or magic MCA
        IOM0.IOM_PHY0_DDRPHY_FIR_REG =      // 0x07011000         // maybe use SCOM1 (AND) 0x07011001
              [56]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_2 = 0   // calibration errors
              [58]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_4 = 0   // DLL errors
        MC01.PORT0.SRQ.MBACALFIRQ =         // 0x07010900         // maybe use SCOM1 (AND) 0x07010901
              [4]   MBACALFIRQ_RCD_PARITY_ERROR = 0
              [8]   MBACALFIRQ_DDR_MBA_EVENT_N =  0

## mss_ddr_phy_reset: Soft reset of DDR PHY macros (13.9)

> - Lock DDR DLLs
>   - Already configured DDR DLL in scaninit
> - Sends Soft DDR Phy reset
> - Kick off internal ZQ Cal
> - Perform any config that wasn't scanned in (TBD)
>   - Nothing known here

for each functional MCBIST:
  p9_mss_ddr_phy_reset
    if (count_dimms(MCBIST) == 0) return

    for each functional or magic MCA
      MC01.PORT0.SRQ.MBA_FARB5Q =
            [8]     MBA_FARB5Q_CFG_FORCE_MCLK_LOW_N = 0

    // Drive all control signals to their inactive/idle state, or inactive value
    for each functional or magic MCA
      IOM0.DDRPHY_DP16_SYSCLK_PR0_P0_{0,1,2,3,4} =              // 0x800000070701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_SYSCLK_PR1_P0_{0,1,2,3,4} =              // 0x8000007F0701103F, +0x0400_0000_0000
            [all]   0
            [48]    reserved = 1            // MCA_DDRPHY_DP16_SYSCLK_PR0_P0_0_01_ENABLE

    // Assert reset to PHY for 32 memory clocks
    for each functional or magic MCA
      MC01.PORT0.SRQ.MBA_CAL0Q =                                // 0x0701090F
            [57]    MBA_CAL0Q_RESET_RECOVER = 1

    delay(32 memclocks)     // These delays probably are the only reason why everything has separate "for each MCA" loops

    // Deassert reset_n
    for each functional or magic MCA
      MC01.PORT0.SRQ.MBA_CAL0Q =                                // 0x0701090F
            [57]    MBA_CAL0Q_RESET_RECOVER = 0

    // Flush output drivers
    for each functional or magic MCA
      IOM0.DDRPHY_ADR_OUTPUT_FORCE_ATEST_CNTL_P0_ADR32S{0,1} =    // 0x800080350701103F, 0x800084350701103F
            [all]   0
            [48]    FLUSH =   1
            [50]    INIT_IO = 1

      IOM0.DDRPHY_DP16_CONFIG0_P0_{0,1,2,3,4} =                   // 0x800000030701103F, +0x0400_0000_0000
            [all]   0
            [51]    FLUSH =                 1
            [54]    INIT_IO =               1
            [55]    ADVANCE_PING_PONG =     1
            [58]    DELAY_PING_PONG_HALF =  1

    delay(32 memclocks)     // These delays probably are the only reason why everything has separate "for each MCA" loops

    for each functional or magic MCA
      IOM0.DDRPHY_ADR_OUTPUT_FORCE_ATEST_CNTL_P0_ADR32S{0,1} =    // 0x800080350701103F, 0x800084350701103F
            [all]   0
            [48]    FLUSH =   0
            [50]    INIT_IO = 0

      IOM0.DDRPHY_DP16_CONFIG0_P0_{0,1,2,3,4} =                   // 0x800000030701103F, +0x0400_0000_0000
            [all]   0
            [51]    FLUSH =                 0
            [54]    INIT_IO =               0
            [55]    ADVANCE_PING_PONG =     1
            [58]    DELAY_PING_PONG_HALF =  1

    // ZCTL Enable
    for each magic MCA            // note we are already in "for each MCBIST" loop
      IOM0.DDRPHY_PC_RESETS_P0 =                                  // 0x8000C00E0701103F
            // Yet another documentation error: all bits in this register are marked as read-only
            [51]    ENABLE_ZCAL = 1

    // Is this really necessary? We are polling ZCAL_DONE, if it were to fail we're screwed anyway
    delay(1024 memclocks)
    // Comment says ENABLE_ZCAL has to be deasserted here, neither code nor spec agrees
    for each magic MCA            // note we are already in "for each MCBIST" loop
      timeout(50*10ns):
            // Maybe this should be reordered for consistent timeouts across MCAs: timeout->for each->check bit.
            // Difference between RMW (assert reset bit) and polling should be much smaller that this timeout,
            // which would otherwise be added per each magic MCA in the worst case scenario. On the other hand,
            // number of magic MCAs is const and relatively small, we may end up dropping 'for each' altogether.
            if (IOM0.DDRPHY_PC_DLL_ZCAL_CAL_STATUS_P0 [63] /*ZCAL_DONE*/) == 1) break    // 0x8000C0000701103F
            delay(10ns)

    // DLL calibration
    // Here was an early return if no functional MCAs were found. Wouldn't that make whole MCBIST non-functional?
    for each functional MCA
      IOM0.DDRPHY_ADR_DLL_CNTL_P0_ADR32S{0,1} =           // 0x8000803A0701103F, 0x8000843A0701103F
            [48]    INIT_RXDLL_CAL_RESET = 0
      IOM0.DDRPHY_DP16_DLL_CNTL{0,1}_P0_{0,1,2,3} =       // 0x8000002{4,5}0701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_DLL_CNTL0_P0_4
            [48]    INIT_RXDLL_CAL_RESET = 0
      IOM0.DDRPHY_DP16_DLL_CNTL1_P0_4
            [48]    INIT_RXDLL_CAL_RESET = 1      // no-op?

    // 32,772 dphy_nclk cycles from Reset=0 to VREG Calibration to exhaust all values
    // 37,382 dphy_nclk cycles for full calibration to start and fail ("worst case")
    delay(37,382 memclocks)

    // The comment before poll says:
    // > To keep things simple, we'll poll for the change in one of the ports. Once that's completed, we'll
    // > check the others. If any one has failed, or isn't notifying complete, we'll pop out an error
    // The issue is that it only tests the first of the functional ports. Other ports may or may not have failed.
    // Even if this times out, the rest of the function continues normally, without throwing any error...
    // A case in which the first MCA finishes calib before the rest does is caught by "worst case" delay above.
    // If the tests below were done properly (poll every MCA), we could do better than "worst case", statistically
    // we should hit proper VREG in half of that period, which would give ~8ms wasted here (average for DDR4-2133).
    // For now I'll leave it described as it was done in Hostboot, but there is room for improvement here.
    timeout(50*10ns):
      if (IOM0.DDRPHY_PC_DLL_ZCAL_CAL_STATUS_P0
                [48]  DP_DLL_CAL_GOOD ==        1
                [49]  DP_DLL_CAL_ERROR ==       0
                [50]  DP_DLL_CAL_ERROR_FINE ==  0
                [51]  ADR_DLL_CAL_GOOD ==       1
                [52]  ADR_DLL_CAL_ERROR ==      0
                [53]  ADR_DLL_CAL_ERROR_FINE == 0) break    // success
      if (IOM0.DDRPHY_PC_DLL_ZCAL_CAL_STATUS_P0
                [49]  DP_DLL_CAL_ERROR ==       1 |
                [50]  DP_DLL_CAL_ERROR_FINE ==  1 |
                [52]  ADR_DLL_CAL_ERROR ==      1 |
                [53]  ADR_DLL_CAL_ERROR_FINE == 1) break and do the workaround
      // either 48 or 51 is 0
      delay(10ns)

    // Workaround is also required if any of coarse VREG has value 1 after calibration
    // Test from poll above is repeated here - this time for every MCA, but it doesn't wait until DLL gets
    // calibrated if that is still in progress. The registers below (also used in the workaround) __must not__
    // be written to while hardware calibration is in progress.
    for each functional MCA     // this loop may be skipped if we're doing workaround anyway
      if (IOM0.DDRPHY_ADR_DLL_VREG_COARSE_P0_ADR32S0        |       // 0x8000803E0701103F
          IOM0.DDRPHY_DP16_DLL_VREG_COARSE0_P0_{0,1,2,3,4}  |       // 0x8000002C0701103F, +0x0400_0000_0000
          IOM0.DDRPHY_DP16_DLL_VREG_COARSE1_P0_{0,1,2,3}    |       // 0x8000002D0701103F, +0x0400_0000_0000
                [56-62] REGS_RXDLL_VREG_DAC_COARSE = 1)    // The same offset for ADR and DP16, convenient
              do the workaround

    // Proper workaround - skip if not needed
    -----------------------------------------
    fix_bad_voltage_settings
      for each functional MCA
        // Each MCA has 10 DLLs: ADR DLL0, DP0-4 DLL0, DP0-3 DLL1. Each of those can fail. For each DLL there are 5 registers
        // used in this workaround, those are (see src/import/chips/p9/procedures/hwp/memory/lib/workarounds/dll_workaround.C):
        // - l_CNTRL:         DP16 or ADR CNTRL register
        // - l_COARSE_SAME:   VREG_COARSE register for same DLL as CNTRL reg
        // - l_COARSE_NEIGH:  VREG_COARSE register for DLL neighbor for this workaround
        // - l_DAC_LOWER:     DLL DAC Lower register
        // - l_DAC_UPPER:     DLL DAC Upper register
        // Warning: the last two have their descriptions swapped in dll_workaround.H
        // It seems that the code excepts that DLL neighbor is always good, what if it isn't?
        //
        // General flow, stripped from C++ bloating and repeated loops:
        for each DLL          // list in workarounds/dll_workaround.C
          1. check if this DLL failed, if not - skip to the next one
                (l_CNTRL[62 | 63] | l_COARSE_SAME[56-62] == 1) -> failed
          2. set reset bit, set skip VREG bit, clear the error bits
                l_CNTRL[48] =     1
                l_CNTRL[50-51] =  2     // REGS_RXDLL_CAL_SKIP, 2 - skip VREG calib., do coarse delay calib. only
                l_CNTRL[62-63] =  0
          3. clear DLL FIR (see "Do FIRry things" at the end of 13.8)  // this was actually done for non-failed DLLs too, why?
                IOM0.IOM_PHY0_DDRPHY_FIR_REG =      // 0x07011000         // maybe use SCOM1 (AND) 0x07011001
                      [56]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_2 = 0   // calibration errors
                      [58]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_4 = 0   // DLL errors
          4. write the VREG DAC value found in neighbor (good) to the failing DLL VREG DAC
                l_COARSE_SAME[56-62] = l_COARSE_NEIGH[56-62]
          5. reset the upper and lower fine calibration bits back to defaults
                l_DAC_LOWER[56-63] =  0x0x8000    // Hard coded default values per Steve Wyatt for this workaround
                l_DAC_UPPER[56-63] =  0x0xFFE0
          6. run DLL Calibration again on failed DLLs
                l_CNTRL[48] = 0
        // Wait for calibration to finish
        delay(37,382 memclocks)     // again, we could do better than this

        // Check if calibration succeeded (same tests as in 1 above, for all DLLs)
        for each DLL
          if (l_CNTRL[62 | 63] | l_COARSE_SAME[56-62] == 1): failed, assert and die?
    -----------------------------------------
    // End of DLL workaround

    // Start bang-bang-lock
    // Take dphy_nclk/SysClk alignment circuits out of reset and put into continuous update mode
    for each functional MCA
      IOM0.DDRPHY_ADR_SYSCLK_CNTL_PR_P0_ADR32S{0,1} =           // 0x800080320701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_SYSCLK_PR0_P0_{0,1,2,3,4} =              // 0x800000070701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_SYSCLK_PR1_P0_{0,1,2,3} =                // 0x8000007F0701103F, +0x0400_0000_0000
            [all]   0
            [48-63] 0x8024      // From the DDR PHY workbook

    // Wait at least 5932 dphy_nclk clock cycles to allow the dphy_nclk/SysClk alignment circuit to perform initial alignment
    delay(5932 memclocks)

    // Check for LOCK in DDRPHY_DP16_SYSCLK_PR_VALUE registers and DDRPHY_ADR_SYSCLK_PR_VALUE
    for each functional MCA
      timeout(50*10ns):
        IOM0.DDRPHY_ADR_SYSCLK_PR_VALUE_RO_P0_ADR32S{0,1}       // 0x800080340701103F, +0x0400_0000_0000
              [56]  BB_LOCK     &
        IOM0.DDRPHY_DP16_SYSCLK_PR_VALUE_P0_{0,1,2,3}           // 0x800000730701103F, +0x0400_0000_0000
              [48]  BB_LOCK0    &
              [56]  BB_LOCK1    &
        IOM0.DDRPHY_DP16_SYSCLK_PR_VALUE_P0_4
              [48]  BB_LOCK0          // last DP16 uses only first half
        if all bits listed above are set: break
        delay(10ns)

    // Write 0b0 into the DDRPHY_PC_RESETS register bit 1. This write de-asserts the SYSCLK_RESET
    for each functional MCA
      IOM0.DDRPHY_PC_RESETS_P0 =                                  // 0x8000C00E0701103F
              [49]  SYSCLK_RESET = 0

    // Reset the windage registers
    // According to the PHY team, resetting the read delay offset must be done after SYSCLK_RESET
    for each functional MCA
      // This was using floating point math, so it has to be changed.
      // ATTR_MSS_VPD_MT_WINDAGE_RD_CTR holds (signed) value of offset in picoseconds. It must be converted to
      // phase rotator ticks. There are 128 ticks per clock, and clock period depends on memory frequency.
      // See FREQ_TO_CLOCK_PERIOD in /src/import/generic/memory/lib/utils/conversion.H for values.
      // Result is rounded away from zero, so we have to add *or subtract* half of tick.
      //
      // Maybe we can skip this (40 register writes per port), from documentation:
      // "This register must not be set to a nonzero value unless detailed timing analysis shows that, for
      // a particular configuration, the read-centering algorithm places the sampling point off from the eye center."
      IOM0.DDRPHY_DP16_READ_DELAY_OFFSET0_RANK_PAIR{0,1,2,3}_P0_{0,1,2,3,4} =   // 0x80000{0,1,2,3}0C0701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_READ_DELAY_OFFSET1_RANK_PAIR{0,1,2,3}_P0_{0,1,2,3,4} =   // 0x80000{0,1,2,3}0D0701103F, +0x0400_0000_0000
              [all]   0
              [49-55] OFFSET0 = offset_in_ticks_rounded
              [57-63] OFFSET1 = offset_in_ticks_rounded

    // Take the dphy_nclk/SysClk alignment circuit out of the Continuous Update mode
    for each functional MCA
      IOM0.DDRPHY_ADR_SYSCLK_CNTL_PR_P0_ADR32S{0,1} =           // 0x800080320701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_SYSCLK_PR0_P0_{0,1,2,3,4} =              // 0x800000070701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_SYSCLK_PR1_P0_{0,1,2,3} =                // 0x8000007F0701103F, +0x0400_0000_0000
            [all]   0
            [48-63] 0x8020      // From the DDR PHY workbook

    // Wait at least 32 dphy_nclk clock cycles
    delay(32 memclocks)
    // Done bang-bang-lock

    // Per J. Bialas, force_mclk_low can be dasserted
    for each functional MCA
      MC01.PORT0.SRQ.MBA_FARB5Q =
            [8]     MBA_FARB5Q_CFG_FORCE_MCLK_LOW_N = 1

    // Workarounds
    // It reads and writes back DDRPHY_DP16_RD_VREF_DAC_n_P0_p. Docs don't say it has side effects, but who knows...
    mss::workarounds::dp16::after_phy_reset - not needed on DD2

    // New for Nimbus - perform duty cycle clock distortion calibration (DCD cal)
    // Per PHY team's characterization, the DCD cal needs to be run after DLL calibration
    // It can be skipped based on ATTR_MSS_RUN_DCD_CALIBRATION
    for each functional MCA
      // DCD hardware calibration is a three step process:
      // 1) kick off cal on all the registers
      // 2) poll for done on all of the registers
      // 3) loop through the list of failing DCD regs and do the software calibration
      // Step 2) in hostboot also calculates average value of adjust for all successfully calibrated regs. This value
      // is later discarded in step 3), so instead of doing these steps separately we can modify and merge them into
      // one loop. Note that software calibration takes time, it may impact the timeout calculation for further regs.
      //
      // 1) kick off cal on all the registers
      IOM0.DDRPHY_ADR_DCD_CONTROL_P0_ADR32S0                        // 0x800080380701103F
      IOM0.DDRPHY_DP16_DCD_CONTROL{0,1}_P0_{0,1,2,3}                // 0x800000A{4,5}0701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_DCD_CONTROL0_P0_4
              [all]   0
              [48-63] 0x80a0  // for DD2 first field (DLL_DCD_ADJUST) is 8b long, for DD1 it was 7b

      // 2) poll for done on all of the registers
      IOM0.DDRPHY_ADR_DCD_CONTROL_P0_ADR32S0                        // 0x800080380701103F
      IOM0.DDRPHY_DP16_DCD_CONTROL{0,1}_P0_{0,1,2,3}                // 0x800000A{4,5}0701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_DCD_CONTROL0_P0_4
        // Timeout is separate for each reg, but perhaps it should use one global number of iterations for all regs per MCA
        timeout((128 + 256) * 100ns):         // starting from the middle, max 128 steps down and 256 steps up
          if [61] DLL_DCD_CAL_DONE == 1: break
          delay(100ns)

        // 3) do the software calibration for failing DCD regs
        if [62] DLL_DCD_CAL_ERROR == 1:
          seed = 0x80
          A_val = B_val = 0
          // This is almost identical for both sides, might be a function
          // Can we use bisect instead of linear search? Would delays be different?
          // Hostboot returned RC which tells if given side failed, but it can fail only if SCOM access or delay
          // fails (in that case we have bigger problems...), otherwise it asserts.
          ------------------------------
          tick =      +1
          expected =  1
          overflow =  0xff
          [all]   0
          [48-55] DLL_DCD_ADJUST =      seed
          [56]    DLL_DCD_CORRECT_EN =  1
          [57]    DLL_DCD_ITER_A =      1   // side A
          [58]    DLL_DCD_CAL_ENABLE =  0
          [63]    DLL_DCD_COMPARE_OUT = 0
          // BUG? No delay between write and read here, but there is 100ns delay later
          write and read back register    // DLL_DCD_COMPARE_OUT will be set based on whether target val is higher/lower than seed
          if ([63] == 1):   // target is below seed value
            tick =      -1
            expected =  0
            overflow =  0x00
          // overflow is the last valid value (poor variable naming), so use do..while
          do:
            if ([63] == expected): break
            seed += tick
            [48-55] seed
            [63]    0     // must be cleared before each write
            write
            delay(100ns)
            read
            // Here was another 100ns delay. Docs does not specify any. Why delay *after* read?
            // Here current value was obtained from read value, but it should be always seed (unless HW modifies it?)
          while (seed != overflow)
          // BUG? Hostboot asserts on seed != overflow, what if it is the last good value? Let's check expected instead
          assert([63] == expected)  // maybe not assert? We didn't get 50% duty cycle, but it still might be close enough,
                                    // RDIMM is more forgiving than DIMM (40% instead of 48% min)
          A_val = seed
          ------------------------------
          // Note we use A value as a seed - in ideal world A_val == B_val, real world should be close to that
          // Hostboot used (A_val - 1) to cover corner case when A_val == B_val, but it introduced another corner case
          // for (A_val - 1) == B_val.
          do the same for side B
          // [57] = 0
          // B_val = seed
          ------------------------------
          // The final value is the average of the a-side and b-side values
          // Hostboot uses convoluted way of calculating target value based on RCs from functions above
          [48-55] (A_val + B_val) / 2
          [63]    0

    // FIR
    mss::check::during_phy_reset
      // Mostly FFDC, which to my current knowledge is just the error logging. If it does anything else,
      // this needs rechecking
      for each functional or magic MCA
        // If any of these bits is set, return error. Clear them unconditionally (maybe they are not cleared on platform reset?)
        MC01.PORT0.SRQ.MBACALFIRQ =           // 0x07010900         // use SCOM1 (AND) 0x07010901 for clearing
              [0]   MBACALFIRQ_MBA_RECOVERABLE_ERROR
              [1]   MBACALFIRQ_MBA_NONRECOVERABLE_ERROR
              [10]  MBACALFIRQ_SM_1HOT_ERR
        IOM0.IOM_PHY0_DDRPHY_FIR_REG          // 0x07011000         // use SCOM1 (AND) 0x07011001 for clearing
              [54]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_0
              [55]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_1
              [56]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_2
              [57]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_3
              [58]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_4
              [59]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_5
              [60]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_6
              [61]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_7

    mss::unmask::after_phy_reset
      // *MASK must be always written as a last one, otherwise we may get unintended actions
      MC01.MCBIST.MBA_SCOMFIR.MCBISTFIRACT0             // 0x07012306
            [2]   MCBISTFIRQ_INTERNAL_FSM_ERROR =       0
            [13]  MCBISTFIRQ_SCOM_RECOVERABLE_REG_PE =  0
            [14]  MCBISTFIRQ_SCOM_FATAL_REG_PE =        0
      MC01.MCBIST.MBA_SCOMFIR.MCBISTFIRACT1             // 0x07012307
            [2]   MCBISTFIRQ_INTERNAL_FSM_ERROR =       0
            [13]  MCBISTFIRQ_SCOM_RECOVERABLE_REG_PE =  1
            [14]  MCBISTFIRQ_SCOM_FATAL_REG_PE =        0
      MC01.MCBIST.MBA_SCOMFIR.MCBISTFIRMASK             // 0x07012303
            [2]   MCBISTFIRQ_INTERNAL_FSM_ERROR =       0   // checkstop (0,0,0)
            [13]  MCBISTFIRQ_SCOM_RECOVERABLE_REG_PE =  0   // recoverable_error (0,1,0)
            [14]  MCBISTFIRQ_SCOM_FATAL_REG_PE =        0   // checkstop (0,0,0)

      // No magic, so cannot be merged with previous function
      for each functional MCA
        MC01.PORT0.SRQ.MBACALFIR_ACTION0              // 0x07010906
              [0]   MBACALFIR_MASK_MBA_RECOVERABLE_ERROR =    0
              [1]   MBACALFIR_MASK_MBA_NONRECOVERABLE_ERROR = 0
              [4]   MBACALFIR_MASK_RCD_PARITY_ERROR =         0
              [10]  MBACALFIR_MASK_SM_1HOT_ERR =              0
        MC01.PORT0.SRQ.MBACALFIR_ACTION1              // 0x07010907
              [0]   MBACALFIR_MASK_MBA_RECOVERABLE_ERROR =    1
              [1]   MBACALFIR_MASK_MBA_NONRECOVERABLE_ERROR = 0
              [4]   MBACALFIR_MASK_RCD_PARITY_ERROR =         1
              [10]  MBACALFIR_MASK_SM_1HOT_ERR =              0
        MC01.PORT0.SRQ.MBACALFIR_MASK                 // 0x07010903
              [0]   MBACALFIR_MASK_MBA_RECOVERABLE_ERROR =    0   // recoverable_error (0,1,0)
              [1]   MBACALFIR_MASK_MBA_NONRECOVERABLE_ERROR = 0   // checkstop (0,0,0)
              [4]   MBACALFIR_MASK_RCD_PARITY_ERROR =         0   // recoverable_error (0,1,0)
              [10]  MBACALFIR_MASK_SM_1HOT_ERR =              0   // checkstop (0,0,0)
        IOM0.IOM_PHY0_DDRPHY_FIR_ACTION0_REG          // 0x07011006
              [54]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_0 = 0
              [55]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_1 = 0
              [57]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_3 = 0   // no ERROR_2
              [58]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_4 = 0
              [59]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_5 = 0
              [60]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_6 = 0
              [61]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_7 = 0
        IOM0.IOM_PHY0_DDRPHY_FIR_ACTION1_REG          // 0x07011007
              [54]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_0 = 1
              [55]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_1 = 1
              [57]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_3 = 1
              [58]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_4 = 1
              [59]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_5 = 1
              [60]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_6 = 1
              [61]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_7 = 1
        IOM0.IOM_PHY0_DDRPHY_FIR_MASK_REG             // 0x07011003
              [54]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_0 = 0   // recoverable_error (0,1,0)
              [55]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_1 = 0   // recoverable_error (0,1,0)
              [57]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_3 = 0   // recoverable_error (0,1,0)
              [58]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_4 = 0   // recoverable_error (0,1,0)
              [59]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_5 = 0   // recoverable_error (0,1,0)
              [60]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_6 = 0   // recoverable_error (0,1,0)
              [61]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_7 = 0   // recoverable_error (0,1,0)

## mss_draminit: Dram initialize (13.10)

> a) p9_mss_draminit.C (mcbist) -- Nimbus
> b) p9c_mss_draminit.C (mba) -- Cumulus
>    - RCD parity errors are checked before logging other errors - HWP will exit with RC
>    - De-assert dram reset
>    - De-assert bit (Scom) that forces mem clock low - dram clocks start
>    - Raise CKE
>    - Load RCD Control Words
>    - Load MRS - for each dimm pair/ports/rank
>      - ODT Values
>      - MR0-MR6
> c) Check for attentions (even if HWP has error)
>    - FW
>      - Call PRD
>        - If finds and error, commit HWP RC as informational
>        - Else commit HWP RC as normal
>      - Trigger reconfig loop is anything was deconfigured

for each functional MCBIST
  MC01.MCBIST.MBA_SCOMFIR.CCS_MODEQ               // 0x070123A7
        // "It's unclear if we want to run with this true or false. Right now (10/15) this
        // has to be false. Shelton was unclear if this should be on or off in general BRS"
        [0]   CCS_MODEQ_CCS_STOP_ON_ERR =           0
        [1]   CCS_MODEQ_CCS_UE_DISABLE =            0
        [24]  CCS_MODEQ_CFG_CCS_PARITY_AFTER_CMD =  1
        [26]  CCS_MODEQ_COPY_CKE_TO_SPARE_CKE =     1   // Docs: "Does not apply for POWER9. No spare chips to copy to."

  for each functional MCA
    MC01.PORT0.SRQ.MBA_FARB5Q                     // 0x07010918
          // RESET_N should stay low for at least 200us (JEDEC fig 7) for cold boot. Who and when sets it low?
          // "Up, down P down, up N. Somewhat magic numbers - came from Centaur and proven to be the
          // same on Nimbus. Why these are what they are might be lost to time ..."
          [0-1] MBA_FARB5Q_CFG_DDR_DPHY_NCLK =          0x1     // 0b01     // 2nd RMW
          [2-3] MBA_FARB5Q_CFG_DDR_DPHY_PCLK =          0x2     // 0b10     // 2nd RMW
          [4]   MBA_FARB5Q_CFG_DDR_RESETN =             1                   // 3rd RMW (optional (?), only if changes)
          [5]   MBA_FARB5Q_CFG_CCS_ADDR_MUX_SEL =       1                   // 1st RMW (optional, only if changes)
          [6]   MBA_FARB5Q_CFG_CCS_INST_RESET_ENABLE =  0                   // 1st RMW (optional, only if changes)
    delay(500us)  // part of 3rd RMW, but delay is unconditional

  // JEDEC, fig 7,8: delays above and below end at the same point, they are not consecutive.
  // RDIMM spec says that clocks must be stable for 16nCK before RESET_n = 1. This is not explicitly ensured.
  // Below seems unnecessary, we are starting clocks at the same time as deasserting reset (are we?)
  delay(10ns)   // max(10ns, 5tCK), but for all DDR4 Speed Bins 10ns is bigger - JEDEC

  // draminit_cke_helper - this is done only for the first functional MCA because CCS_ADDR_MUX_SEL is set
  for first functional MCA
    // All of this may be used later, maybe creating a function is in order
    // Hostboot stops CCS before sending new programs. I'm not sure it is wise to do, unless there are infinite loops
    // MC01.MCBIST.MBA_SCOMFIR.CCS_CNTLQ          // 0x070123A5
    //        [all] 0
    //        [1]   CCS_CNTLQ_CCS_STOP = 1
    // timeout(50*10ns):
    //    if MC01.MCBIST.MBA_SCOMFIR.CCS_STATQ[0] (CCS_STATQ_CCS_IP) != 1: break          // 0x070123A6
    //    delay(10ns)

    MC01.MCBIST.CCS.CCS_INST_ARR0_00              // 0x07012315
          [all]   0
          // "ACT is high. It's a no-care in the spec but it seems to raise questions when
          // people look at the trace, so lets set it high."
          [20]    CCS_INST_ARR0_00_CCS_DDR_ACTN =     1
          // "CKE is high Note: P8 set all 4 of these high - not sure if that's correct. BRS"
          [24-27] CCS_INST_ARR0_00_CCS_DDR_CKE =      0xf
          [32-33] CCS_INST_ARR0_00_CCS_DDR_CSN_0_1 =  3
          [36-37] CCS_INST_ARR0_00_CCS_DDR_CSN_2_3 =  3
    MC01.MCBIST.CCS.CCS_INST_ARR1_00              // 0x07012335
          [all]   0
          // According to comments, 400 comes from JEDEC, but I have not seen this value anywhere.
          // What I have seen is tXPR = max(5nCK, tRFC(min) + 10ns). We can discard 5nCK, in any sane configuration
          // it is always smaller than the rest (this is probably defined to cover DLL off mode). tRFC(min) depends
          // on the memory density, it is 160, 260 or 350ns for 2, 4, 8Gb, respectively (16Gb has default and two
          // optional values, but it isn't supported by platform anyway). Unless we want to check memory density
          // here for each DIMM under MCBIST, we should use worst case of 350+10=360ns. This needs to be converted
          // to memory cycles, which (obviously) depends on the memory frequency. Average clock period tCK(avg)
          // varies from <1.5ns (max period for DDR4-1600) to 0.625ns (min period for DDR4-3200), using these numbers
          // we get from 240 to 576 cycles. Calculating backwards, 400 cycles would meet tXPR criteria for tCK = 0.9ns,
          // which is just below the middle of DDR4-2400 Speed Bin for 8Gb (meaning 2400MT/s will work, but 2666MT/s
          // may not, depending on the safety margin used by vendor). For 4Gb density (tXPR = 270ns) with 400 cycles
          // we get tCK = 0.675ns, which lands in DDR4-3200 bin, 2Gb density easily covers all defined DDR4 bins.
          // On the other hand, we wouldn't want to wait for almost 600 cycles on lower speeds...
          //
          // tl;dr version: for 400 cycles
          // - all 2Gb and 4Gb DIMMs should work
          // - 8Gb DIMMs <= 2400MT/s should work
          // - these are guaranteed by spec, rest depends on margins used by vendors
          //
          // -1 is there because CCS does not wait for IDLES for the last command before clearing IP (in progress) bit,
          // so we must use one separate DES instruction at the end
          [0-15]  CCS_INST_ARR1_00_IDLES =    400 - 1
          [59-63] CCS_INST_ARR1_00_GOTO_CMD = 1

    --------------- begin of CCS finalization and execution ----------------
    // Final DES
    MC01.MCBIST.CCS.CCS_INST_ARR0_01              // 0x07012316
          [all]   0
          // "ACT is high. It's a no-care in the spec but it seems to raise questions when
          // people look at the trace, so lets set it high."
          [20]    CCS_INST_ARR0_00_CCS_DDR_ACTN =     1
          // "CKE is high Note: P8 set all 4 of these high - not sure if that's correct. BRS"
          [24-27] CCS_INST_ARR0_00_CCS_DDR_CKE =      0xf
          [32-33] CCS_INST_ARR0_00_CCS_DDR_CSN_0_1 =  3
          [36-37] CCS_INST_ARR0_00_CCS_DDR_CSN_2_3 =  3
    MC01.MCBIST.CCS.CCS_INST_ARR1_01              // 0x07012336
          [all]   0
          [58]    CCS_INST_ARR1_00_CCS_END = 1
    // Select ports
    MC01.MCBIST.MBA_SCOMFIR.MCB_CNTLQ             // 0x070123DB
          // Broadcast mode is not supported, set only one bit at a time
          [2-5]   MCB_CNTLQ_MCBCNTL_PORT_SEL = bitmap with MCA index  // not always 0x8 (port 0), it may not be functional

    // Lets go
    MC01.MCBIST.MBA_SCOMFIR.CCS_CNTLQ          // 0x070123A5
          [all] 0
          [0]   CCS_CNTLQ_CCS_START = 1
    // Note that these timeouts may be different for different CCS invocations
    delay(400 memclocks)  // initial delay of poll method, maybe it should be slightly lower? Code execution takes time
    timeout(50*10ns):
      if MC01.MCBIST.MBA_SCOMFIR.CCS_STATQ[0] (CCS_STATQ_CCS_IP) != 1: break          // 0x070123A6
      delay(10ns)
    if MC01.MCBIST.MBA_SCOMFIR.CCS_STATQ != 0x40..00: report failure  // only [1] set, others 0
    --------------- end of CCS finalization and execution ----------------


    cleanup_from_execute()  - no-op if not LRDIMM_CAPABLE

  // "Per conversation with Shelton and Steve, turn off addr_mux_sel after the CKE CCS but before the RCD/MRS CCSs"
  // TODO: is the last DES being repeated still after this? We need CKE high later so RCD stays on, and also for DRAM
  // per specification CKE must stay high until the initialization sequence is finished, including tZQinit and tDLLK.
  // Is there any way for us to test it? Or is there someone who knows?
  for each functional MCA
    MC01.PORT0.SRQ.MBA_FARB5Q                     // 0x07010918
          [5]   MBA_FARB5Q_CFG_CCS_ADDR_MUX_SEL = 0

  // Load RCD control words
  for each functional MCA
    rcd_load(MCA)
      // Hostboot supposedly is data-driven, however, most of the times it is the code that prepares that data. See e.g.
      // src/import/chips/p9/procedures/hwp/memory/lib/dimm/eff_dimm.C. It is full of (get attr, attr[port][dimm] = const,
      // set attr) sequences. Sometimes the value depends on e.g. memory frequency or timings, usually read from SPD data.
      // Sometimes values are unnecessarily converted multiple times between micro-/nano-/picoseconds and memory cycles.
      // This is also true for Register Control Words.
      //
      // There are two ways of accessing RCWs: in-band on the memory channel as an MRS command ("MR7") or through I2C.
      //
      // From JESD82-31: "For changes to the control word setting, (...) the controller needs to wait tMRD after
      // _the last control word access_, before further access _to the DRAM_ can take place".
      // MRS is passed to rank 0 of the DRAM, but MR7 is reserved so it is ignored by DRAM. tMRD (8nCK) applies here,
      // unless longer delay is needed for RCWs which control the clock timing (see JESD82-31 for list of such). This
      // makes sense from DRAMs point of view, however we are talking to the Registering Clock Driver (RCD), not DRAM.
      // From parts marked in the sentence above one may assume that only one delay at the end is necessary and RCWs
      // can be written back to back; however, in the same document in table 141 tMRD is defined as "Number of clock
      // cycles between two control word accesses, MRS accesses, or any DRAM commands".
      //
      // I2C access to RCWs is required to support byte writes, and writes in blocks of up to double word (32b) size.
      // Bigger blocks are not required. Reads must always be 32b, 32b-aligned blocks, even when read as bytes. RCD
      // ignores the two lowest bits so unaligned accesses would return shifted values. RCWs are tightly packed in I2C
      // space, so it is not possible to write just one 4b RCW without writing its neighbor. This is especially
      // important for F0RC06 - Command Space Control Word, as it it able to reset the state of RCD. For this reason,
      // the mentioned register has NOP command (all 1's). JESD82-31 does not specify timeouts required for such
      // multi-RCWs writes, or any other writes. These are not MRS accesses, so it would be strange to apply those
      // timeouts. Perhaps only the registers that actually change the clock settings require time to stabilize.
      // On the other hand, I2C is relatively slow, so it is possible that the write itself is long enough.
      // RCD I2C address is 0xBx, it should be located on the same bus as SPD (number 3 in Petitboot). It uses a bit
      // unusual bus command encoding, see section 3.3 in JESD82-31 and/or `scripts/rcd_i2c_dump.sh` in this repository
      // for an example of reading and writing register values.
      // TODO: calculate whether we need additional timeouts.
      // TODO2: do we need draminit_cke_helper() when using I2C access, too? Maybe it should be done after RCD is set?
      //
      // From a comment in the code:
      // > Secret sauce : insider knowledge
      // > The JEDEC spec doesn't mention anything about ordering of RCWs
      // > but a supplier informed us that we need to send with CKE low:
      // > 4-bit RCWs first (excluding RC09), followed by 8-bit RCWs.
      // > Then with CKE high (We raise it w/the RCW): 4-bit RC09
      // This may come from an older version of spec, JESD82-31A precises (second paragraph in 2.23) that CKE is
      // "don't care" as long as CKE power down feature is disabled. This is the default setting, it is controlled
      // by a bit in F0RC09, which is why it works when this register is written as the last one. This may also be
      // somehow connected with "BUG?" in MC01.MCBIST.CCS.CCS_INST_ARR0_00 and MC01.MCBIST.CCS.CCS_INST_ARR0_01.
      //
      // > You're probably asking "Why always turn off CKE's? What is this madness?"
      // > Well, due to a vendor sensitivity, we need to have the CKE's off until we run RC09 at the very end
      // > Unfortunately, we need to have the CKE's off on the DIMM we are running second
      // > We also don't want to turn off the CKE's on the DIMM we are running first
      // > Therefore, we want to setup all RCW commands to have CKE's off across both DIMM's
      // > We then manually turn on the CKE's associated with a specific DIMM
      //
      // I2C probably doesn't have to have CKE set to any particular value.
      //
      // Except for F0RC09, EVERY other register is written once, in order. It doesn't make any sense for registers
      // F0RC4x, F0RC5x and F0RC6x. These are used as a windowed access to other Function spaces (F1, F2, ... F15),
      // and the access itself is initiated by a command written to F0RC06. Host is responsible for putting DRAM in
      // the MPR mode before sending read command, and issuing the MPR read operation after that command. Writes are
      // performed by the RCD.
      //
      // Registers in Hostboot are loaded with the help of CCS. Here are just their values, for loading procedure see
      // src/import/chips/p9/procedures/hwp/memory/lib/dimm/ddr4/control_word_ddr4.H or use I2C. Default values are
      // all 0s on reset. Note these registers are little endian, bit 0 is LSB, the same goes for SPD data.
      //
      // Before accessing RCWs Hostboot drives CKE low by sending PDE command (Power Down Entry). Probably not needed
      // for I2C.
      F0RC00  = 0x0   // depends on reference raw card used, sometimes 0x2 (ref. A, B, C and custom?)
                      // Maybe SPD bytes 137 and 138 can tell this?
      F0RC01  = 0x0   // depends on reference raw card used, sometimes 0xC (ref. C?). JESD82-31: "The system must
                      // read the module SPD to determine which clock outputs are used by the module", but which
                      // bytes? We can also download ref cards schematics and see which clock signals are connected.
      F0RC02  =
          [0] = 1 if(!(16Gb density && x4 width))     // disable A17?     // Why not use SPD[5]?
                      // Hostboot waits for tSTAB, however it is not necessary as long as bit 3 is not changed.
      F0RC03  =
          [0-1] SPD[137][4-5]   // Address/Command drive strength
          [2-3] SPD[137][6-7]   // CS drive strength
                      // There is also a workaround for NVDIMM hybrids, not needed for plain RDIMM
      F0RC04  =
          // BUG? Hostboot reverses bitfields order for RC04, 05
          [0-1] SPD[137][2-3]   // ODT drive strength
          [2-3] SPD[137][0-1]   // CKE drive strength
                      // There is also a workaround for NVDIMM hybrids, not needed for plain RDIMM
      F0RC05  =
          [0-1] SPD[138][2-3]   // Clocks drive strength, A side (1,3)
          [2-3] SPD[138][0-1]   // Clocks drive strength, B side (0,2)
                      // There is also a workaround for NVDIMM hybrids, not needed for plain RDIMM
      F0RC06  = 0xf   // This is a command register, either don't touch it or use NOP (F)
      F0RC07  = 0x0   // This is a command register, either don't touch it or use NOP (0)
      F0RC08  =
          [0-1] =
              1 if master ranks == 4 (SPD[12])        // C0 and C1 enabled      // master rank AKA package rank
              3 if not 3DS (check SPD[6] and SPD[10]) // all disabled
              2 if slave ranks <= 2                   // C0 enabled             // slave rank AKA logical rank...
              1 if slave ranks <= 4                   // C0 and C1 enabled      // ...SPD[6] Die Count
              0 otherwise (3DS with 5-8 slave ranks)  // C0, C1 and C2 enabled
          [3] = 1 if(!(16Gb density && x4 width))     // disable A17?     // Why not use SPD[5]?
      F0RC09  =
          [2] =
              // TODO: add test for it. Maybe leave it as 0 for now, this is "just" for power saving.
              0 if this DIMM's ODTs are used for writes or reads that target the other DIMM on the same port
              1 otherwise
          [3] = 1     // Register CKE Power Down. CKE must be high at the moment of writing to this register and stay high.
                      // TODO: For how long? Indefinitely, tMRD, tInDIS, tFixedOutput or anything else?
      F0RC0A  =
          [0-2] =     // There are other valid values not used by Hostboot
              1 if 1866 MT/s
              2 if 2133 MT/s
              3 if 2400 MT/s
              4 if 2666 MT/s
      F0RC0B  = 0xe   // External VrefCA connected to QVrefCA and BVrefCA
      F0RC0C  = 0     // Normal operating mode
      F0RC0D  =
          [0-1] =         // CS mode
              3 if master ranks == 4 (SPD[12])    // encoded QuadCS
              0 otherwise                         // direct DualCS
          [2] = 1         // RDIMM
          [3] = SPD[136]  // Address mirroring for MRS commands
      F0RC0E  = 0xd     // Parity enable, ALERT_n assertion and re-enable
      F0RC0F  = 0       // Normal mode
      F0RC1x  = 0       // Normal mode, VDD/2
      F0RC2x  = 0       // Normal mode, all I2C accesses enabled
      F0RC3x  =
              0x1f if 1866 MT/s
              0x2c if 2133 MT/s
              0x39 if 2400 MT/s
              0x47 if 2666 MT/s
      F0RC4x  = 0       // Should not be touched at all, it is used to access different function spaces
      F0RC5x  = 0       // Should not be touched at all, it is used to access different function spaces
      F0RC6x  = 0       // Should not be touched at all, it is used to access different function spaces
      F0RC7x  = 0       // Value comes from VPD, 0 is default, it doesn't seem to be changed anywhere in the code...
      F0RC8x  = 0       // Default QxODT timing for reads and for writes
      F0RC9x  = 0       // QxODT not asserted during writes, all ranks
      F0RCAx  = 0       // QxODT not asserted during reads, all ranks
      F0RCBx  =
          [0-2] =       // Note that only the first line is different than F0RC08 (C0 vs. C0 & C1)
              6 if master ranks == 4 (SPD[12])        // C0 enabled             // master rank AKA package rank
              7 if not 3DS (check SPD[6] and SPD[10]) // all disabled
              6 if slave ranks <= 2                   // C0 enabled             // slave rank AKA logical rank...
              4 if slave ranks <= 4                   // C0 and C1 enabled      // ...SPD[6] Die Count
              0 otherwise (3DS with 5-8 slave ranks)  // C0, C1 and C2 enabled

      // After all RCWs are set, DRAM gets reset "to ensure it is reset properly". Can we ever avoid it?
      // Comment: "Note: the minimum for a FORC06 soft reset is 32 cycles, but we empirically tested it at 8k cycles"
      // Shouldn't we rather wait (again!) for periods defined in JESD79-4C? (200us low and 500us high)
      F0RC06 = 0x2      // Set QRST_n to active (low)
      delay(8000 memclocks)
      F0RC06 = 0x3      // Set QRST_n to inactive (high)
      delay(8000 memclocks)

      // Dumped values from currently installed DIMM, from Petitboot:
      // 0xc7 0x18 0x42 0x00 0x00 0x00 0x00 0x00    VID[2], DID[2], RID[1], 3x reserved
      // 0x02 0x01 0x00 0x03 0xcb 0xe4 0x40 0x0d    F0RC00-0F (4b each)
      // 0x00 0x00 0x47 0x00 0x00 0x00 0x00 0x00    F0RC1x-8x (8b each)
      // 0x00 0x00 0x07                             F0RC9x-Bx (8b each), then all zeroes (Error Log Registers)

      mss::ccs::workarounds::hold_cke_high()
        // In Hostboot, all of the above RCW instructions are not executed yet at this point. This function iterates
        // over all of them and latches CKE high after it is first set high (which should be RC09) for all instructions
        // that follow. Since I2C access does not depend on CKE, perhaps we may ignore it and leave CKE high at all
        // times. Note that CKE was set high in draminit_cke_helper and should still be in this state, unless unsetting
        // CCS_ADDR_MUX_SEL or CCS completion changes it.
        //
        // My suggestion is to not touch CKE after draminit_cke_helper() and see if it works. If not, try doing DES with
        // CKE high after/instead of delays after toggling QRST_n in F0RC06.

  // Load data buffer control words (BCW)
  bcw_load(i_target) - not LRDIMM -> no data buffers

  // Load MRS
  mrs_load(i_target)
    // Programming the Mode Registers consists of entering special mode using MRS (Mode Register Set) command and sending
    // MR# values, one at a time, in a specific order (3,6,5,4,2,1,0). Those values are sent using address lines,
    // including bank and bank group lines, which select which MR to write to. One of the implications is that these
    // values cannot be read back. PHY controller holds the mirrors of last written values in its registers, but the
    // mapping of bits is not clear. This mirror is RW, so there is a possibility that the values are not the same as the
    // real ones (but this would be a bad idea as these bits are used by a controller). It gets further complicated when
    // PDA mode was used at any point, as there is just one mirror register per rank pair.
    //
    // We have to write a whole register even when changing just one bit, this means that we have to remember what was
    // written, or be able to (re)generate valid data. For this platform we have CCS which can be programmed to push all
    // MRs in one sequence of instructions, including all required timeouts. There are two main timeout parameters: tMRD
    // (minimal amount of time between two MRS commands) and tMOD (time between MRS and non-MRS and non-DES command). For
    // all Speed Bins tMRD = 8nCK, tMOD = max(24nCK, 15ns) = 24nCK. Exceptions to those are:
    // - gear down mode
    // - PDA mode
    // - settings to command & address lines: C/A parity latency, CS to C/A latency (only tMRC doesn't apply)
    // - VrefDQ training
    // - DLL Enable, DLL Reset (only tMOD doesn't apply)
    // - maximum power saving mode (only tMOD doesn't apply)
    //
    // MRS are written per rank usually, although most of them must have the same values across the DIMM or even port.
    // There are some settings that apply to individual DRAMs instead of whole rank (e.g. Vref in MR6). Normally settings
    // written to MR# are passed to each DRAM, if individual DRAM has to have its settings changed independently of others
    // we must use Per DRAM Addressability (PDA) mode. PDA is possible only if write leveling was performed.
    //
    // CCS is per MCBIST, so we need at most 4 (ports) * 2 (DIMMs per port) * 2 (master ranks per DIMM, is 4 ranks on
    // RDIMM possible/used? PHY supports two ranks per DIMM) * 2 (A- and B-side) * (7 (# of MRS) + 1 (final DES)) = 256
    // instructions. CCS holds space for 32 instructions, so we have to divide it and send a set of instructions per
    // DIMM or even smaller chunks.
    //
    // Just the MR# values, send each one in this order using procedure described below. Remember about address mirroring!
    // These bits are also in little endian order. All multi-bit fields must be swizzled.
    --------------------------------------------------
    MR3 =
      [all] 0
      [A3]      1 if 2N mode      // Geardown Mode. Is this why Hostboot doubles tMRD and tMOD?
      [A10-A9]  1                 // CRC to WR latency. 1 = 5nCK for 1600 < freq <= 2666.
      [A8-A6]   0                 // Fine Granularity Refresh. Default 0, depends on MR4[A3]. Attr in MRW, whatever that is.
                                  // On-the-fly FGR is not supported on RDIMM.
      [A5]      0                 // Temp readout. It is 0, won't it impact `sensors`?
    MR6 =
      [all] 0
      [A5-A0]   ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x3f       // This is "don't care" when A7 is not set
      [A6]      ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x40       // This is "don't care" when A7 is not set
      // BUG? Hostboot doesn't take into account minimal values per freq from JESD79-4C
      // Keep in mind that SPD[40] is unsigned MTB and SPD[117] is signed FTB
      [A12-A10] (conv_to_nCK(SPD[40] + SPD[117])) - 4
    MR5 =
      [all] 0
      // ATTR_MSS_VPD_MT_DRAM_RTT_PARK is saved as a value in Ohms. JEDEC uses seemingly strange mapping to describe
      // these values in MR5, however there is some logic to it. All possible values are (240/N) Ohms, where N is between
      // 1 and 7. This N is a value saved into MR5, with reversed bit order, so 60 = 240/4 => 0b001, 80 = 240/3 => 0b110
      // etc, so just don't swizzle this field. A value of 0 (both in VPD as well as in MR5) disables RTT_PARK.
      [A6-A8] 240/ATTR_MSS_VPD_MT_DRAM_RTT_PARK     // integer division rounds properly for 7/34 (watch out for 0)
    MR4 =
      [all] 0
      // code style BUG: src/import/chips/p9/procedures/hwp/memory/lib/dimm/ddr4/mrs04.C#65 uses wrong enum, not harmful
      [A2]  0         // ATTR_MSS_MRW_TEMP_REFRESH_RANGE, default 0
      [A3]  0         // ATTR_MSS_MRW_TEMP_REFRESH_MODE, default 0, impacts MR3[A8-A6]: if this == 0 then MR3[A8-A6] = 0
      [A11] (ATTR_MSS_VPD_MT_PREAMBLE & 0xf0) >> 4
      [A12] (ATTR_MSS_VPD_MT_PREAMBLE & 0x0f)
    MR2 =
      [all] 0
      [A5-A3] =
          if (ATTR_MSS_VPD_MT_PREAMBLE & 0x0f) == 1:    // 2nCK write preamble
            4 if 2400 MT/s      // CWL = 14
            5 if 2666 MT/s      // CWL = 16
          if (ATTR_MSS_VPD_MT_PREAMBLE & 0x0f) == 0:    // 1nCK write preamble
            1 if 1866 MT/s      // CWL = 10
            2 if 2133 MT/s      // CWL = 11
            3 if 2400 MT/s      // CWL = 12
            4 if 2666 MT/s      // CWL = 14
      [A7-A6] =   // Low Power Auto Self Refresh, doesn't use Auto, just Manual mode (normal or extended temp range)
          0 if ATTR_MSS_MRW_REFRESH_RATE_REQUEST == ATTR_MSS_MRW_REFRESH_RATE_REQUEST_SINGLE*
          2 if ATTR_MSS_MRW_REFRESH_RATE_REQUEST == ATTR_MSS_MRW_REFRESH_RATE_REQUEST_DOUBLE*
      // ATTR_MSS_VPD_MT_DRAM_RTT_WR is also saven in Ohms, however this time there is no logic when it comes to
      // VPD<->MR2 mapping. It seems as if JEDEC added third bit later.
      // '0' seems to be the safest option, but it is not always the case in VPD.
      // See "Write leveling - pre-workaround" (and post-workaround) in 13.11, maybe write 0 here and don't do pre-?
      // VPD    MR2
      // 0      0b000     Dynamic ODT Off
      // 80     0b100     RZQ/3
      // 120    0b001     RZQ/2
      // 240    0b010     RZQ/1
      // 1      0b011     Hi-Z
      [A11-A9]  f(ATTR_MSS_VPD_MT_DRAM_RTT_WR)
      [A12]     ATTR_MSS_MRW_DRAM_WRITE_CRC
    MR1 =
      [all] 0
      [A0]      1       // DLL Enable. There is a note about reversed states in JESD79-4C, not sure what this is about...
      [A2-A1] =         // Output Driver Impedance Control
          0 if ATTR_MSS_VPD_MT_DRAM_DRV_IMP_DQ_DQS == ENUM_ATTR_MSS_VPD_MT_DRAM_DRV_IMP_DQ_DQS_OHM34  // 34 in VPD
          1 if ATTR_MSS_VPD_MT_DRAM_DRV_IMP_DQ_DQS == ENUM_ATTR_MSS_VPD_MT_DRAM_DRV_IMP_DQ_DQS_OHM48  // 48 in VPD
      // ATTR_MSS_VPD_MT_DRAM_RTT_NOM is saved as a value in Ohms. JEDEC uses seemingly strange mapping to describe
      // these values in MR1, however there is some logic to it. All possible values are (240/N) Ohms, where N is between
      // 1 and 7. This N is a value saved into MR5, with reversed bit order, so 60 = 240/4 => 0b001, 80 = 240/3 => 0b110
      // etc, so just don't swizzle this field. A value of 0 (both in VPD as well as in MR5) disables RTT_PARK.
      // See also ATTR_MSS_VPD_MT_DRAM_RTT_PARK in MR5.
      [A8-A10]  240/ATTR_MSS_VPD_MT_DRAM_RTT_NOM      // integer division rounds properly for 7/34 (watch out for 0)
      [A11] =
          1 if x8     // SPD[12][0-2] == 1
          0 if x4     // SPD[12][0-2] == 0
    // MR0 has two non-contiguous bit fields, numbers in brackets are sorted MSB to LSB.
    MR0 =
      [all] 0
      // Common for all DIMMs in this domain (?), calculated in istep 7.3, encoded! Values are not in order.
      [A12,A6-A4,A2]  CAS Latency
      [A8]            1             // DLL Reset, "Default is to reset DLLs during IPL"
      // JESD79-4C also specifies min of 15ns, we should probably use max of those two values. Field is encoded,
      // not 1:1, and not in order! (values 22 and 24 are swapped)
      [A13,A11-A9]    tWR = conv_to_nCK(SPD[41-42])
    --------------------------------------------------

    for each DIMM
      // Procedure for sending MRS through CCS
      //
      // We need to remember about two things here:
      // - RDIMM has A-side and B-side, some address bits are inverted for B-side; side is selected by DBG1 (*)
      // - odd ranks may or may not have mirrored lines, depending on SPD[136].
      // *) When mirroring is enabled DBG0 is used for odd ranks to select side, instead of DBG1.
      //
      // Because of those two reasons we cannot simply repeat MRS data for all sides and ranks, we have to do some juggling
      // instead. Inverting is easy, we just have to XOR with appropriate mask (special case for A17, it is not inverted if
      // it isn't used). Mirroring will require manual bit manipulations, we cannot use two pairs of shift and mask because
      // A11/A13 and BG0/BG1 are not next to each other in the CCS instruction registers.
      //
      // There are no signals that are mirrored but not inverted, which means that the order of those operations doesn't
      // matter.
      --------------------------------------------------
      // Rank 2n, side A
      MC01.MCBIST.CCS.CCS_INST_ARR0_{00, 01, .., 31}    // 0x07012315 + N
            [all]   0
            [0-13]  CCS_INST_ARR0_00_CCS_DDR_ADDRESS_0_13 =   A0-A13 to be written to MR#
            [17-19] CCS_INST_ARR0_00_CCS_DDR_BANK_0_1, CCS_INST_ARR0_00_CCS_DDR_BANK_GROUP_0 = MR#    // swizzled!
            [20]    CCS_INST_ARR0_00_CCS_DDR_ACTN =           1
            // "CKE is high Note: P8 set all 4 of these high - not sure if that's correct. BRS"
            [24-27] CCS_INST_ARR0_00_CCS_DDR_CKE =            0xf
            // The encoding of CS signals in Hostboot seems like it would fail if DIMM1 has more ranks than DIMM0
            // Below depends on CS mode and which DIMM are we on:
            // In encoded QuadCS (i.e. when we have 4 master ranks) on DIMM0:
            //    - rank 0: CSN_0_1 = 0b01, CID_0_1 = 0b00, CSN_2_3 = 0b11
            //    - rank 1: CSN_0_1 = 0b01, CID_0_1 = 0b11, CSN_2_3 = 0b11
            //    - rank 2: CSN_0_1 = 0b10, CID_0_1 = 0b00, CSN_2_3 = 0b11
            //    - rank 3: CSN_0_1 = 0b10, CID_0_1 = 0b11, CSN_2_3 = 0b11
            // In direct DualCS on DIMM0:
            //    - rank 0: CSN_0_1 = 0b01, CID_0_1 = 0b00, CSN_2_3 = 0b11
            //    - rank 1: CSN_0_1 = 0b10, CID_0_1 = 0b00, CSN_2_3 = 0b11
            //    - rank 2: CSN_0_1 = 0b11, CID_0_1 = 0b00, CSN_2_3 = 0b01
            //    - rank 3: CSN_0_1 = 0b11, CID_0_1 = 0b00, CSN_2_3 = 0b10
            // On DIMM1 in both cases CSN_0_1 and CSN_2_3 are exchanged
            [32-33] CCS_INST_ARR0_00_CCS_DDR_CSN_0_1 =        see above
            [34-35] CCS_INST_ARR0_00_CCS_DDR_CID_0_1 =        see above
            [36-37] CCS_INST_ARR0_00_CCS_DDR_CSN_2_3 =        see above
      MC01.MCBIST.CCS.CCS_INST_ARR1_{00, 01, .., 31}    // 0x07012335 + N
            [all]   0
            // Timeout. This is tMRD (8nCK), except for the last one (MR0): tMOD (max(24nCK, 15ns)).
            // Hostboot uses doubled tMRD and tMOD values "to increase margin per lab request", it also waits for
            // tDLLK after the last write: "Adding Per Glancy's request, to ensure DLL locking time". The tDLLK is later
            // added again for ZQ calibration, one of these would be more than enough. Per spec, we need to wait for
            // tDLLK between write to MR0 and normal operation, we also need to wait for tZQinit between ZQCL (done in
            // next istep) and normal operation. This means that we need at least max(tDLLK, tMOD + tZQinit) between
            // write to MR0 and normal operation. tDLLK is lower than or equal to tZQinit for all defined DDR4 speed
            // bins, so we may use only tZQinit and forget about tDLLK altogether.
            //
            // Also, it is not clear if the delay is needed between A- and B-side:
            // > Not sure if we can get tricky here and only delay after the b-side MR. The question is whether the delay
            // > is needed/assumed by the register or is purely a DRAM mandated delay. We know we can't go wrong having
            // > both delays but if we can ever confirm that we only need one we can fix this. BRS
            //
            // TODO: test if all of this is needed, we may have 4x longer delays than necessary. Definitely tDLLK doesn't
            // have to be separated between sides (or even components higher in topology), however the worst case would
            // have to be used.
            [0-15]  CCS_INST_ARR1_00_IDLES =    see above
            [59-63] CCS_INST_ARR1_00_GOTO_CMD = (index of next command)
      // Rank 2n, side B
      MC01.MCBIST.CCS.CCS_INST_ARR0_{00, 01, .., 31}    // 0x07012315 + N
            [all]   0
            [0-13]  CCS_INST_ARR0_00_CCS_DDR_ADDRESS_0_13 =   (A0-A13 to be written to MR#) XOR (A3-A9,A11,A13)
            // A17 is low for all MRS commands, but here it is inverted. It is not clear if we can drive it high when it
            // is not used. If we can, we may just write 1 here always, which would simplify the code. Most likely this
            // would impact the electrical characteristics, as it wouldn't be terminated.
            [14]    CCS_INST_ARR0_02_CCS_DDR_ADDRESS_17 =     1 if used     // 16Gb density && x4 width, or check SPD[5]
            [15]    CCS_INST_ARR0_02_CCS_DDR_BANK_GROUP_1 =   1     // B side
            [17-19] CCS_INST_ARR0_00_CCS_DDR_BANK_0_1, CCS_INST_ARR0_00_CCS_DDR_BANK_GROUP_0 = ~(MR#)   // swizzled!
            [20]    CCS_INST_ARR0_00_CCS_DDR_ACTN =           1
            [24-27] CCS_INST_ARR0_00_CCS_DDR_CKE =            0xf
            [32-33] CCS_INST_ARR0_00_CCS_DDR_CSN_0_1 =        see above
            [34-35] CCS_INST_ARR0_00_CCS_DDR_CID_0_1 =        see above
            [36-37] CCS_INST_ARR0_00_CCS_DDR_CSN_2_3 =        see above
      MC01.MCBIST.CCS.CCS_INST_ARR1_{00, 01, .., 31}    // 0x07012335 + N
            [all]   0
            [0-15]  CCS_INST_ARR1_00_IDLES =    see above
            [59-63] CCS_INST_ARR1_00_GOTO_CMD = (index of next command)

      // Rank 2n+1, side A, only if rank is present
      MC01.MCBIST.CCS.CCS_INST_ARR0_{00, 01, .., 31}    // 0x07012315 + N
            [all]   0
            // Mirroring swaps the following bit pairs:
            //   A3 <->  A4
            //   A5 <->  A6
            //   A7 <->  A8
            //  A12 <-> A13
            //  BA0 <-> BA1
            //  BG0 <-> BG1
            // After mirroring, BG0 is the bit that chooses side B when set.
            [0-13]  CCS_INST_ARR0_00_CCS_DDR_ADDRESS_0_13 =   A0-A13 to be written to MR#, mirrored
            [15]    CCS_INST_ARR0_02_CCS_DDR_BANK_GROUP_1 =   MR#.BG0
            [17-18] CCS_INST_ARR0_00_CCS_DDR_BANK_0_1 =       MR#.BA_0_1, mirrored    // mirrored + swizzled = nop
            [20]    CCS_INST_ARR0_00_CCS_DDR_ACTN =           1
            [24-27] CCS_INST_ARR0_00_CCS_DDR_CKE =            0xf
            [32-33] CCS_INST_ARR0_00_CCS_DDR_CSN_0_1 =        see above
            [34-35] CCS_INST_ARR0_00_CCS_DDR_CID_0_1 =        see above
            [36-37] CCS_INST_ARR0_00_CCS_DDR_CSN_2_3 =        see above
      MC01.MCBIST.CCS.CCS_INST_ARR1_{00, 01, .., 31}    // 0x07012335 + N
            [all]   0
            [0-15]  CCS_INST_ARR1_00_IDLES =    see above
            [59-63] CCS_INST_ARR1_00_GOTO_CMD = (index of next command)

      // Rank 2n+1, side B, only if rank is present
      MC01.MCBIST.CCS.CCS_INST_ARR0_{00, 01, .., 31}    // 0x07012315 + N
            [all]   0
            [0-13]  CCS_INST_ARR0_00_CCS_DDR_ADDRESS_0_13 =   (A0-A13 to be written to MR#) XOR (A3-A9,A11,A13), mirrored
            [14]    CCS_INST_ARR0_02_CCS_DDR_ADDRESS_17 =     1 if used     // 16Gb density && x4 width, or check SPD[5]
            [15]    CCS_INST_ARR0_02_CCS_DDR_BANK_GROUP_1 =   ~MR#.BG0
            [17-18] CCS_INST_ARR0_00_CCS_DDR_BANK_0_1 =       ~(MR#.BA_0_1), mirrored   // mirrored + swizzled = nop
            [19]    CCS_INST_ARR0_02_CCS_DDR_BANK_GROUP_0 =   1   // B side
            [20]    CCS_INST_ARR0_00_CCS_DDR_ACTN =           1
            [24-27] CCS_INST_ARR0_00_CCS_DDR_CKE =            0xf
            [32-33] CCS_INST_ARR0_00_CCS_DDR_CSN_0_1 =        see above
            [34-35] CCS_INST_ARR0_00_CCS_DDR_CID_0_1 =        see above
            [36-37] CCS_INST_ARR0_00_CCS_DDR_CSN_2_3 =        see above
      MC01.MCBIST.CCS.CCS_INST_ARR1_{00, 01, .., 31}    // 0x07012335 + N
            [all]   0
            [0-15]  CCS_INST_ARR1_00_IDLES =    see above
            [59-63] CCS_INST_ARR1_00_GOTO_CMD = (index of next command)

      ...
      ... repeat for all ranks, all MRS commands
      ...

      --------------- do CCS finalization and execution, see draminit_cke_helper ----------------------

mss_post_draminit
  // This plays with attributes generated by src/usr/targeting/common/genHwsvMrwXml.pl based on XML files from
  // src/usr/targeting/common/xmltohb/. We need someone fluent in Perl to parse it probably...
  //
  // IIUC this function can change VDDR dynamically on some platforms, depending on OPENPOWER_VOLTMSG config option.
  // This option is nowhere to be found, but there is OPENPOWER_MEM_VOLT in src/usr/isteps/HBconfig, which seems to
  // have description similar to what OPENPOWER_VOLTMSG should be responsible for.
  //
  // There is a possibility that this is no-op on BMC-based platforms. Names of some variables suggest that a message
  // is sent to SP.


## mss_draminit_training: Dram training (13.11)

> a) p9_mss_draminit_training.C (mcbist) -- Nimbus
> b) p9c_mss_draminit_training.C (mba) -- Cumulus
>    - Prior to running this procedure will apply known DQ bad bits to prevent them from participating in training.
>      This information is extracted from the bad DQ attribute and applied to Hardware
>      - Marks the calibration fail array
>    - External ZQ Calibration
>    - Execute initial dram calibration (7 step - handled by HW)
>    - This procedure will update the bad DQ attribute for each dimm based on its findings

for each functional MCBIST
  if (count_dimms(MCBIST) == 0) go to next MCBIST

  // Configure the CCS engine
  // Deja vu, see 13.10. Maybe first 4 bits in this list are repeated only for simulation?
  MC01.MCBIST.MBA_SCOMFIR.CCS_MODEQ               // 0x070123A7
        // "It's unclear if we want to run with this true or false. Right now (10/15) this
        // has to be false. Shelton was unclear if this should be on or off in general BRS"
        [0]     CCS_MODEQ_CCS_STOP_ON_ERR =           0
        [1]     CCS_MODEQ_CCS_UE_DISABLE =            0
        [24]    CCS_MODEQ_CFG_CCS_PARITY_AFTER_CMD =  1
        [26]    CCS_MODEQ_COPY_CKE_TO_SPARE_CKE =     1 // Docs: "Does not apply for POWER9. No spare chips to copy to."
        // "Hm. Centaur sets this up for the longest duration possible. Can we do better?"
        // This is timeout so we should only hit it in the case of error. What is the unit of this field? Memclocks?
        [8-23]  CCS_MODEQ_DDR_CAL_TIMEOUT_CNT =       0xffff
        [30-31] CCS_MODEQ_DDR_CAL_TIMEOUT_CNT_MULT =  3

  // Clean out any previous calibration results, set bad-bits and configure the ranks
  for each functional MCA
    setup_and_execute_zqcal()
      for each DIMM, for each rank
        // Max instructions: 4 (ports per MCBIST) * 2 (DIMMs per port) * 2 (master ranks per DIMM) * 2 (sides) * 1 (ZQCL)
        // + 1 (final DES) = 33 instructions
        // TODO: do we have to do this for side A and side B? Probably yes, ZQ is for DRAM, not for RCD.
        // TODO: maybe "double buffering" CCS instruction array is an option? We can fill one half of the array, let it run,
        // fill the second half and only then poll for completion. When first half completes, we start the other half and
        // can begin filling next instructions in the half that is not used at the moment.
        //
        // JEDEC: "All banks must be precharged and tRP met before ZQCL or ZQCS commands are issued by the controller" -
        // not sure if this is met. A refresh during the calibration probably would impact the results. Also, "No other
        // activities should be performed on the DRAM channel by the controller for the duration of tZQinit, tZQoper,
        // or tZQCS" - this means we have to insert a delay after every ZQCL, not only after the last one. As a possible
        // improvement, we could reorder this step a bit and send ZQCL on all ports "simultaneously" (without delays)
        // and add a delay just between different DIMMs/ranks.
        MC01.MCBIST.CCS.CCS_INST_ARR0_{00, 01, .., 31}    // 0x07012315 + N
              [all]   0
              [10]    CCS_INST_ARR0_00_CCS_DDR_ADDRESS_10 =   1
              [20]    CCS_INST_ARR0_00_CCS_DDR_ACTN =         1
              [21]    CCS_INST_ARR0_00_CCS_DDR_ADDRESS_16 =   1
              [22]    CCS_INST_ARR0_00_CCS_DDR_ADDRESS_15 =   1
              [23]    CCS_INST_ARR0_00_CCS_DDR_ADDRESS_14 =   0
              [24-27] CCS_INST_ARR0_00_CCS_DDR_CKE =          0xf
              [32-33] CCS_INST_ARR0_00_CCS_DDR_CSN_0_1 =      see comment in 13.10
              [34-35] CCS_INST_ARR0_00_CCS_DDR_CID_0_1 =      see comment in 13.10
              [36-37] CCS_INST_ARR0_00_CCS_DDR_CSN_2_3 =      see comment in 13.10
        MC01.MCBIST.CCS.CCS_INST_ARR1_{00, 01, .., 31}    // 0x07012335 + N
              [all]   0
              // Timeout. This should be tZQinit, but Hostboot uses a bigger margin, and also includes tDLLK for the
              // second time here (first one was after MR0 was written, see also a comment in there). Total timeout in
              // Hostboot is 2*(tDLLK + tZQinit) which is 3-4x more than required, depending on frequency.
              [0-15]  CCS_INST_ARR1_00_IDLES =    1024    // tZQinit
              [59-63] CCS_INST_ARR1_00_GOTO_CMD = (index of next command)

        --------------- do CCS finalization and execution, see draminit_cke_helper ----------------------

    // ZQ calibration done, since now we no longer have to keep CKE high at all times

    IOM0.DDRPHY_PC_INIT_CAL_CONFIG0_P0 = 0      // 0x8000C0160701103F

    // > Disable port fails as it doesn't appear the MC handles initial cal timeouts
    // > correctly (cal_length.) BRS, see conversation with Brad Michael
    MC01.PORT0.SRQ.MBA_FARB0Q =                 // 0x0000000007010913
          [57]  MBA_FARB0Q_CFG_PORT_FAIL_DISABLE = 1

    // > The following registers must be configured to the correct operating environment:
    // > These are reset in phy_scominit
    // > Section 5.2.5.10 SEQ ODT Write Configuration {0-3} on page 422
    // > Section 5.2.6.1 WC Configuration 0 Register on page 434
    // > Section 5.2.6.2 WC Configuration 1 Register on page 436
    // > Section 5.2.6.3 WC Configuration 2 Register on page 438

    clear_initial_cal_errors()
      IOM0.DDRPHY_DP16_RD_VREF_CAL_ERROR_P0_0,      // 0x8000007A0701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_RD_VREF_CAL_ERROR_P0_1,
      IOM0.DDRPHY_DP16_RD_VREF_CAL_ERROR_P0_2,
      IOM0.DDRPHY_DP16_RD_VREF_CAL_ERROR_P0_3,
      IOM0.DDRPHY_DP16_RD_VREF_CAL_ERROR_P0_4,
      IOM0.DDRPHY_DP16_WR_ERROR0_P0_0,              // 0x8000001B0701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_WR_ERROR0_P0_1,
      IOM0.DDRPHY_DP16_WR_ERROR0_P0_2,
      IOM0.DDRPHY_DP16_WR_ERROR0_P0_3,
      IOM0.DDRPHY_DP16_WR_ERROR0_P0_4,
      IOM0.DDRPHY_DP16_RD_STATUS0_P0_0,             // 0x800000140701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_RD_STATUS0_P0_1,
      IOM0.DDRPHY_DP16_RD_STATUS0_P0_2,
      IOM0.DDRPHY_DP16_RD_STATUS0_P0_3,
      IOM0.DDRPHY_DP16_RD_STATUS0_P0_4,
      IOM0.DDRPHY_DP16_RD_LVL_STATUS2_P0_0,         // 0x800000100701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_RD_LVL_STATUS2_P0_1,
      IOM0.DDRPHY_DP16_RD_LVL_STATUS2_P0_2,
      IOM0.DDRPHY_DP16_RD_LVL_STATUS2_P0_3,
      IOM0.DDRPHY_DP16_RD_LVL_STATUS2_P0_4,
      IOM0.DDRPHY_DP16_RD_LVL_STATUS0_P0_0,         // 0x8000000E0701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_RD_LVL_STATUS0_P0_1,
      IOM0.DDRPHY_DP16_RD_LVL_STATUS0_P0_2,
      IOM0.DDRPHY_DP16_RD_LVL_STATUS0_P0_3,
      IOM0.DDRPHY_DP16_RD_LVL_STATUS0_P0_4,
      IOM0.DDRPHY_DP16_WR_VREF_ERROR0_P0_0,         // 0x800000AE0701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_WR_VREF_ERROR0_P0_1,
      IOM0.DDRPHY_DP16_WR_VREF_ERROR0_P0_2,
      IOM0.DDRPHY_DP16_WR_VREF_ERROR0_P0_3,
      IOM0.DDRPHY_DP16_WR_VREF_ERROR0_P0_4,
      IOM0.DDRPHY_DP16_WR_VREF_ERROR1_P0_0,         // 0x800000AF0701103F, +0x0400_0000_0000
      IOM0.DDRPHY_DP16_WR_VREF_ERROR1_P0_1,
      IOM0.DDRPHY_DP16_WR_VREF_ERROR1_P0_2,
      IOM0.DDRPHY_DP16_WR_VREF_ERROR1_P0_3,
      IOM0.DDRPHY_DP16_WR_VREF_ERROR1_P0_4,
            [all] 0

      IOM0.DDRPHY_APB_CONFIG0_P0 =                  // 0x8000D0000701103F
            [49]  RESET_ERR_RPT = 1, then 0     // toggle. It's ok to do just one read and two writes
      IOM0.DDRPHY_APB_ERROR_STATUS0_P0 =            // 0x8000D0010701103F
            [all] 0

      IOM0.DDRPHY_RC_ERROR_STATUS0_P0 =             // 0x8000C8050701103F
            [all] 0

      IOM0.DDRPHY_SEQ_ERROR_STATUS0_P0 =            // 0x8000C4080701103F
            [all] 0

      IOM0.DDRPHY_WC_ERROR_STATUS0_P0 =             // 0x8000CC030701103F
            [all] 0

      IOM0.DDRPHY_PC_ERROR_STATUS0_P0 =             // 0x8000C0120701103F
            [all] 0

      IOM0.DDRPHY_PC_INIT_CAL_ERROR_P0 =            // 0x8000C0180701103F
            [all] 0

      IOM0.IOM_PHY0_DDRPHY_FIR_REG SCOM1 (AND) =    // 0x0000000007011001
            [all] 1
            [56]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_2 = 0

    get_rank_pairs(MCA, l_pairs)        // described in 13.8

    dp16::reset_delay_values()    // configurable (?) based on ATTR_MSS_MRW_RESET_DELAY_BEFORE_CAL, by default do it (?)
      for each rp in l_pairs
        IOM0.DDRPHY_DP16_DQS_GATE_DELAY_RP<rp>_P0_0,      // 0x0x80000<rp>130701103F, +0x0400_0000_0000
        IOM0.DDRPHY_DP16_DQS_GATE_DELAY_RP<rp>_P0_1,
        IOM0.DDRPHY_DP16_DQS_GATE_DELAY_RP<rp>_P0_2,
        IOM0.DDRPHY_DP16_DQS_GATE_DELAY_RP<rp>_P0_3,
        IOM0.DDRPHY_DP16_DQS_GATE_DELAY_RP<rp>_P0_4 =
              [all] 0

    dqs_align::turn_on_refresh()      // workaround always enabled
      IOM0.DDRPHY_SEQ_MEM_TIMING_PARAM0_P0          // 0x8000C4120701103F
        // > May need to add freq/tRFI attr dependency later but for now use this value
        // > Provided by Ryan King
        [60-63] TRFC_CYCLES = 9             // tRFC = 2^9 = 512 memcycles = 384-640 ns (2666-1866MT/s, respectively)

      IOM0.DDRPHY_PC_INIT_CAL_CONFIG1_P0                  // 0x8000C0170701103F
        // > Hard coded settings provided by Ryan King for this workaround
        [48-51] REFRESH_COUNT =     0xf
        // TODO: see "Read clock align - pre-workaround" below. Why not 1 until calibration finishes? Does it pull in
        // refresh commands?
        [52-53] REFRESH_CONTROL =   3       // refresh commands may interrupt calibration routines
        [54]    REFRESH_ALL_RANKS = 1
        [55]    CMD_SNOOP_DIS =     0
        [57-63] REFRESH_INTERVAL =  0x13    // Worst case: 6.08us for 1866 (max tCK). Must be not more than 7.8us
        // When we want to preserve data in RAM the controller must send a refresh command every tREFI (7.8us) on average.
        // Up to 8 such commands may be postponed/pulled in in advance, which gives max of 9*tREFI between commands where
        // calibration may happen (minus the time required for refresh command to do its job - tRFC, depends on memory
        // density). With these in mind, max time for any calibration step should be no longer than 70us if we want to
        // preserve the contents of memory. However, due to conservative settings of TRFC_CYCLES and REFRESH_INTERVAL,
        // and the fact that an error is reported by the controller when internal counter overflows after 15 postponed
        // commands (see description of REFRESH_INTERVAL in the documentation) for 2666MT/s DIMMs this time falls down
        // below 50us. Max value for REFRESH_INTERVAL for 1866MT/s DIMMs that meets the 7.8us requirement is 24 (0x18).

    // List of calibration steps for RDIMM, in execution order:
    // - ZQ calibration - calibrates DRAM output driver and on-die termination values (already done)
    // - Write leveling - compensates for skew caused by a fly-by topology
    // - Initial pattern write - not exactly a calibration, but prepares patterns for next steps
    // - DQS align
    // - RDCLK align
    // - Read centering
    // - Write Vref latching - not exactly a calibration, but required for next steps
    // - Write centering
    // - Coarse write/read
    // - Custom read and/or write centering - performed in istep 13.12
    // Some of these steps have pre- or post-workarounds, or both.
    //
    // All of those steps (except ZQ calibration) are executed for each rank pair before going to the next pair. Some of
    // them require that there is no other activity on the controller so parallelization may not be possible.

    for each rp in l_pairs
      ===============================================================
      // Write leveling - pre-workaround
      // JEDEC spec requires disabling RTT_WR during WR_LEVEL, and enabling equivalent terminations
      //
      // All tests here are done for primary rank in a "pair" (which may have up to 4 ranks, because why not), however
      // they should be the same/similar, otherwise we can't group multiple ranks anyway. All settings must be saved in
      // registers for primary rank in group because DDR PHY applies settings from this rank to all ranks in a group
      // ("pair"). In the following, the physical number of primary rank is pri_rank.
      if (ATTR_MSS_VPD_MT_DRAM_RTT_WR == 0): skip this workaround       // goto skip_here
      MR2 =               // redo the rest of the bits
          [A11-A9]  0
      MR1 =               // redo the rest of the bits
          [A8-A10]  240/ATTR_MSS_VPD_MT_DRAM_RTT_WR       // Write properly encoded RTT_WR value as RTT_NOM
      // Assumption: RDIMM has at most 2 primary ranks. This means that possible rank numbers are 0, 1, 4, 5, where
      // 4 and 5 are ranks 0 and 1 on DIMM1. Even if rank numbers 2/3 are used when there is no DIMM1 we will never
      // train them, so it should be safe to ignore them here.
      pri_rank == 0:
        IOM0.DDRPHY_SEQ_ODT_WR_CONFIG0_P0 =     // 0x8000C40A0701103F
              [48] = 1
      pri_rank == 1:
        IOM0.DDRPHY_SEQ_ODT_WR_CONFIG0_P0 =     // 0x8000C40A0701103F
              [57] = 1
      pri_rank == 4:
        IOM0.DDRPHY_SEQ_ODT_WR_CONFIG1_P0 =     // 0x8000C40B0701103F
              [50] = 1
      pri_rank == 5:
        IOM0.DDRPHY_SEQ_ODT_WR_CONFIG1_P0 =     // 0x8000C40B0701103F
              [59] = 1

      mss::workarounds::seq::odt_config - not needed on DD2

      skip_here:

      // Different workaround, executed even if RTT_WR == 0
      workarounds::wr_lvl::configure_non_calibrating_ranks()
        for each rank on MCA except current primary rank:
          MR1 =               // redo the rest of the bits
              [A7]  = 1       // Write Leveling Enable
              [A12] = 1       // Outputs disabled (DQ, DQS)

      ---------------------------------------------------------------
      // Write leveling - main
      // This is a PHY hardware accelerated calibration step

      ################ PHY steps common part - begin ##########################
      // Common part of all PHY steps (w/o debug and error checking for clarity):
      //
      // >  const auto& l_mcbist = mss::find_target<TARGET_TYPE_MCBIST>(i_target);
      // >  auto l_cal_inst = mss::ccs::initial_cal_command(i_rp);
      // >  ccs::program l_program;
      // >
      // >  // Delays in the CCS instruction ARR1 for training are supposed to be 0xFFFF,
      // >  // and we're supposed to poll for the done or timeout bit. But we don't want
      // >  // to wait 0xFFFF cycles before we start polling - that's too long. So we put
      // >  // in a best-guess of how long to wait. This, in a perfect world, would be the
      // >  // time it takes one rank to train one training algorithm times the number of
      // >  // ranks we're going to train. We fail-safe as worst-case we simply poll the
      // >  // register too much - so we can tune this as we learn more.
      // >  l_program.iv_poll.iv_initial_sim_delay = 200;
      // >  l_program.iv_poll.iv_poll_count = 0xFFFF;
      // >  l_program.iv_instructions.push_back(l_cal_inst);
      // >
      // >  // We need to figure out how long to wait before we start polling. Each cal step has an expected
      // >  // duration, so for each cal step which was enabled, we update the CCS program.
      // >  mss::cal_timer_setup(i_target, i_total_cycles, l_program.iv_poll);
      // >  mss::setup_cal_config( i_target, i_rp, i_cal_config, i_abort_on_error);
      // >
      // >  // In the event of an init cal hang, CCS_STATQ(2) will assert and CCS_STATQ(3:5) = "001" to indicate a
      // >  // timeout. Otherwise, if calibration completes, FW should inspect DDRPHY_FIR_REG bits (50) and (58)
      // >  // for signs of a calibration error. If either bit is on, then the DDRPHY_PC_INIT_CAL_ERROR register
      // >  // should be polled to determine which calibration step failed.
      // >  mss::ccs::execute(l_mcbist, l_program, i_target);
      //
      // i_cal_config is one of IOM0.DDRPHY_PC_INIT_CAL_CONFIG0_P0[48-56] bits set.
      // i_total_cycles is a result of calculate_cycles() for given calibration step. cal_timer_setup() then sets
      // polling parameters: initial delay is i_total_cycles/8, delay between polls is 10us, poll count is whatever
      // it takes to get to i_total_cycles (rounded up), multiplied by 4 (although this may be required just for
      // simulation, but wouldn't hurt unless calibration fails anyway).
      // l_cal_inst is almost the same as DES instruction except for ACTN, DDR_CAL_TYPE and DDR_CALIBRATION_ENABLE:
      MC01.MCBIST.CCS.CCS_INST_ARR0_xx              // 0x07012316
            [all]   0
            // "CKE is high Note: P8 set all 4 of these high - not sure if that's correct. BRS"
            [24-27] CCS_INST_ARR0_00_CCS_DDR_CKE =      0xf
            [32-33] CCS_INST_ARR0_00_CCS_DDR_CSN_0_1 =  3     // Not used by the engine for calibration?
            [36-37] CCS_INST_ARR0_00_CCS_DDR_CSN_2_3 =  3     // Not used by the engine for calibration?
            [56-59] CCS_INST_ARR0_00_CCS_DDR_CAL_TYPE = 0xc
      MC01.MCBIST.CCS.CCS_INST_ARR1_xx              // 0x07012336
            [all]   0
            [53-56] CCS_INST_ARR1_00_DDR_CAL_RANK = rp
            [57]    CCS_INST_ARR1_00_DDR_CALIBRATION_ENABLE = 1

      // setup_cal_config()
      IOM0.DDRPHY_PC_INIT_CAL_CONFIG0_P0            // 0x8000C0160701103F
            [48-57] i_cal_config            // ### depends on step, bit 48 set for WR leveling ###
            [58]    ABORT_ON_CAL_ERROR =  0   // Maybe setting to 1 will help in debugging? ATTR_MSS_CAL_ABORT_ON_ERROR
            [60+rp] ENA_RANK_PAIR =       1   // So, rp must be [0-3]

      ### For WR leveling:
      ### > // Note: the following equation is taken from the PHY workbook - leaving the naked numbers in for parity to
      ### > // the workbook
      ### > // This step runs for approximately (80 + TWLO_TWLOE) x NUM_VALID_SAMPLES x (384/(BIG_STEP + 1) +
      ### > // (2 x (BIG_STEP + 1))/(SMALL_STEP + 1)) + 20 memory clock cycles per rank.
      ### TWLO_TWLOE for every defined speed bin is 9.5 + 2 = 11.5 ns, this needs to be converted to clock cycles, it is
      ### the only non-constant component of the equation.
      ### WR_LVL_BIG_STEP = 7
      ### WR_LVL_SMALL_STEP = 0
      ### WR_LVL_NUM_VALID_SAMPLES = 5
      ### We should leave full equation in the code and leave it for the compiler to simplify, but for rough estimations:
      ### i_total_cycles = (80 + to_cycles(11.5ns)) * 320 + 20
      ### i_total_cycles = (80 + 11.5/0.75) * 320 + 20 = 30740    // Min tCK for 2666, ~23us
      ### i_total_cycles = (80 + 11.5/1.25) * 320 + 20 = 28820    // Max tCK for 1866, ~36us

      // Important: delays and timeouts are different than defaults! Depends on i_total_cycles
      // TODO: are there any drawbacks for polling more often than every 10us?
      // TODO: do we have to do this for side A and side B?
      --------------- do CCS finalization and execution, see draminit_cke_helper ----------------------

      ################ PHY steps common part - end ############################

      ---------------------------------------------------------------
      // Write leveling - post-workaround
      //
      // Basically reverting the pre-workaround here
      if (ATTR_MSS_VPD_MT_DRAM_RTT_WR == 0): skip this workaround       // goto skip_here
      MR2 =               // redo the rest of the bits
          [A11-A9]  f(ATTR_MSS_VPD_MT_DRAM_RTT_WR)      // see mrs_load() above
      MR1 =               // redo the rest of the bits
          [A8-A10]  240/ATTR_MSS_VPD_MT_DRAM_RTT_NOM      // integer division rounds properly for 7/34 (watch out for 0)
      // Originally set in 13.8
      IOM0.DDRPHY_SEQ_ODT_WR_CONFIG0_P0 =     // 0x8000C40A0701103F
            F(X) = (((X >> 4) & 0xc) | ((X >> 2) & 0x3))    // Bits 0,1,4,5 of X, see also MC01.PORT0.SRQ.MBA_FARB2Q
            [all]   0
            [48-51] ODT_WR_VALUES0 = F(ATTR_MSS_VPD_MT_ODT_WR[index(MCA)][0][0])
            [56-59] ODT_WR_VALUES1 = F(ATTR_MSS_VPD_MT_ODT_WR[index(MCA)][0][1])

      IOM0.DDRPHY_SEQ_ODT_WR_CONFIG1_P0 =     // 0x8000C40B0701103F
            F(X) = (((X >> 4) & 0xc) | ((X >> 2) & 0x3))    // Bits 0,1,4,5 of X, see also MC01.PORT0.SRQ.MBA_FARB2Q
            [all]   0
            [48-51] ODT_WR_VALUES2 =
                      // RDIMM can't have more than 2 master ranks, maybe don't use ranks 2/3? On the other hand,
                      // maybe ranks 2/3 are used as "DIMM1 not present". TODO: check VPD for clues
                      count_dimm(MCA) == 2: F(ATTR_MSS_VPD_MT_ODT_WR[index(MCA)][1][0])
                      count_dimm(MCA) != 2: F(ATTR_MSS_VPD_MT_ODT_WR[index(MCA)][0][2])
            [56-59] ODT_WR_VALUES3 =
                      count_dimm(MCA) == 2: F(ATTR_MSS_VPD_MT_ODT_WR[index(MCA)][1][1])
                      count_dimm(MCA) != 2: F(ATTR_MSS_VPD_MT_ODT_WR[index(MCA)][0][3])
              [59] = 1

      mss::workarounds::seq::odt_config - not needed on DD2

      skip_here:

      // Different workaround, executed even if RTT_WR == 0
      workarounds::wr_lvl::configure_non_calibrating_ranks()
        for each rank on MCA except current primary rank:
          MR1 =               // redo the rest of the bits
              [A7]  = 0       // Write Leveling Enable: 0 = disabled
              [A12] = 0       // Outputs disabled (DQ, DQS): 0 = not disabled

      ===============================================================
      // Initial Pattern Write
      // No pre-/post-workaround required. This is PHY hardware accelerated step.
      //
      // This isn't exactly a calibration algorithm, but it prepares data for further steps. It writes to MPRs (Multi
      // Purpose Registers), using values specified in IOM0.DDRPHY_SEQ_RD_WR_DATA{0,1}_P0 in 13.8.
      PHY steps common part:
        i_cal_config[49] ENA_INITIAL_PAT_WR = 1
        // > Not sure how long this should take, so we're gonna use 1 to make sure we get at least one polling loop
        i_total_cycles = 1    // Note that delay between polls is 10us, so it basically becomes our timeout

      ===============================================================
      // DQS (read) alignment
      // No pre-workaround required, post-workaround does not apply to DD2.*. This is PHY hardware accelerated step.
      PHY steps common part:
        i_cal_config[50] ENA_DQS_ALIGN = 1
        // > Note: the following equation is taken from the PHY workbook - leaving the naked numbers in for parity to the
        // > workbook. This step runs for approximately 6 x 600 x 4 DRAM clocks per rank pair.
        i_total_cycles = 6 * 600 * 4 (= 14400)

      ===============================================================
      // Alignment of the internal SysClk to the Read clock
      // This is PHY hardware accelerated step.
      //
      // Read clock align - pre-workaround
      // Turn off refresh, we don't want it to interfere here
      IOM0.DDRPHY_PC_INIT_CAL_CONFIG1_P0                  // 0x8000C0170701103F
        // TODO: we just set it before starting calibration steps. As we don't have any precious data in RAM yet (no S3?),
        // maybe we can use 0 there and just change it to 3 in the post-workaround?
        [52-53] REFRESH_CONTROL =   0       // refresh commands are only sent at start of initial calibration

      ---------------------------------------------------------------
      // Read clock align - main
      PHY steps common part:
        i_cal_config[51] ENA_RDCLK_ALIGN = 1
        // > Note: the following equation is taken from the PHY workbook - leaving the naked numbers in for parity to the
        // > workbook. This step runs for approximately 24 x ((1024/COARSE_CAL_STEP_SIZE + 4 x COARSE_CAL_STEP_SIZE) x 4 + 32)
        // > DRAM clocks per rank pair
        // COARSE_CAL_STEP_SIZE = 4
        i_total_cycles = 24 * ((256 + 16) * 4 + 32) = 26880

      ---------------------------------------------------------------
      // Read clock align - post-workaround
      // > In DD2.*, We adjust the red waterfall to account for low VDN settings. We move the waterfall forward by one
      IOM0.DDRPHY_DP16_DQS_RD_PHASE_SELECT_RANK_PAIR{0-3}_P0_{0-3}      // 0x80000{0-3}090701103F, +0x0400_0000_0000
        [48-49] DQSCLK_SELECT0 = (++DQSCLK_SELECT0 % 4)
        [52-53] DQSCLK_SELECT1 = (++DQSCLK_SELECT1 % 4)
        [56-57] DQSCLK_SELECT2 = (++DQSCLK_SELECT2 % 4)
        [60-61] DQSCLK_SELECT3 = (++DQSCLK_SELECT3 % 4)
      IOM0.DDRPHY_DP16_DQS_RD_PHASE_SELECT_RANK_PAIR{0-3}_P0_4          // 0x80001{0-3}090701103F
        [48-49] DQSCLK_SELECT0 = (++DQSCLK_SELECT0 % 4)
        [52-53] DQSCLK_SELECT1 = (++DQSCLK_SELECT1 % 4)
        // Can't change non-existing quads

      // Turn on refresh
      // This is exactly the same as was called just before iterating over rank pairs...
      IOM0.DDRPHY_SEQ_MEM_TIMING_PARAM0_P0                              // 0x8000C4120701103F
        [60-63] TRFC_CYCLES = 9
      IOM0.DDRPHY_PC_INIT_CAL_CONFIG1_P0                                // 0x8000C0170701103F
        [48-51] REFRESH_COUNT =     0xf
        [52-53] REFRESH_CONTROL =   3       // refresh commands may interrupt calibration routines
        [54]    REFRESH_ALL_RANKS = 1
        [55]    CMD_SNOOP_DIS =     0
        [57-63] REFRESH_INTERVAL =  0x13

      ===============================================================
      // Read centering
      // This is PHY hardware accelerated step. Assuming both Vref and centering is enabled.
      //
      // Read centering - pre-workaround
      turn off refreshing - see "Read clock align - pre-workaround"

      IOM0.DDRPHY_DP16_CONFIG0_P0_{0-4}                                 // 0x800000030701103F, +0x0400_0000_0000
        [62]  1         // part of ATESTSEL_0_4 field

      ---------------------------------------------------------------
      // Read centering - main
      IOM0.DDRPHY_DP16_RD_VREF_CAL_EN_P0_{0-4}                          // 0x800000760701103F, +0x0400_0000_0000
        [all] 0
        [48-63] VREF_CAL_EN = 0xffff    // But we already did this in reset_rd_vref() in 13.8...

      IOM0.DDRPHY_RC_RDVREF_CONFIG1_P0                                  // 0x8000C80A0701103F
        [60]  CALIBRATION_ENABLE =  1
        [61]  SKIP_RDCENTERING =    0

      PHY steps common part:
        i_cal_config[52] ENA_READ_CTR = 1
        // > Note: the following equation is taken from the PHY workbook - leaving the naked numbers in for parity to the
        // > workbook
        // > This step runs for approximately 6 x (512/COARSE_CAL_STEP_SIZE + 4 x (COARSE_CAL_STEP_SIZE +
        // > 4 x CONSEQ_PASS)) x 24 DRAM clocks per rank pair.
        // COARSE_CAL_STEP_SIZE = 4
        // CONSEQ_PASS = 8
        i_total_cycles = 6 * (128 + 4 * (4 + 32)) * 24 = 39168

      ---------------------------------------------------------------
      // Read centering - post-workaround
      workarounds::dp16::rd_dq::fix_delay_values() - does not apply to DD2.*

      turn on refreshing - see "Read clock align - post-workaround"

      IOM0.DDRPHY_DP16_CONFIG0_P0_{0-4}                                 // 0x800000030701103F, +0x0400_0000_0000
        [62]  0         // part of ATESTSEL_0_4 field

      ===============================================================
      // Write VREF Latching
      // Pre-workaround does not apply to DD2.*, there is no post-workaround.
      //
      // > JEDEC has a 3 step latching process for WR VREF
      // > 1) enter into VREFDQ training mode, with the desired range value is XXXXXX
      // > 2) set the VREFDQ value while in training mode - this actually latches the value
      // > 3) exit VREFDQ training mode and go into normal operation mode
      // Each step is followed by a 150ns (tVREFDQE or tVREFDQX) stream of DES commands before next one.
      for each present rank in rp:
        // Step 1
        MR6 =
          [all] 0
          [A5-A0]   ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x3f       // This is "don't care" in step 1
          [A6]      ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x40
          [A7]      1
          [A12-A10] (conv_to_nCK(SPD[40] + SPD[117])) - 4

        // Step 2 - exactly the same as step 1
        MR6 =
          [all] 0
          [A5-A0]   ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x3f
          [A6]      ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x40
          [A7]      1
          [A12-A10] (conv_to_nCK(SPD[40] + SPD[117])) - 4

        // Step 3
        MR6 =
          [all] 0
          [A5-A0]   ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x3f       // This is "don't care" when A7 is not set
          [A6]      ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x40       // This is "don't care" when A7 is not set
          [A12-A10] (conv_to_nCK(SPD[40] + SPD[117])) - 4

      ===============================================================
      // Write centering
      // This is PHY hardware accelerated step. Assuming both Vref and centering is enabled.
      //
      // Write centering - pre-workaround
      // Following the assumption from reset_bad_bits() - assume there are no bad DQ bits
      // DRAM is one IC on the DIMM module, there are 9 DRAMs for x8 and 18 for x4 devices (DQ bits/width) per master rank
      l_dram_delays[number of DRAMs]        // will be used in post-workaround
      for each DRAM:
        // This assumes that the delays are the same across the rank pair. Does it mean that grouping is useful only for
        // slave ranks and one master rank always is exactly one rank pair? This would explain a lot...
        // Before centering the delays should be the same for each DQ of a given DRAM
        // Hostboot extracted just the delay from that SCOM, but the rest is 0s so why bother
        // DP = (DRAM*width) / 16
        // val = (DRAM*width) % 16
        l_dram_delays[DRAM] = IOM0.DDRPHY_DP16_WR_DELAY_VALUE_<val>_RP<rp>_REG_P0_<DP>
                    // 0x800000380701103F and others

      ---------------------------------------------------------------
      // Write centering - main
      // Hostboot sets bit 48 of IOM0.DDRPHY_DP16_WR_VREF_CONFIG0_P0_{0-4} to 0, but it was already set that way
      // in reset_wr_vref_registers() in 13.8. It is also used by a workaround, where it may be set as 1.
      PHY steps common part:
        i_cal_config[53] ENA_WRITE_CTR = 1
        // > Note: the following equation is taken from the PHY workbook - leaving the naked numbers in for parity to the
        // > workbook
        // > 1000 + (NUM_VALID_SAMPLES * (FW_WR_RD + FW_RD_WR + 16) *
        // > (1024/(SMALL_STEP +1) + 128/(BIG_STEP +1)) + 2 * (BIG_STEP+1)/(SMALL_STEP+1)) x 24 DRAM
        // > clocks per rank pair.
        //
        // Yes, write leveling values are used for write centering, this is not an error (or is it? CONFIG0 says BIG_STEP = 1)
        // WR_LVL_BIG_STEP = 7
        // WR_LVL_SMALL_STEP = 0
        // WR_LVL_NUM_VALID_SAMPLES = 5
        //
        // > Per PHY spec, defaults to 0. Would need an attribute to drive differently
        // FW_WR_RD = 0
        //
        // > From the PHY spec. Also confirmed with S. Wyatt as this is different than the calculation used in Centaur.
        // > This field must be set to the larger of the two values in number of memory clock cycles.
        // > FW_RD_WR = max(tWTR + 11, AL + tRTP + 3)
        // > Note from J. Bialas: The difference between tWTR_S and tWTR_L is that _S is write to read
        // > time to different bank groups, while _L is to the same. The algorithm should be switching
        // > bank groups so tWTR_S can be used
        // tWTR_S is shorter than tWTR_L
        // tWTR_S can be read from SPD[0x29] and SPD[0x2c], there are also minimal values in DDR4 spec, max of those should
        // be used (tWTR_L is in SPD[0x29] and SPD[0x2d], if it were to be used)
        // tRTP = 7.5ns, but it has to be converted to nCK (this comes from DDR4 spec)
        // AL = 0
        i_total_cycles = 1000 + (5 * (0 + max(tWTR_S + 11, 0 + to_clocks(7.5ns) + 3) + 16) *
                          (1024/(0 + 1) + 128/(7 + 1)) + 2 * (7+1)/(0+1)) * 24
        // to_clocks(7.5ns) is between 6 and 10 clocks for all supported frequencies (1866-2666MT/s). Minimal tWTR_S per JEDEC
        // is max(2nCK, 2.5ns), which means that even for minimal possible tWTR_S it is at least as big as the second part, so
        // max(tWTR_S + 11, to_clocks(7.5ns) + 3) = tWTR_S + 11
        // Reducing as much as possible:
        // i_total_cycles = 1000 + ((tWTR_S + 27) * 5200 + 16) * 24 = 1000 + (5200*tWTR_S + 140400 + 16) * 24 =
        //                  1000 + 124800*tWTR_S + 3369984 = 124800*tWTR_S + 3370984
        // Taking tWTR_S = 2.5ns (as seen in some SPDs) this gives 3620584 - 3870184 cycles = ~2.9 - 4.5ms (rough estimations).

      ---------------------------------------------------------------
      // Write centering - post-workaround
      // Assume no NVDIMMs.
      // Write centering may fail for DQ bits that have significantly different RD VREF values than the rest of DQ bits under
      // the same DRAM. In that case disable all but one, known to be good, DQ bits and rerun WR centering.
      //
      // This workaround uses per DRAM addressing (PDA) mode. In general, PDA is used to set values that may not be the same
      // for all DRAMs on a given rank, such as ODT or Vref. Only MRS commands are available in PDA mode. How to use it:
      // 0. Write leveling must be performed before entering PDA mode.
      // 1. Enable PDA by writing MR3 with A4 = 1 (this MRS is sent to ALL DRAMs).
      // 2. In PDA mode DQ0 of each DRAM serves as a "chip select" - when DQ0 is 1, that DRAM ignores the command. Note that
      //    DQ bits on the edge connector do not have to be mapped 1:1 into consecutive DRAM DQ pins (see SPD[60-77]). For
      //    this reason the controller may choose to drive all the DQ bits of a nibble (or byte for x8 devices).
      // 3. After appropriate DQ bits are set, MRS command may be sent as usual. Because only MRS commands are allowed, there
      //    is no separate tMOD, but tMRD_PDA = max(16nCK, 10ns) is used instead of tMRD = 8nCK. In addition to tMRD_PDA more
      //    delay is needed because the DQ bits must propagate to DRAM (AL + CWL + PL + BL/2), we can subtract half clock
      //    cycle because tMRD_PDA is counted since the arrival of the last DQ bit, not including the hold time. The total
      //    minimum time between MRS commands in PDA mode is thus (AL + (PL) + CWL + BL/2 - 0.5tCK + tMRD_PDA), where:
      //    - AL - Additive Latency, set in MR1
      //    - CWL - CAS Write Latency, set in MR2
      //    - BL - Burst Length, set in MR0, divided by 2 because DDR
      //    - PL - C/A Parity Latency, set in MR5, optional
      // 4. To exit PDA mode write MR3 with A4 = 0. As this command is sent while still in PDA mode, it is send ONLY to the
      //    selected DRAMs. DQ0 bits for all DRAMs should be driven to 0 so the command is sent to all DRAM devices at once.
      //    Bits in mode registers are assigned in such a way that no per-DRAM values are configured by MR3. Next command
      //    (other than MRS and DES) may be send after (AL + (PL) + CWL + BL/2 - 0.5tCK + tMOD).
      //
      // That was the theory. On POWER9 we have some help from the hardware. We still have the CCS to send MRS commands. DP16s
      // have registers that can set appropriate DQ bits for a whole nibble, we just have to specify which one. Delay and hold
      // time of DQ bits is configurable, although Hostboot uses 0 for delay and max possible value for hold (0x3f memory
      // clock cycles) because it is "safer and easier than figuring out how long to hold the values". PHY logic can only
      // track one MRS PDA command at a time. This introduces another timing constraint: spacing between MRS commands in PDA
      // mode must be at least (delay + hold + 8) memory clock cycles.
      //
      // Unfortunately, those DQ bits cannot be changed by CCS_INSTR_ARR0/1 registers, which means that switching the targets
      // must be performed outside of CCS, manually. We still can and should, if possible, select multiple DRAMs at once.
      // Configuring CCS for each command takes time, we also have to poll the status to know when it is safe to modify
      // registers specifying DQs. We cannot change them in the middle of an instruction, but it should be safe to do so
      // during the last tMRD_PDA, however the time saved this way would be negligible.
      //
      // On the controller, PDA mode is enabled by multiple bits. There is one global (per MCA) bit to set up the driving of
      // DQ/DQS bits in write control block, and MR3 mirrors (per rank pair) in PHY control block. The latter are changed
      // automatically, but unfortunately they do not account for RDIMMs A- and B-sides. This is not an issue for entering
      // PDA mode (side B is written with all DQs driven to 0, except for possibly longer timeout they are ignored by DRAMs
      // that are not in PDA mode yet), but for exiting we need another workaround to tell the controller that it is still
      // using PDA and should drive DQ bits as ordered. This is done by manually setting MR3[A4] mirror between issuing
      // commands to A- and B-side. Note that the workaround is needed just for the command that clears MR3[A4], and not all
      // of the MRS commands.

      // Check if there are any (new) bad DQ bits, there is no reason to run this workaround if calibration passed.
      for each DRAM:
        // DP = (DRAM*width) / 16
        IOM0.DDRPHY_DP16_DQ_BIT_DISABLE_RP<rp>_P0_<DP>:       // 0x8000007C0701103F and others
            if ALL 'width' bits for this DRAM == 1: add DRAM to l_bad_drams

      if l_bad_drams is empty: skip workaround        // go to next calibration step

      // We are about to disable DQ bits. One of those bits may be DQ0, which is used to select DRAM in PDA mode, which
      // means we have to do PDA first to redo WR VREF latch.
      //
      // Attribute ATTR_MSS_VPD_MT_VREF_DRAM_WR that is written to most of the registers below is defined for MCS, so it
      // will be the same for all ranks.
      //
      // Deselect all DRAMs by setting appropriate DQ bits. Hostboot does it later (PDA enter) but doing it now will
      // simplify the rest of the code. In the code these registers were named MCA_DDRPHY_DP16_DATA_BIT_ENABLE1_P0_*.
      IOM0.DDRPHY_DP16_DFT_PDA_CONTROL_P0_{0-3}                     // 800000010701103F, +0x0400_0000_0000
          [60-63] MRS_CMD_DATA_Nx = 1
      IOM0.DDRPHY_DP16_DFT_PDA_CONTROL_P0_4
          [60-61] MRS_CMD_DATA_Nx = 1             // only two bits for last DP

      for each DRAM in l_bad_drams:
        mss::ddr4::pda::commands::add_command():
          // In Hostboot this function is generalised and uses C++ containers magic to minimise the number of rank switching.
          // For this particular case (one command to a group of ranks, no switching required other than exit from PDA) it
          // is enough to just add bad DRAM to the current set, provided that this set was cleared before the loop. PDA mode
          // will be enabled regardless of DQ bits, even though the controller will set those just for bad DRAMs on the PDA
          // entry for side B. In non-PDA mode those bits are ignored by DRAMs.
          // reg = (DRAM*width) / 16
          // bit = (DRAM*width/4) % 4             // so 1 bit per DRAM for x4, 2 bits for x8
          IOM0.DDRPHY_DP16_DFT_PDA_CONTROL_P0_<reg>
              [60+bit] MRS_CMD_DATA_Nx = 0
              if x8:                  // for x8 set second nibble too, DQ0 may be in any of them
                [60+bit+1] = 0

        configure_wr_vref_to_nominal():
          // DP = (DRAM*width) / 16
          // reg = ((DRAM*width) % 16) / 2
          IOM0.DDRPHY_DP16_WR_VREF_VALUE<reg>_RANK_PAIR<rp>_P0_<DP> =   // 0x8000005E0701103F and others
              // Modify just the bits for this DRAM, leave the rest as it was set by the calibration
              if DRAM % 2 == 0:
                [49]    WR_VREF_RANGE_DRAM{0,2} = ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x40
                [50-55] WR_VREF_VALUE_DRAM{0,2} = ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x3f
              if DRAM % 2 == 1:
                [57]    WR_VREF_RANGE_DRAM{1,3} = ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x40
                [58-63] WR_VREF_VALUE_DRAM{1,3} = ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x3f

        reset_wr_dq_delay():
          // Saved in pre-workaround
          // DP = (DRAM*width) / 16
          // val = (DRAM*width) % 16
          IOM0.DDRPHY_DP16_WR_DELAY_VALUE_<val>_RP<rp>_REG_P0_<DP> = l_dram_delays[DRAM]
                      // 0x800000380701103F and others

        // Must temporally re-enable DQ bits for PDA
        clear_dram_disable_bits():
          // DP = (DRAM*width) / 16
          // pos = 48 + (DRAM*width) % 16
          IOM0.DDRPHY_DP16_DQ_BIT_DISABLE_RP<rp>_P0_<DP>:       // 0x8000007C0701103F and others
              [pos - pos+width-1]   0     // might as well do this in the first loop of this workaround

      // MR6 is sent to bad DRAMs only through PDA, but we are sending one command to multiple DRAMs, so this is outside
      // "for each DRAM" loop. But first we have to set up and enter PDA mode. For MRS use CCS as before, remember to
      // send the commands to side A and side B. No workaround needed for entry.
      //
      // JEDEC says to wait for tMOD = max(24nCK, 15ns) even if the next command is another MRS, but we may have different
      // constraints:
      // > Note: the delay is taken from the PDA timing register's maximum value 2^6
      // > 10 cycles for safety
      // Hostboot waits for 64 + 10 = 74 cycles.
      MR3:
        [A4]      1

      // PDA mode is enabled for DRAMs, but the controller isn't set to drive DQ bits yet, do it now.
      IOM0.DDRPHY_WC_CONFIG3_P0                                 // 0x8000CC050701103F
        [all] 0       // all non-0 bits are changed, no need to read the register
        [48]    PDA_RANKDELAY_ENABLE =  1
        [49-54] MRS_CMD_DQ_ON =         0
        [55-60] MRS_CMD_DQ_OFF =        0x3f

      // Only now Hostboot configures DQ bits in DDRPHY_DP16_DFT_PDA_CONTROL registers, until now all that data was hold
      // in the PDA command structures. It also disables DRAMs (one by one) after the command stream is sent, preparing for
      // the next set of commands, even though there are none.
      //
      // By JEDEC, we should wait for (AL + (PL) + CWL + BL/2 - 0.5tCK + tMRD_PDA) = ~30-40 clocks, depending on settings,
      // but because of delay in DDRPHY_WC_CONFIG3_P0 we have to wait at least (MRS_CMD_DQ_ON + MRS_CMD_DQ_OFF + 8) = 71
      // clock cycles. On top of that, because we are changing VrefDQ, tVREFDQ{E,X} = 150ns is used instead of tMRD_PDA.
      // However, Hostboot uses just tVREFDQE which probably is OK, as it is longer than other constraints and DRAM still
      // receives it in the same intervals.
      //
      // This is exactly the same as in Write VREF latching, except we do not do this for all ranks.
      // Step 1
      MR6 =
        [all] 0
        [A5-A0]   ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x3f       // This is "don't care" in step 1
        [A6]      ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x40
        [A7]      1
        [A12-A10] (conv_to_nCK(SPD[40] + SPD[117])) - 4

      // Step 2 - exactly the same as step 1
      MR6 =
        [all] 0
        [A5-A0]   ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x3f
        [A6]      ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x40
        [A7]      1
        [A12-A10] (conv_to_nCK(SPD[40] + SPD[117])) - 4

      // Step 3
      MR6 =
        [all] 0
        [A5-A0]   ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x3f       // This is "don't care" when A7 is not set
        [A6]      ATTR_MSS_VPD_MT_VREF_DRAM_WR & 0x40       // This is "don't care" when A7 is not set
        [A12-A10] (conv_to_nCK(SPD[40] + SPD[117])) - 4

      // Vref on DRAMs has been restored, prepare to exit PDA.
      // Select all DRAMs, not just the disabled ones. Hostboot does it too, overwriting what it just wrote during PDA
      // command set finalisation where it deselected bad DRAMs.
      IOM0.DDRPHY_DP16_DFT_PDA_CONTROL_P0_{0-3}                     // 800000010701103F, +0x0400_0000_0000
          [60-63] MRS_CMD_DATA_Nx = 0
      IOM0.DDRPHY_DP16_DFT_PDA_CONTROL_P0_4
          [60-61] MRS_CMD_DATA_Nx = 0             // only two bits for last DP

      // Disable PDA on DRAMs. This needs a workaround, so the command is send to side A only (for now).
      MR3:
        [A4] 0

      // Right now the controller sees that PDA is being disabled, so it traps this information in MR3 mirror register.
      // It does it before sending the command to side B, so side B would receive this command as if it were in non-PDA
      // mode. We must manually set A4 mirror bit to tell the controller that it should still work in PDA mode.
      IOM0.DDRPHY_PC_MR3_RP<rp>_P0                                  // 0x8000C<rp>1F0701103F
        // This bit corresponds to A4. Perhaps bit numbering is reversed (A0->63, A1->62...), or bits may be swizzled,
        // there is no explicit information about the order of bits, but 59 comes from the Hostboot code.
        [59]  1

      // Now send the same command to side B (with inverting and mirroring as usual).
      MR3:
        [A4] 0

      // Disable PDA mode in WC register
      IOM0.DDRPHY_WC_CONFIG3_P0                                 // 0x8000CC050701103F
        // Any reason for RMW and not zeroing the whole register?
        [48]    PDA_RANKDELAY_ENABLE =  0

      // Everything up to this point was done just to revert the state to that from before first try of write centering,
      // for bad DRAMs only. Now we have to disable all but one DQ bits for bad DRAMs. We must select a bit that is good,
      // that means its RD Vref is close to the median value of DRAM's Vrefs (not true median actually, for even number
      // of elements, as is always the case for DQ bits, we choose element n/2 instead of average of this and the next
      // element - integer math and such value always exists).
      for each DRAM in l_bad_drams:
        disable_bits():
          // > There are two RD VREF values stored per register, one RD VREF value corresponds to one bit
          // > For a x4 DRAM, there are 4 bits per DRAM, meaning two registers need to be read
          // > For a x8 DRAM, there are 8 bits per DRAM, meaning four registers need to be read
          // DP = (DRAM*width) / 16
          // DAC_l = (DRAM * width/2) % 8
          // DAC_h = ((DRAM+1) * width/2) % 8 - 1
          // DRAMs do not cross DPs and both values in a register describe exactly one DRAM. We need the median of
          // values from registers in range DAC_l-DAC_h from:
          IOM0.DDRPHY_DP16_RD_VREF_DAC_<DAC>_P0_<DP>
            [49-55] BIT(2*DAC)_VREF_DAC
            [57-63] BIT(2*DAC+1)_VREF_DAC

          // Hostboot searches for the first good bit but any one would do probably. It uses a threshold of 3 units to
          // minimise lookup time. Take care to not overflow.
          // TODO: can we find median without sorting, so we can keep the index of element? If yes, is this faster?
          // good_bit = first bit for which RD VREF value is median +/- 3
          // pos = 48 + (DRAM*width) % 16
          IOM0.DDRPHY_DP16_DQ_BIT_DISABLE_RP<rp>_P0_<DP>:       // 0x8000007C0701103F and others
              [pos - pos+width-1]   1         // disable all...
              [pos+good_bit]        0         // ...but one, known to be good

      configure_skip_bits():
        IOM0.DDRPHY_DP16_WR_VREF_CONFIG0_P0_{0,1,2,3,4} =       // 0x8000006C0701103F, +0x0400_0000_0000
            [57-59] WR_CTR_NUM_BITS_TO_SKIP = 7     // skip all but one

      // Rerun main calibration
      // TODO: what about i_total_cycles? Hostboot uses one value, regardless of number of skip bits and whether 2D or 1D
      // calibration is performed.
      run()

      // Clear training FIRs
      IOM0.IOM_PHY0_DDRPHY_FIR_REG SCOM1 (AND) =    // 0x0000000007011001
          [all] 1
          [56]  IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_2 = 0

      // Hostboot here reads IOM0.IOM_PHY0_DDRPHY_FIR_REG (0x07011001) and discards the value. This was not done in
      // clear_initial_cal_errors().

      // Check if DRAMs are still bad.
      for each DRAM in l_bad_drams:
        // DP = (DRAM*width) / 16
        IOM0.DDRPHY_DP16_DQ_BIT_DISABLE_RP<rp>_P0_<DP>:       // 0x8000007C0701103F and others
            if ALL 'width' bits for this DRAM == 1: l_is_bad = true

        if l_is_bad == false:     // if DRAM was recovered
          clear_dram_disable_bits():
            // DP = (DRAM*width) / 16
            // pos = 48 + (DRAM*width) % 16
            IOM0.DDRPHY_DP16_DQ_BIT_DISABLE_RP<rp>_P0_<DP>:       // 0x8000007C0701103F and others
                [pos - pos+width-1]   0

      // Now that the disable bits for recovered DRAMs were cleared, we can rerun 1D WR centering calibration.
      IOM0.DDRPHY_DP16_WR_VREF_CONFIG0_P0_{0,1,2,3,4} =       // 0x8000006C0701103F, +0x0400_0000_0000
          [48]  WR_CTR_1D_MODE_SWITCH = 1

      // Rerun main calibration, again
      run()

      ===============================================================
      // Coarse WR/RD calibration
      // No pre-/post-workaround required. This is PHY hardware accelerated step.
      PHY steps common part:
        i_cal_config
            [54] ENA_INITIAL_COARSE_WR =  1
            [55] ENA_COARSE_RD =          1
        // 40 cycles for WR, 32 for RD
        i_total_cycles = 72

      ===============================================================

      // That was the last calibration step performed in draminit_training, there are two more in draminit_trainadv.
      // We are still in "for each rp" loop.
      //
      // Assuming ABORT_ON_CAL_ERROR==0 in DDRPHY_PC_INIT_CAL_CONFIG0_Px, we want to continue training other DIMMs/ranks
      // regardless of whether calibration passed or failed. We may or may not have bad DQ bits now. A number of bad bits
      // can be handled.
      //
      // Check if initial calibration failed.
      l_rc = process_initial_cal_errors(DIMM):
        IOM0.DDRPHY_DP16_RD_VREF_CAL_ERROR_P0_{0-4}               // 0x8000007A0701103F, +0x0400_0000_0000
          // We can test all bits of the last DP16 - unused bits are always 0 because they were not trained.
          if any register != 0: return error

        // Note ERROR_MASK1 is before ERROR_MASK0 in SCOM space
        IOM0.DDRPHY_DP16_WR_VREF_ERROR0_P0_{0-4}                  // 0x800000AE0701103F, +0x0400_0000_0000
        IOM0.DDRPHY_DP16_WR_VREF_ERROR1_P0_{0-4}                  // 0x800000AF0701103F, +0x0400_0000_0000
        IOM0.DDRPHY_DP16_WR_VREF_ERROR_MASK0_P0_{0-4}             // 0x800000FB0701103F, +0x0400_0000_0000
        IOM0.DDRPHY_DP16_WR_VREF_ERROR_MASK1_P0_{0-4}             // 0x800000FA0701103F, +0x0400_0000_0000
          if any (ERRORn & ~ERROR_MASKn) != 0: return error

        IOM0.DDRPHY_PC_INIT_CAL_ERROR_P0                          // 0x8000C0180701103F
          if [60-63] == 0 or      // no rank pairs reported
           [48-59] == 0:          // no errors reported
            // This is either true success or an error in the calibration engine itself. Check for latter.
            IOM0.IOM_PHY0_DDRPHY_FIR_REG        // 0x07011000
              if IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_2 (52) == 1:
                // > Clear the PHY FIR ERROR 2 bit so we don't keep failing training and training advance on this port
                [52] IOM_PHY0_DDRPHY_FIR_REG_DDR_FIR_ERROR_2 = 0
                // FIXME: comments say that we return success if there are FIR errors, even when bit 52 was 1. Code
                // seems to negate that and return error caused by PLL or error caused by FIR, which is treated the same
                // by functions higher in the call stack (different debug output maybe?). It is possible that I totally
                // misunderstood the code, double check later with fresh mind.
                // Or, maybe it should return "success" as an indication of failure that isn't related to bad DQ bits,
                // so there is no reason to even try fixing it?
                return error

            return success        // still in the "if no rp or no errors reported" branch

        // At this point we have no RD/WR VREF errors, but at least one bit in PC_INIT_CAL_ERROR is set. Print it and:
        return error        // This also checks PLL vs FIR errors in Hostboot

      if l_rc != success:
        // Hostboot assumes that when we got here, we have some bad DQ bits. It doesn't seem to differentiate between
        // bad bits and other errors, like calibration engine failure (unless FFDC does something about that).
        //
        // We can recover from 1 nibble + 1 bit (or less) bad lines. Anything more and DIMM is beyond repair. A bad
        // nibble is a nibble with any number of bad bits. If a DQS is bad (either true or complementary signal, or
        // both), a whole nibble (for x4 DRAMs) or byte (x8) is considered bad.
        //
        // Function used in Hostboot checks again if there are any bad bits. It also has support for checking more than
        // one rank pair (maybe it is called from other places, too). These check are omitted here.
        //
        // Check both DQS and DQ registers in one loop, iterating over DP16s - easier to sum bad bits/nibbles.
        //
        // See reset_write_clock_enable() and reset_write_clock_enable() in 13.8 or an array in process_bad_bits() in
        // phy/dp16.C for mapping of DQS bits in x8 and mask bits from this register accordingly.
        // TODO: maybe unused bits are not trained and cannot fail? This would simplify things, we could use the same
        // logic for x8 as for x4.
        total_bad_nibbles = 0
        total_bad_bits = 0
        IOM0.DDRPHY_DP16_DQS_BIT_DISABLE_RP<rp>_P0_{0-4}:         // 0x80000<rp>7D0701103F, +0x0400_0000_0000
          // This calculates how many (DQS_t | DQS_c) failed - if _t and _c failed for the same DQS, we count it as one.
          bad_dqs = bit_count((reg & 0x5500) | ((reg & 0xaa00) >> 1))
          if x8 && bad_dqs > 0: DIMM is FUBAR, return error?
          total_bad_nibbles += bad_dqs
          // If we are already past max possible number, we might as well return now
          if total_bad_nibbles > 1: DIMM is FUBAR, return error?

        IOM0.DDRPHY_DP16_DQ_BIT_DISABLE_RP<rp>_P0_{0-4}:          // 0x80000<rp>7C0701103F, +0x0400_0000_0000
          nibble = {[48-51], [52-55], [56-59], [60-63]}   // exclude nibble corresponding to a bad DQS, it won't get worse
          for each nibble:
            if bit_count(nibble) >  1: total_bad_nibbles += 1
            if bit_count(nibble) == 1: total_bad_bits += 1
            // We can't have two bad bits, one of them must be treated as bad nibble
            if total_bad_bits    >  1: total_bad_nibbles += 1, total_bad_bits -= 1
            if total_bad_nibbles >  1: DIMM is FUBAR, return error?

        // Now, if total_bad_nibbles is less than 2 we know that total_bad_bits is also less than 2, and DIMM is good
        // enough for recovery.

    // End of "for each rp" loop

    // Hostboot writes bad DQ maps into an attribute. Attribute name suggests this is saved in VPD, but comments mention
    // SPD. Long time ago we assumed no bad DQ bits from VPD, all of them were to be trained on each boot, so no reason
    // to write it back (at least for now).

    workarounds::dp16::modify_calibration_results() - does not apply to DD2.*

  // End of "for each functional MCA" loop

  // Hostboot just logs the errors reported earlier (i.e. more than 1 nibble + 1 bit of bad DQ lines) "and lets PRD
  // deconfigure based off of ATTR_BAD_DQ_BITMAP".
  // TODO: what is PRD? How does it "deconfigure" and what? Quick glance at the code: it may have something to do with
  // undocumented 0x501082X SCOM registers, there are usr/diag/prdf/*/*.rule files with yacc/flex files to compile them.
  // It also may be using `attn` instruction.

  mss::unmask::after_dram_training():
    // > All mcbist attentions are already special attentions
    MC01.MCBIST.MBA_SCOMFIR.MCBISTFIRACT0             // 0x07012306
          [1] MCBISTFIRQ_COMMAND_ADDRESS_TIMEOUT =  0
    MC01.MCBIST.MBA_SCOMFIR.MCBISTFIRACT1             // 0x07012307
          [1] MCBISTFIRQ_COMMAND_ADDRESS_TIMEOUT =  1
    MC01.MCBIST.MBA_SCOMFIR.MCBISTFIRMASK             // 0x07012303
          [1] MCBISTFIRQ_COMMAND_ADDRESS_TIMEOUT =  0     //recoverable_error (0,1,0)

    for each functional MCA
      MC01.PORT0.SRQ.MBACALFIR_ACTION0              // 0x07010906
            [2]   MBACALFIR_MASK_REFRESH_OVERRUN =        0
            [5]   MBACALFIR_MASK_DDR_CAL_TIMEOUT_ERR =    0
            [7]   MBACALFIR_MASK_DDR_CAL_RESET_TIMEOUT =  0
            [9]   MBACALFIR_MASK_WRQ_RRQ_HANG_ERR =       0
            [11]  MBACALFIR_MASK_ASYNC_IF_ERROR =         0
            [12]  MBACALFIR_MASK_CMD_PARITY_ERROR =       0
            [14]  MBACALFIR_MASK_RCD_CAL_PARITY_ERROR =   0
      MC01.PORT0.SRQ.MBACALFIR_ACTION1              // 0x07010907
            [2]   MBACALFIR_MASK_REFRESH_OVERRUN =        1
            [5]   MBACALFIR_MASK_DDR_CAL_TIMEOUT_ERR =    1
            [7]   MBACALFIR_MASK_DDR_CAL_RESET_TIMEOUT =  1
            [9]   MBACALFIR_MASK_WRQ_RRQ_HANG_ERR =       1
            [11]  MBACALFIR_MASK_ASYNC_IF_ERROR =         0
            [12]  MBACALFIR_MASK_CMD_PARITY_ERROR =       0
            [14]  MBACALFIR_MASK_RCD_CAL_PARITY_ERROR =   1
      MC01.PORT0.SRQ.MBACALFIR_MASK                 // 0x07010903
            [2]   MBACALFIR_MASK_REFRESH_OVERRUN =        0   // recoverable_error (0,1,0)
            [5]   MBACALFIR_MASK_DDR_CAL_TIMEOUT_ERR =    0   // recoverable_error (0,1,0)
            [7]   MBACALFIR_MASK_DDR_CAL_RESET_TIMEOUT =  0   // recoverable_error (0,1,0)
            [9]   MBACALFIR_MASK_WRQ_RRQ_HANG_ERR =       0   // recoverable_error (0,1,0)
            [11]  MBACALFIR_MASK_ASYNC_IF_ERROR =         0   // checkstop (0,0,0)
            [12]  MBACALFIR_MASK_CMD_PARITY_ERROR =       0   // checkstop (0,0,0)
            [14]  MBACALFIR_MASK_RCD_CAL_PARITY_ERROR =   0   // recoverable_error (0,1,0)

## mss_draminit_trainadv: Advanced dram training (13.12)

> a) p9_mss_draminit_training_advanced.C  (mcbist target) - Nimbus
> b) p9c_mss_draminit_training_advanced.C  (mba target)   - Cumulus
>    - Prior to running this procedure will apply known DQ bad bits to prevent them from participating in training.
>      This information is extracted from the bad DQ attribute and applied to Hardware
>      - Marks the MCBist mask
>    - This step will contain any algorithms to improve data eye post training
>      - At the moment this is a no-op for P9 Nimbus
>      - For P9 Cumulus the VREF calibration will be done here
>    - Also will contain some characterization (mfg only) tests
>      - There will be a FAPI interface for dumping characterization data, platform implementation is TBD (dump to console,
>        memory, PNOR)
>    - This procedure will update the bad DQ attribute for each dimm based on its finding

// Code flow is very similar to that from 13.11. Key differences:
// - CCS is already configured, there is no need to do this again,
// - register resets, ZQ calibration and workarounds (DQS refreshing) are not repeated,
// - no workarounds (for RDIMM) after all training steps,
// - no "FIRry things" after the training,
// - bad DQ bits are not updated, despite what IPL flow says.
// It jumps straight into calibration steps.

for each functional MCBIST
  if (count_dimms(MCBIST) == 0) go to next MCBIST

  for each functional MCA
    get_rank_pairs(MCA, l_pairs)        // described in 13.8
    for each rp in l_pairs
      // Custom read/write centering
      // Those are two separate PHY hardware accelerated steps, but WR centering may fail because of bad RD centering,
      // in which case both RD and WR must be repeated with a different pattern. Initial Pattern Write described earlier
      // is also used in this step to load custom patterns into appropriate DRAM registers.
      //
      // There are 3 custom read patterns and 1 write pattern. Code iterates over read patterns until it succeeds for both
      // read and write centering, or runs out of patterns. In any case, it returns success - default centering was performed
      // earlier and its results are restored if custom centering fails.
      save original settings:               // good values from default pattern centering, copy to variables
        IOM0.DDRPHY_DP16_READ_DELAY{0-7}_RANK_PAIR<rp>_P0_{0-3}         // 0x80000<rp>5{0-7}0701103F, +0x0400_0000_0000
        IOM0.DDRPHY_DP16_READ_DELAY{0-3}_RANK_PAIR<rp>_P0_4
        IOM0.DDRPHY_DP16_DQS_RD_PHASE_SELECT_RANK_PAIR<rp>_P0_{0-4}     // 0x80000<rp>090701103F, +0x0400_0000_0000
        IOM0.DDRPHY_DP16_DQ_BIT_DISABLE_RP<rp>_P0_{0-4}                 // 0x80000<rp>7C0701103F, +0x0400_0000_0000
        IOM0.DDRPHY_DP16_DQS_BIT_DISABLE_RP<rp>_P0_{0-4}                // 0x80000<rp>7D0701103F, +0x0400_0000_0000
        IOM0.DDRPHY_DP16_READ_EYE_SIZE{0-11}_RANK_PAIR<rp>_P0_{0-4}     // 0x80000<rp>6{0-B}0701103F, +0x0400_0000_0000
        // 111 registers in total
        // TODO: maybe save write centering results here, too? But that is 100 additional registers...

      // Read and write patterns are originally stored in a form that needs swizzling (reversing bit order for each byte
      // separately). Unless we want to read the data from Hostboot's structures, we can store it already swizzled. Whenever
      // a pattern is read in the notes below, it should operate on already swizzled form.
      // Note that it is not the same as endianness, as it changes order of bits, not bytes.
      read_patterns = {0x8E942BC6, 0xEA0CA6C9, 0x13EC02FD}      // before swizzling
      read_patterns = {0x7129D463, 0x57306593, 0xC83740BF}      // after swizzling
      write_pattern = 0x69                                      // before swizzling
      write_pattern = 0x96969696                                // after swizzling and copying to fill the whole register
      ret = success       // we may need to differentiate between "pattern failed, try next" and "abort whole calibration"
      for each pattern
        ===============================================================
        // Custom read centering - pre-workaround
        turn off refreshing - see "Read clock align - pre-workaround"

        ---------------------------------------------------------------
        // Custom read centering - main
        //
        // Inner loop starts at the outer loop's current pattern and updates it, something like:
        //
        // for (int cur_pat = 0; cur_pat < NUM_PATTERNS; cur_pat++) {
        //   pre_workaround();
        //   for ( ; cur_pat < NUM_PATTERNS; cur_pat++) {
        //      ret = custom_read_calib_main(cur_pat);
        //      if (ret == success) break;
        //   }
        //   post_workaround();
        //   (...)
        //   ret = custom_write_calib();
        //   if (ret == success) break;
        // }
        //
        // Code above is simplified, there will be more tests and functions take more arguments, like rank pair and MCA.
        // This is done to try all patterns in one iteration of outer loop if read centering fails for a given pattern,
        // without the need for multiple invocations of pre- and post-workarounds, and without trying to do write calibration
        // if read calibration fails. In Hostboot, the inner loop is inside "main()" and some steps are done before that loop.
        //
        // Hostboot saves another copy of calibration registers - this would be used if there were a custom read calibration
        // without a write calibration, but it is redundant when both of those steps are performed. Likewise, this second
        // copy is restored before "main()" returns, but when both steps are performed together, it always has the same,
        // original values, regardless of when and where the failure happens. It is enough to restore it only once, after
        // the outer loop exits, only if it didn't report success.
        // TODO: move outside of loop?
        IOM0.DDRPHY_RC_CONFIG0_P0                           // 0x8000C8000701103F
            [63] STAGGERED_PATTERN = 1

        // TODO: move outside of loop?
        IOM0.DDRPHY_DP16_RX_CONFIG0_P0_{0-4}                // 0x800000060701103F, +0x0400_0000_0000
            [62-63] READ_CENTERING_MODE = 3

        for each not yet checked pattern
          if ret != success:
            restore original settings

          IOM0.DDRPHY_SEQ_RD_WR_DATA0_P0                    // 0x8000C4000701103F
            [all] 0?      // Hostboot does RMW, but everything else is RO, const 0
            [48-63] RD_WR_DATA_REG0 = (read_patterns[cur_pat] & 0xFFFF0000) >> 16

          IOM0.DDRPHY_SEQ_RD_WR_DATA1_P0                    // 0x8000C4010701103F
            [all] 0?      // Hostboot does RMW, but everything else is RO, const 0
            [48-63] RD_WR_DATA_REG1 = (read_patterns[cur_pat] & 0x0000FFFF)

          // Two registers set above specify:
          // a) data that is sent to MPRs in Initial Pattern Write,
          // b) data that is sent to reserved memory in Custom Write Centering,
          // c) expected data for Custom Read and Custom Write Centering.
          //
          // It isn't automatically sent to MPRs before Custom Read Calibration, so we must do another Initial Pattern Write.
          PHY steps common part:
            i_cal_config[49] ENA_INITIAL_PAT_WR = 1
            i_total_cycles = 1

          // Initial Pattern Write shouldn't fail, so this probably clears previous Custom Read Centering errors.
          clear_initial_cal_errors()          // described in 13.11.

          // TODO: move outside of loop?
          IOM0.DDRPHY_RC_RDVREF_CONFIG1_P0                  // 0x8000C80A0701103F
            [60]  CALIBRATION_ENABLE =  0
            [61]  SKIP_RDCENTERING =    0

          // Everything is configured, start PHY assisted calibration now.
          PHY steps common part:
            i_cal_config[56] ENA_CUSTOM_RD = 1
            // > This step runs for approximately 6 x (512/COARSE_CAL_STEP_SIZE + 4 x (COARSE_CAL_STEP_SIZE +
            // > 4 x CONSEQ_PASS)) x 24 DRAM clocks per rank pair.
            // This is exactly the same as in default read centering - algorithm is the same.
            i_total_cycles = 6 * (128 + 4 * (4 + 32)) * 24 = 39168

          ret = process_initial_cal_errors(DIMM)    // see end of 13.11
          if ret == success: break      // from the inner loop

        ---------------------------------------------------------------
        // Custom read centering - post-workaround
        turn on refreshing - see "Read clock align - post-workaround"

        ===============================================================

        // Break out of outer loop if read centering failed for all custom patterns. We will restore later.
        if ret != success: break

        ===============================================================
        // Custom write centering
        //
        // Skipping what was already done (is repeated for a case where only custom write centering is performed):
        // - saving BIT_DISABLE registers
        // - setting staggered mode
        save original write settings
          IOM0.DDRPHY_DP16_WR_DELAY_VALUE_{0-15,16,18,20,22}_RP<rp>_REG_P0_{0-4} // 0x80000<rp>380701103F, +0x0400_0000_0000
          // DP16_DQS_BIT_DISABLE and DP16_DQ_BIT_DISABLE are already saved

        IOM0.DDRPHY_DP16_WR_VREF_CONFIG0_P0_{0-4}         // 0x8000006C0701103F, +0x0400_0000_0000
          [48] WR_CTR_1D_MODE_SWITCH = 1

        IOM0.DDRPHY_SEQ_RD_WR_DATA0_P0                    // 0x8000C4000701103F
          [all] 0?      // Hostboot does RMW, but everything else is RO, const 0
          [48-63] RD_WR_DATA_REG0 = (write_patterns & 0xFFFF0000) >> 16

        IOM0.DDRPHY_SEQ_RD_WR_DATA1_P0                    // 0x8000C4010701103F
          [all] 0?      // Hostboot does RMW, but everything else is RO, const 0
          [48-63] RD_WR_DATA_REG1 = (write_patterns & 0x0000FFFF)

        clear_initial_cal_errors()          // described in 13.11.

        PHY steps common part:
          i_cal_config[57] ENA_CUSTOM_WR = 1
          // > 1000 + (NUM_VALID_SAMPLES * (FW_WR_RD + FW_RD_WR + 16) *
          // > (1024/(SMALL_STEP +1) + 128/(BIG_STEP +1)) + 2 * (BIG_STEP+1)/(SMALL_STEP+1)) x 24 DRAM
          // > clocks per rank pair.
          // This is exactly the same as in default write centering - algorithm is the same.
          i_total_cycles = 1000 + (5 * (0 + max(tWTR_S + 11, 0 + to_clocks(7.5ns) + 3) + 16) *
                            (1024/(0 + 1) + 128/(7 + 1)) + 2 * (7+1)/(0+1)) * 24

        ret = process_initial_cal_errors(DIMM)    // see end of 13.11
        if ret == success: break      // from the outer loop

        // else
        restore original write settings

      // End of outer loop. We either have found a better calibration values (ret == success) or calibration failed, in
      // which case we have to restore original, working values. As this step is not required for proper DRAM operation,
      // we do not report a failure in any case.
      if ret != success:
        restore original settings

## mss_draminit_mc: Hand off control to MC (13.13)

> a) p9_mss_draminit_mc.C  (mcbist) - Nimbus
> b) p9c_mss_draminit_mc.C  (membuf) -Cumulus
>    - P9 Cumulus --Set IML complete bit in centaur
>    - Start main refresh engine
>    - Refresh, periodic calibration, power controls
>    - Turn on ECC checking on memory accesses
>    - Note at this point memory FIRs can be monitored by PRD

